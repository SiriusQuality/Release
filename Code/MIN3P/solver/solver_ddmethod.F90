!*****Revision Informations Automatically Generated by VisualSVN*****!
!---------------------------------------------------------------------
!> $ID:$
!> $Revision: 491 $
!> $Author: fgerard $
!> $Date: 2017-07-18 00:06:39 +0200 (Tue, 18 Jul 2017) $
!> $URL: https://biot.eos.ubc.ca/svn/min3p_thcm/branches/fgerard_new/src/solver/solver_ddmethod.F90 $
!---------------------------------------------------------------------
!********************************************************************!

#ifdef PETSC

!> module: solver_dd
!>
!> written by: Danyang Su
!>
!> module description:
!>
!> Module of solver for domain decomposition method  
!>
!> Note:  
!> See http://www.mcs.anl.gov/petsc/ for detail


module solver_dd

    use solver_snes_common  
    
    implicit none  

    integer, parameter :: n_binary_limit = 1024          !2147483647

    contains
    
    !>
    !> Create distributed array (DMDA) to manage
    !> parallel grid and vector 
    !>
    subroutine solver_dd_DMDACreate
    
        use gen, only: varsat_flow, reactive_transport
    
        implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif

        
        PetscErrorCode :: ierr
        
        if(varsat_flow) then
            call solver_dd_DMDACreate_flow
        end if
        
        if(reactive_transport) then
            call solver_dd_DMDACreate_react 
        end if
    
    end subroutine
    
    !>
    !> Create distributed array (DMDA) for flow
    !> problem
    !>
    subroutine solver_dd_DMDACreate_flow()
    
        use gen, only: nvxgbl, nvygbl, nvzgbl, idbg, rank, nprcs,      &
                       mpiarray_ndim, mpiarray_sizes_gbl,              &
                       mpiarray_sizes_sub, mpiarray_starts_sub,        &
                       mpiarray_sizes_vel_gbl, mpiarray_sizes_vel_sub, &
                       mpiarray_starts_vel_sub, dmda_neighbors
        
        use dens, only : density_dependence
        use dual, only : dual_porosity
        use m_heat_transport, only : heat_transport
   
        implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#include <petsc/finclude/petscdmdef.h>
#include <petsc/finclude/petscdm.h>
#include <petsc/finclude/petscdmda.h>
#include <petsc/finclude/petscdmda.h90>
#elif PETSC
#include <finclude/petscsys.h>
#include <finclude/petscdmdef.h>
#include <finclude/petscdm.h>
#include <finclude/petscdmda.h>
#include <finclude/petscdmda.h90>
#endif
        
        PetscErrorCode :: ierr
        
        PetscInt :: istart, iend, info_debug        
        
        !> Initialize       
        if((density_dependence .and. heat_transport) .or.              &
              dual_porosity) then
            dmda_flow%dof = 2
        else
            dmda_flow%dof = 1
        end if      
        
        if(stencil_width > 0) then
            dmda_flow%swidth = stencil_width
        else
            dmda_flow%swidth = 1
        end if
        
        dmda_flow%dim  = 0
        
        dmda_flow%xs   = 0
        dmda_flow%xe   = 0
        dmda_flow%xl   = 1
        dmda_flow%gxs  = 0
        dmda_flow%gxe  = 0
        dmda_flow%gxl  = 1

        dmda_flow%ys   = 0
        dmda_flow%ye   = 0
        dmda_flow%yl   = 1
        dmda_flow%gys  = 0
        dmda_flow%gye  = 0
        dmda_flow%gyl  = 1

        dmda_flow%zs   = 0
        dmda_flow%ze   = 0
        dmda_flow%zl   = 1
        dmda_flow%gzs  = 0
        dmda_flow%gze  = 0
        dmda_flow%gzl  = 1

        dmda_flow%nvxgbl   = 1
        dmda_flow%nvygbl   = 1
        dmda_flow%nvzgbl   = 1

        dmda_flow%npx  = 1
        dmda_flow%npy  = 1
        dmda_flow%npz  = 1
        
        !> Initialize mpi subarray parameters
        mpiarray_ndim = 1
        
        mpiarray_sizes_gbl = 1
        mpiarray_sizes_sub = 1
        mpiarray_starts_sub = 0
        
        mpiarray_sizes_vel_gbl = 1
        mpiarray_sizes_vel_sub = 1
        mpiarray_starts_vel_sub = 0
   
        !> Create DMDA and get local grid boundary
        !3D domain
        if (nvxgbl > 1 .and. nvygbl > 1 .and. nvzgbl > 1) then  
!cdsu Note: DMDABoundaryType has become DMBoundaryType, and all the 
!cdsu enumerationvalues have also been renamed from PETSc 3.5
!cdsu For the windows version, we still use PETSc 3.4.
#ifdef PETSC_V3_5_X
            call DMDACreate3d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     DM_BOUNDARY_NONE,DM_BOUNDARY_NONE,                &
                     DMDA_STENCIL_BOX,nvxgbl,nvygbl,nvzgbl,            &
                     PETSC_DECIDE,PETSC_DECIDE,                        &
                     PETSC_DECIDE,                                     &
                     dmda_flow%dof, dmda_flow%swidth,                  &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,dmda_flow%da,ierr) 
            CHKERRQ(ierr)
#else
            call DMDACreate3d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     DMDA_BOUNDARY_NONE,DMDA_BOUNDARY_NONE,            &
                     DMDA_STENCIL_BOX,nvxgbl,nvygbl,nvzgbl,            &
                     PETSC_DECIDE,PETSC_DECIDE,                        &
                     PETSC_DECIDE,                                     &
                     dmda_flow%dof, dmda_flow%swidth,                  &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,dmda_flow%da,ierr) 
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_flow%da,dmda_flow%dim,               &
                     dmda_flow%nvxgbl,dmda_flow%nvygbl,                &
                     dmda_flow%nvzgbl,                                 &
                     dmda_flow%npx,dmda_flow%npy,                      &
                     dmda_flow%npz, PETSC_NULL_INTEGER,                &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_flow%da,dmda_flow%xs,             &
                     dmda_flow%ys,dmda_flow%zs,                        &
                     dmda_flow%xl,dmda_flow%yl,                        &
                     dmda_flow%zl,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_flow%da,dmda_flow%gxs,       &
                     dmda_flow%gys,dmda_flow%gzs,                      &
                     dmda_flow%gxl,dmda_flow%gyl,                      &
                     dmda_flow%gzl,ierr)
            CHKERRQ(ierr)
            
            !>Note: mpi subbary parameters are 0-based index
            mpiarray_ndim = 3            
            mpiarray_sizes_gbl(1) = nvxgbl            
            mpiarray_sizes_sub(1) = dmda_flow%xl
            mpiarray_starts_sub(1) = dmda_flow%xs
            
            mpiarray_sizes_gbl(2) = nvygbl          
            mpiarray_sizes_sub(2) = dmda_flow%yl
            mpiarray_starts_sub(2) = dmda_flow%ys
            
            mpiarray_sizes_gbl(3) = nvzgbl
            mpiarray_sizes_sub(3) = dmda_flow%zl
            mpiarray_starts_sub(3) = dmda_flow%zs
            
            mpiarray_sizes_vel_gbl(1) = nvxgbl-1 
            if(dmda_flow%xs == dmda_flow%gxs) then
              mpiarray_sizes_vel_sub(1) = dmda_flow%xl-1  
              mpiarray_starts_vel_sub(1) = dmda_flow%xs
            else
              mpiarray_sizes_vel_sub(1) = dmda_flow%xl 
              mpiarray_starts_vel_sub(1) = dmda_flow%xs-1
            end if
            
            mpiarray_sizes_vel_gbl(2) = nvygbl-1
            if(dmda_flow%ys == dmda_flow%gys) then
              mpiarray_sizes_vel_sub(2) = dmda_flow%yl-1  
              mpiarray_starts_vel_sub(2) = dmda_flow%ys
            else
              mpiarray_sizes_vel_sub(2) = dmda_flow%yl 
              mpiarray_starts_vel_sub(2) = dmda_flow%ys-1
            end if
            
            mpiarray_sizes_vel_gbl(3) = nvzgbl-1 
            if(dmda_flow%zs == dmda_flow%gzs) then
              mpiarray_sizes_vel_sub(3) = dmda_flow%zl-1  
              mpiarray_starts_vel_sub(3) = dmda_flow%zs
            else
              mpiarray_sizes_vel_sub(3) = dmda_flow%zl 
              mpiarray_starts_vel_sub(3) = dmda_flow%zs-1
            end if
            
            allocate(dmda_neighbors(27))
            dmda_neighbors = -1
            call DMDAGetNeighbors(dmda_flow%da, dmda_neighbors, ierr)
            CHKERRQ(ierr)

        !2D xy domain                                                  
        else if (nvxgbl > 1 .and. nvygbl > 1) then    
#ifdef PETSC_V3_5_X
            call DMDACreate2d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     DM_BOUNDARY_NONE, DMDA_STENCIL_BOX,               &
                     nvxgbl,nvygbl,PETSC_DECIDE,PETSC_DECIDE,          &
                     dmda_flow%dof, dmda_flow%swidth,                  &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_flow%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate2d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     DMDA_BOUNDARY_NONE, DMDA_STENCIL_BOX,             &
                     nvxgbl,nvygbl,PETSC_DECIDE,PETSC_DECIDE,          &
                     dmda_flow%dof, dmda_flow%swidth,                  &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_flow%da,ierr) 
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_flow%da,dmda_flow%dim,               &
                     dmda_flow%nvxgbl,dmda_flow%nvygbl,                &
                     PETSC_NULL_INTEGER,                               &
                     dmda_flow%npx,dmda_flow%npy,                      &
                     PETSC_NULL_INTEGER, PETSC_NULL_INTEGER,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_flow%da,dmda_flow%xs,             &
                     dmda_flow%ys,PETSC_NULL_INTEGER,                  &
                     dmda_flow%xl,dmda_flow%yl,                        &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_flow%da,dmda_flow%gxs,       &
                     dmda_flow%gys,PETSC_NULL_INTEGER,                 &
                     dmda_flow%gxl,dmda_flow%gyl,                      &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
            
            !>Note: mpi subbary parameters are 0-based index
            mpiarray_ndim = 2            
            mpiarray_sizes_gbl(1) = nvxgbl            
            mpiarray_sizes_sub(1) = dmda_flow%xl
            mpiarray_starts_sub(1) = dmda_flow%xs
            
            mpiarray_sizes_gbl(2) = nvygbl          
            mpiarray_sizes_sub(2) = dmda_flow%yl
            mpiarray_starts_sub(2) = dmda_flow%ys
            
           
            mpiarray_sizes_vel_gbl(1) = nvxgbl-1 
            if(dmda_flow%xs == dmda_flow%gxs) then
              mpiarray_sizes_vel_sub(1) = dmda_flow%xl-1  
              mpiarray_starts_vel_sub(1) = dmda_flow%xs
            else
              mpiarray_sizes_vel_sub(1) = dmda_flow%xl 
              mpiarray_starts_vel_sub(1) = dmda_flow%xs-1
            end if
            
            mpiarray_sizes_vel_gbl(2) = nvygbl-1
            if(dmda_flow%ys == dmda_flow%gys) then
              mpiarray_sizes_vel_sub(2) = dmda_flow%yl-1  
              mpiarray_starts_vel_sub(2) = dmda_flow%ys
            else
              mpiarray_sizes_vel_sub(2) = dmda_flow%yl 
              mpiarray_starts_vel_sub(2) = dmda_flow%ys-1
            end if

            allocate(dmda_neighbors(9))
            dmda_neighbors = -1
            call DMDAGetNeighbors(dmda_flow%da, dmda_neighbors, ierr)
            CHKERRQ(ierr)

        !2D yz domain                                                  
        else if (nvygbl > 1 .and. nvzgbl > 1) then    
#ifdef PETSC_V3_5_X
            call DMDACreate2d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     DM_BOUNDARY_NONE, DMDA_STENCIL_BOX,               &
                     nvygbl,nvzgbl,PETSC_DECIDE,PETSC_DECIDE,          &
                     dmda_flow%dof, dmda_flow%swidth,                  &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_flow%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate2d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     DMDA_BOUNDARY_NONE, DMDA_STENCIL_BOX,             &
                     nvygbl,nvzgbl,PETSC_DECIDE,PETSC_DECIDE,          &
                     dmda_flow%dof, dmda_flow%swidth,                  &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_flow%da,ierr)
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_flow%da,dmda_flow%dim,               &
                     dmda_flow%nvygbl,dmda_flow%nvzgbl,                &
                     PETSC_NULL_INTEGER,                               &
                     dmda_flow%npy,dmda_flow%npz,                      &
                     PETSC_NULL_INTEGER, PETSC_NULL_INTEGER,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_flow%da,dmda_flow%ys,             &
                     dmda_flow%zs,PETSC_NULL_INTEGER,                  &
                     dmda_flow%yl,dmda_flow%zl,                        &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_flow%da,dmda_flow%gys,       &
                     dmda_flow%gzs,PETSC_NULL_INTEGER,                 &
                     dmda_flow%gyl,dmda_flow%gzl,                      &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
            
            !>Note: mpi subbary parameters are 0-based index
            mpiarray_ndim = 2            
            mpiarray_sizes_gbl(1) = nvygbl            
            mpiarray_sizes_sub(1) = dmda_flow%yl
            mpiarray_starts_sub(1) = dmda_flow%ys
            
            mpiarray_sizes_gbl(2) = nvzgbl          
            mpiarray_sizes_sub(2) = dmda_flow%zl
            mpiarray_starts_sub(2) = dmda_flow%zs
            
            mpiarray_sizes_vel_gbl(1) = nvygbl-1 
            if(dmda_flow%ys == dmda_flow%gys) then
              mpiarray_sizes_vel_sub(1) = dmda_flow%yl-1  
              mpiarray_starts_vel_sub(1) = dmda_flow%ys
            else
              mpiarray_sizes_vel_sub(1) = dmda_flow%yl 
              mpiarray_starts_vel_sub(1) = dmda_flow%ys-1
            end if
            
            mpiarray_sizes_vel_gbl(2) = nvzgbl-1
            if(dmda_flow%zs == dmda_flow%gzs) then
              mpiarray_sizes_vel_sub(2) = dmda_flow%zl-1  
              mpiarray_starts_vel_sub(2) = dmda_flow%zs
            else
              mpiarray_sizes_vel_sub(2) = dmda_flow%zl 
              mpiarray_starts_vel_sub(2) = dmda_flow%zs-1
            end if

            allocate(dmda_neighbors(9))
            dmda_neighbors = -1
            call DMDAGetNeighbors(dmda_flow%da, dmda_neighbors, ierr)
            CHKERRQ(ierr)

        !2D xz domain                                                  
        else if (nvzgbl > 1 .and. nvxgbl > 1) then  
#ifdef PETSC_V3_5_X
            call DMDACreate2d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     DM_BOUNDARY_NONE, DMDA_STENCIL_BOX,               &
                     nvxgbl,nvzgbl,PETSC_DECIDE,PETSC_DECIDE,          &
                     dmda_flow%dof, dmda_flow%swidth,                  &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_flow%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate2d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     DMDA_BOUNDARY_NONE, DMDA_STENCIL_BOX,             &
                     nvxgbl,nvzgbl,PETSC_DECIDE,PETSC_DECIDE,          &
                     dmda_flow%dof, dmda_flow%swidth,                  &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_flow%da,ierr)
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_flow%da,dmda_flow%dim,               &
                     dmda_flow%nvxgbl,dmda_flow%nvzgbl,                &
                     PETSC_NULL_INTEGER,                               &
                     dmda_flow%npx,dmda_flow%npz,                      &
                     PETSC_NULL_INTEGER, PETSC_NULL_INTEGER,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_flow%da,dmda_flow%xs,             &
                     dmda_flow%zs,PETSC_NULL_INTEGER,                  &
                     dmda_flow%xl,dmda_flow%zl,                        &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_flow%da,dmda_flow%gxs,       &
                     dmda_flow%gzs,PETSC_NULL_INTEGER,                 &
                     dmda_flow%gxl,dmda_flow%gzl,                      &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
            
            !>Note: mpi subbary parameters are 0-based index
            mpiarray_ndim = 2            
            mpiarray_sizes_gbl(1) = nvxgbl            
            mpiarray_sizes_sub(1) = dmda_flow%xl
            mpiarray_starts_sub(1) = dmda_flow%xs
            
            mpiarray_sizes_gbl(2) = nvzgbl          
            mpiarray_sizes_sub(2) = dmda_flow%zl
            mpiarray_starts_sub(2) = dmda_flow%zs
            
           
            mpiarray_sizes_vel_gbl(1) = nvxgbl-1 
            if(dmda_flow%xs == dmda_flow%gxs) then
              mpiarray_sizes_vel_sub(1) = dmda_flow%xl-1  
              mpiarray_starts_vel_sub(1) = dmda_flow%xs
            else
              mpiarray_sizes_vel_sub(1) = dmda_flow%xl 
              mpiarray_starts_vel_sub(1) = dmda_flow%xs-1
            end if
            
            mpiarray_sizes_vel_gbl(2) = nvzgbl-1
            if(dmda_flow%zs == dmda_flow%gzs) then
              mpiarray_sizes_vel_sub(2) = dmda_flow%zl-1  
              mpiarray_starts_vel_sub(2) = dmda_flow%zs
            else
              mpiarray_sizes_vel_sub(2) = dmda_flow%zl 
              mpiarray_starts_vel_sub(2) = dmda_flow%zs-1
            end if

            allocate(dmda_neighbors(9))
            dmda_neighbors = -1
            call DMDAGetNeighbors(dmda_flow%da, dmda_neighbors, ierr)
            CHKERRQ(ierr)

        !1D x domain                                                   
        else if (nvxgbl > 1) then
#ifdef PETSC_V3_5_X
            call DMDACreate1d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     nvxgbl,dmda_flow%dof,dmda_flow%swidth,            &
                     PETSC_NULL_INTEGER,dmda_flow%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate1d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     nvxgbl,dmda_flow%dof,dmda_flow%swidth,            &
                     PETSC_NULL_INTEGER,dmda_flow%da,ierr)  
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_flow%da,dmda_flow%dim,               &
                     dmda_flow%nvxgbl,PETSC_NULL_INTEGER,              &
                     PETSC_NULL_INTEGER,                               &
                     dmda_flow%npx,PETSC_NULL_INTEGER,                 &
                     PETSC_NULL_INTEGER, PETSC_NULL_INTEGER,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_flow%da,dmda_flow%xs,             &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_flow%xl,PETSC_NULL_INTEGER,                  &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_flow%da,dmda_flow%gxs,       &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_flow%gxl,PETSC_NULL_INTEGER,                 &
                     PETSC_NULL_INTEGER,ierr)  
            CHKERRQ(ierr)
            
            !>Note: mpi subbary parameters are 0-based index
            mpiarray_ndim = 1            
            mpiarray_sizes_gbl(1) = nvxgbl            
            mpiarray_sizes_sub(1) = dmda_flow%xl
            mpiarray_starts_sub(1) = dmda_flow%xs
            
            mpiarray_sizes_vel_gbl(1) = nvxgbl-1 
            if(dmda_flow%xs == dmda_flow%gxs) then
              mpiarray_sizes_vel_sub(1) = dmda_flow%xl-1  
              mpiarray_starts_vel_sub(1) = dmda_flow%xs
            else
              mpiarray_sizes_vel_sub(1) = dmda_flow%xl 
              mpiarray_starts_vel_sub(1) = dmda_flow%xs-1
            end if

            allocate(dmda_neighbors(3))
            dmda_neighbors = -1

                                                                      
        !1D y domain                                                   
        else if (nvygbl > 1) then           
#ifdef PETSC_V3_5_X
            call DMDACreate1d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     nvygbl,dmda_flow%dof,dmda_flow%swidth,            &
                     PETSC_NULL_INTEGER,dmda_flow%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate1d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     nvygbl,dmda_flow%dof,dmda_flow%swidth,            &
                     PETSC_NULL_INTEGER,dmda_flow%da,ierr)
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_flow%da,dmda_flow%dim,               &
                     dmda_flow%nvygbl,PETSC_NULL_INTEGER,              &
                     PETSC_NULL_INTEGER,                               &
                     dmda_flow%npy,PETSC_NULL_INTEGER,                 &
                     PETSC_NULL_INTEGER, PETSC_NULL_INTEGER,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_flow%da,dmda_flow%ys,             &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_flow%yl,PETSC_NULL_INTEGER,                  &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_flow%da,dmda_flow%gys,       &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_flow%gyl,PETSC_NULL_INTEGER,                 &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
            
            !>Note: mpi subbary parameters are 0-based index
            mpiarray_ndim = 1            
            mpiarray_sizes_gbl(1) = nvygbl            
            mpiarray_sizes_sub(1) = dmda_flow%yl
            mpiarray_starts_sub(1) = dmda_flow%ys
            
            mpiarray_sizes_vel_gbl(1) = nvygbl-1 
            if(dmda_flow%ys == dmda_flow%gys) then
              mpiarray_sizes_vel_sub(1) = dmda_flow%yl-1  
              mpiarray_starts_vel_sub(1) = dmda_flow%ys
            else
              mpiarray_sizes_vel_sub(1) = dmda_flow%yl 
              mpiarray_starts_vel_sub(1) = dmda_flow%ys-1
            end if

            allocate(dmda_neighbors(3))
            dmda_neighbors = -1
                                                                       
        !1D z domain                                                   
        else if (nvzgbl > 1) then        
#ifdef PETSC_V3_5_X
            call DMDACreate1d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     nvzgbl,dmda_flow%dof,dmda_flow%swidth,            &
                     PETSC_NULL_INTEGER,dmda_flow%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate1d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     nvzgbl,dmda_flow%dof,dmda_flow%swidth,            &
                     PETSC_NULL_INTEGER,dmda_flow%da,ierr)
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_flow%da,dmda_flow%dim,               &
                     dmda_flow%nvzgbl,PETSC_NULL_INTEGER,              &
                     PETSC_NULL_INTEGER,                               &
                     dmda_flow%npz,PETSC_NULL_INTEGER,                 &
                     PETSC_NULL_INTEGER, PETSC_NULL_INTEGER,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_flow%da,dmda_flow%zs,             &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_flow%zl,PETSC_NULL_INTEGER,                  &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_flow%da,dmda_flow%gzs,       &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_flow%gzl,PETSC_NULL_INTEGER,                 &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
            
            !>Note: mpi subbary parameters are 0-based index
            mpiarray_ndim = 1            
            mpiarray_sizes_gbl(1) = nvzgbl            
            mpiarray_sizes_sub(1) = dmda_flow%zl
            mpiarray_starts_sub(1) = dmda_flow%zs
            
            mpiarray_sizes_vel_gbl(1) = nvzgbl-1 
            if(dmda_flow%zs == dmda_flow%gzs) then
              mpiarray_sizes_vel_sub(1) = dmda_flow%zl-1  
              mpiarray_starts_vel_sub(1) = dmda_flow%zs
            else
              mpiarray_sizes_vel_sub(1) = dmda_flow%zl 
              mpiarray_starts_vel_sub(1) = dmda_flow%zs-1
            end if
            
            allocate(dmda_neighbors(3))
            dmda_neighbors = -1

        end if
        
        !> Shift the starting indices up by one so that we can easily
        !> use the Fortran convention of 1-based indices (rather 0-based indices).
        dmda_flow%xs  = dmda_flow%xs+1        
        dmda_flow%ys  = dmda_flow%ys+1        
        dmda_flow%zs  = dmda_flow%zs+1
        
        dmda_flow%gxs = dmda_flow%gxs+1
        dmda_flow%gys = dmda_flow%gys+1
        dmda_flow%gzs = dmda_flow%gzs+1
        
        dmda_flow%xe  = dmda_flow%xs+dmda_flow%xl-1
        dmda_flow%ye  = dmda_flow%ys+dmda_flow%yl-1
        dmda_flow%ze  = dmda_flow%zs+dmda_flow%zl-1

        dmda_flow%gxe = dmda_flow%gxs+dmda_flow%gxl-1
        dmda_flow%gye = dmda_flow%gys+dmda_flow%gyl-1
        dmda_flow%gze = dmda_flow%gzs+dmda_flow%gzl-1
        
        !> Extract global and local vectors from DMDA; then duplicate for remaining
        !> vectors that are the same types
        call DMCreateGlobalVector(dmda_flow%da,x_flow,ierr)
        CHKERRQ(ierr)
        call VecDuplicate(x_flow,b_flow,ierr)
        CHKERRQ(ierr)
        call VecDuplicate(b_flow,r_flow,ierr)
        CHKERRQ(ierr)
        
        call DMCreateLocalVector(dmda_flow%da,x_flow_loc,ierr)
        CHKERRQ(ierr)
        call VecDuplicate(x_flow_loc,b_flow_loc,ierr)
        CHKERRQ(ierr)
        call VecDuplicate(b_flow_loc,r_flow_loc,ierr)
        CHKERRQ(ierr)
        
        !> get range
        call VecGetOwnershipRange(x_flow, istart, iend, ierr)
        CHKERRQ(ierr)
        dmda_flow%range_start = istart + 1
        dmda_flow%range_end = iend
        
        !> Check the result
#ifdef DEBUG
        info_debug = 0
        if(info_debug > 0) then
            write(idbg, '(a/,26(1x,a,1x,i4))')                         &
                  "flow","dof",dmda_flow%dof,                          &
                  "stencil_width", dmda_flow%swidth,                   &
                  "dim",dmda_flow%dim,"nvxgbl",dmda_flow%nvxgbl,       &
                  "nvygbl",dmda_flow%nvygbl,                           &
                  "nvzgbl",dmda_flow%nvzgbl,                           & 
                  "xs",dmda_flow%xs,"xe",dmda_flow%xe,                 &
                  "xl",dmda_flow%xl,"gxs",dmda_flow%gxs,               &
                  "gxe",dmda_flow%gxe,"gxl",dmda_flow%gxl,             &
                  "ys",dmda_flow%ys,"ye",dmda_flow%ye,                 &
                  "yl",dmda_flow%yl,"gys",dmda_flow%gys,               &
                  "gye",dmda_flow%gye,"gyl",dmda_flow%gyl,             &
                  "zs",dmda_flow%zs,"ze",dmda_flow%ze,                 &
                  "zl",dmda_flow%zl,"gzs",dmda_flow%gzs,               &
                  "gze",dmda_flow%gze,"gzl",dmda_flow%gzl,             &
                  "vec_range_start", dmda_flow%range_start,            &
                  "vec_range_end", dmda_flow%range_end
        end if
#endif
    
    end subroutine 
    
    !>
    !> Create distributed array (DMDA) for reactive
    !> transport problem
    !>
    subroutine solver_dd_DMDACreate_react()
    
        use gen, only: nvxgbl, nvygbl, nvzgbl, n, idbg, rank
    
        implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#include <petsc/finclude/petscdmdef.h>
#include <petsc/finclude/petscdm.h>
#include <petsc/finclude/petscdmda.h>
#include <petsc/finclude/petscdmda.h90>
#elif PETSC
#include <finclude/petscsys.h>
#include <finclude/petscdmdef.h>
#include <finclude/petscdm.h>
#include <finclude/petscdmda.h>
#include <finclude/petscdmda.h90>
#endif
        
        PetscErrorCode :: ierr
        
        PetscInt :: istart, iend, info_debug        
        
        !> Initialize       
        dmda_react%dof = n
        
        if(stencil_width > 0) then
            dmda_react%swidth = stencil_width 
        else
            dmda_react%swidth = 1
        end if
        
        dmda_react%xs   = 0
        dmda_react%xe   = 0
        dmda_react%xl   = 1
        dmda_react%gxs  = 0
        dmda_react%gxe  = 0
        dmda_react%gxl  = 1

        dmda_react%ys   = 0
        dmda_react%ye   = 0
        dmda_react%yl   = 1
        dmda_react%gys  = 0
        dmda_react%gye  = 0
        dmda_react%gyl  = 1

        dmda_react%zs   = 0
        dmda_react%ze   = 0
        dmda_react%zl   = 1
        dmda_react%gzs  = 0
        dmda_react%gze  = 0
        dmda_react%gzl  = 1

        dmda_react%nvxgbl   = 1
        dmda_react%nvygbl   = 1
        dmda_react%nvzgbl   = 1

        dmda_react%npx  = 1
        dmda_react%npy  = 1
        dmda_react%npz  = 1
   
        !> Create DMDA and get local grid boundary
        !3D domain
        if (nvxgbl > 1 .and. nvygbl > 1 .and. nvzgbl > 1) then 
!cdsu Note: DMDABoundaryType has become DMBoundaryType, and all the 
!cdsu enumerationvalues have also been renamed from PETSc 3.5.
!cdsu For the windows version, we still use PETSc 3.4. 
#ifdef PETSC_V3_5_X
            call DMDACreate3d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     DM_BOUNDARY_NONE,DM_BOUNDARY_NONE,                &
                     DMDA_STENCIL_BOX,nvxgbl,nvygbl,nvzgbl,            &
                     PETSC_DECIDE,PETSC_DECIDE,                        &
                     PETSC_DECIDE,                                     &
                     dmda_react%dof, dmda_react%swidth,                &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,dmda_react%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate3d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     DMDA_BOUNDARY_NONE,DMDA_BOUNDARY_NONE,            &
                     DMDA_STENCIL_BOX,nvxgbl,nvygbl,nvzgbl,            &
                     PETSC_DECIDE,PETSC_DECIDE,                        &
                     PETSC_DECIDE,                                     &
                     dmda_react%dof, dmda_react%swidth,                &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,dmda_react%da,ierr)
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_react%da,dmda_react%dim,             &
                     dmda_react%nvxgbl,dmda_react%nvygbl,              &
                     dmda_react%nvzgbl,                                &
                     dmda_react%npx,dmda_react%npy,                    &
                     dmda_react%npz, PETSC_NULL_INTEGER,               &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_react%da,dmda_react%xs,           &
                     dmda_react%ys,dmda_react%zs,                      &
                     dmda_react%xl,dmda_react%yl,                      &
                     dmda_react%zl,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_react%da,dmda_react%gxs,     &
                     dmda_react%gys,dmda_react%gzs,                    &
                     dmda_react%gxl,dmda_react%gyl,                    &
                     dmda_react%gzl,ierr)
             CHKERRQ(ierr)

        !2D xy domain                                                  
        else if (nvxgbl > 1 .and. nvygbl > 1) then  
#ifdef PETSC_V3_5_X
            call DMDACreate2d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     DM_BOUNDARY_NONE, DMDA_STENCIL_BOX,               &
                     nvxgbl,nvygbl,PETSC_DECIDE,PETSC_DECIDE,          &
                     dmda_react%dof, dmda_react%swidth,                &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_react%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate2d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     DMDA_BOUNDARY_NONE, DMDA_STENCIL_BOX,             &
                     nvxgbl,nvygbl,PETSC_DECIDE,PETSC_DECIDE,          &
                     dmda_react%dof, dmda_react%swidth,                &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_react%da,ierr)
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_react%da,dmda_react%dim,             &
                     dmda_react%nvxgbl,dmda_react%nvygbl,              &
                     PETSC_NULL_INTEGER,                               &
                     dmda_react%npx,dmda_react%npy,                    &
                     PETSC_NULL_INTEGER, PETSC_NULL_INTEGER,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_react%da,dmda_react%xs,           &
                     dmda_react%ys,PETSC_NULL_INTEGER,                 &
                     dmda_react%xl,dmda_react%yl,                      &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_react%da,dmda_react%gxs,     &
                     dmda_react%gys,PETSC_NULL_INTEGER,                &
                     dmda_react%gxl,dmda_react%gyl,                    &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)

        !2D yz domain                                                  
        else if (nvygbl > 1 .and. nvzgbl > 1) then     
#ifdef PETSC_V3_5_X
            call DMDACreate2d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     DM_BOUNDARY_NONE, DMDA_STENCIL_BOX,               &
                     nvygbl,nvzgbl,PETSC_DECIDE,PETSC_DECIDE,          &
                     dmda_react%dof, dmda_react%swidth,                &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_react%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate2d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     DMDA_BOUNDARY_NONE, DMDA_STENCIL_BOX,             &
                     nvygbl,nvzgbl,PETSC_DECIDE,PETSC_DECIDE,          &
                     dmda_react%dof, dmda_react%swidth,                &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_react%da,ierr)
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_react%da,dmda_react%dim,             &
                     dmda_react%nvygbl,dmda_react%nvzgbl,              &
                     PETSC_NULL_INTEGER,                               &
                     dmda_react%npy,dmda_react%npz,                    &
                     PETSC_NULL_INTEGER, PETSC_NULL_INTEGER,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_react%da,dmda_react%ys,           &
                     dmda_react%zs,PETSC_NULL_INTEGER,                 &
                     dmda_react%yl,dmda_react%zl,                      &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_react%da,dmda_react%gys,     &
                     dmda_react%gzs,PETSC_NULL_INTEGER,                &
                     dmda_react%gyl,dmda_react%gzl,                    &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)

        !2D xz domain                                                  
        else if (nvzgbl > 1 .and. nvxgbl > 1) then 
#ifdef PETSC_V3_5_X
            call DMDACreate2d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     DM_BOUNDARY_NONE, DMDA_STENCIL_BOX,               &
                     nvxgbl,nvzgbl,PETSC_DECIDE,PETSC_DECIDE,          &
                     dmda_react%dof, dmda_react%swidth,                &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_react%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate2d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     DMDA_BOUNDARY_NONE, DMDA_STENCIL_BOX,             &
                     nvxgbl,nvzgbl,PETSC_DECIDE,PETSC_DECIDE,          &
                     dmda_react%dof, dmda_react%swidth,                &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_react%da,ierr)
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_react%da,dmda_react%dim,             &
                     dmda_react%nvxgbl,dmda_react%nvzgbl,              &
                     PETSC_NULL_INTEGER,                               &
                     dmda_react%npx,dmda_react%npz,                    &
                     PETSC_NULL_INTEGER, PETSC_NULL_INTEGER,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_react%da,dmda_react%xs,           &
                     dmda_react%zs,PETSC_NULL_INTEGER,                 &
                     dmda_react%xl,dmda_react%zl,                      &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_react%da,dmda_react%gxs,     &
                     dmda_react%gzs,PETSC_NULL_INTEGER,                &
                     dmda_react%gxl,dmda_react%gzl,                    &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)

        !1D x domain                                                   
        else if (nvxgbl > 1) then
#ifdef PETSC_V3_5_X
            call DMDACreate1d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     nvxgbl,dmda_react%dof,dmda_react%swidth,          &
                     PETSC_NULL_INTEGER,dmda_react%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate1d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     nvxgbl,dmda_react%dof,dmda_react%swidth,          &
                     PETSC_NULL_INTEGER,dmda_react%da,ierr)
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_react%da,dmda_react%dim,             &
                     dmda_react%nvxgbl,PETSC_NULL_INTEGER,             &
                     PETSC_NULL_INTEGER,                               &
                     dmda_react%npx,PETSC_NULL_INTEGER,                &
                     PETSC_NULL_INTEGER, PETSC_NULL_INTEGER,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_react%da,dmda_react%xs,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_react%xl,PETSC_NULL_INTEGER,                 &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_react%da,dmda_react%gxs,     &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_react%gxl,PETSC_NULL_INTEGER,                &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
        !1D y domain                                                   
        else if (nvygbl > 1) then
#ifdef PETSC_V3_5_X
            call DMDACreate1d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     nvygbl,dmda_react%dof,dmda_react%swidth,          &
                     PETSC_NULL_INTEGER,dmda_react%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate1d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     nvygbl,dmda_react%dof,dmda_react%swidth,          &
                     PETSC_NULL_INTEGER,dmda_react%da,ierr)
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_react%da,dmda_react%dim,             &
                     dmda_react%nvygbl,PETSC_NULL_INTEGER,             &
                     PETSC_NULL_INTEGER,                               &
                     dmda_react%npy,PETSC_NULL_INTEGER,                &
                     PETSC_NULL_INTEGER, PETSC_NULL_INTEGER,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_react%da,dmda_react%ys,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_react%yl,PETSC_NULL_INTEGER,                 &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_react%da,dmda_react%gys,     &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_react%gyl,PETSC_NULL_INTEGER,                &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
        !1D z domain                                                   
        else if (nvzgbl > 1) then
#ifdef PETSC_V3_5_X
            call DMDACreate1d(Petsc_Comm_World,DM_BOUNDARY_NONE,       &
                     nvzgbl,dmda_react%dof,dmda_react%swidth,          &
                     PETSC_NULL_INTEGER,dmda_react%da,ierr)
            CHKERRQ(ierr)
#else
            call DMDACreate1d(Petsc_Comm_World,DMDA_BOUNDARY_NONE,     &
                     nvzgbl,dmda_react%dof,dmda_react%swidth,          &
                     PETSC_NULL_INTEGER,dmda_react%da,ierr)
            CHKERRQ(ierr)
#endif
                                                                       
            call DMDAGetInfo(dmda_react%da,dmda_react%dim,             &
                     dmda_react%nvzgbl,PETSC_NULL_INTEGER,             &
                     PETSC_NULL_INTEGER,                               &
                     dmda_react%npz,PETSC_NULL_INTEGER,                &
                     PETSC_NULL_INTEGER, PETSC_NULL_INTEGER,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetCorners(dmda_react%da,dmda_react%zs,           &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_react%zl,PETSC_NULL_INTEGER,                 &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
                                                                       
            call DMDAGetGhostCorners(dmda_react%da,dmda_react%gzs,     &
                     PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,            &
                     dmda_react%gzl,PETSC_NULL_INTEGER,                &
                     PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
            
        end if
        
        !> Shift the starting indices up by one so that we can easily
        !> use the Fortran convention of 1-based indices (rather 0-based indices).
        dmda_react%xs  = dmda_react%xs+1
        dmda_react%ys  = dmda_react%ys+1
        dmda_react%zs  = dmda_react%zs+1

        dmda_react%gxs = dmda_react%gxs+1
        dmda_react%gys = dmda_react%gys+1
        dmda_react%gzs = dmda_react%gzs+1

        dmda_react%xe  = dmda_react%xs+dmda_react%xl-1
        dmda_react%ye  = dmda_react%ys+dmda_react%yl-1
        dmda_react%ze  = dmda_react%zs+dmda_react%zl-1

        dmda_react%gxe = dmda_react%gxs+dmda_react%gxl-1
        dmda_react%gye = dmda_react%gys+dmda_react%gyl-1
        dmda_react%gze = dmda_react%gzs+dmda_react%gzl-1
        
        !> Extract global and local vectors from DMDA; then duplicate for remaining
        !> vectors that are the same types
        call DMCreateGlobalVector(dmda_react%da,x_react,ierr)
        CHKERRQ(ierr)
        call VecDuplicate(x_react,b_react,ierr)
        CHKERRQ(ierr)
        call VecDuplicate(b_react,r_react,ierr)
        CHKERRQ(ierr)
        
        call DMCreateLocalVector(dmda_react%da,x_react_loc,ierr)
        CHKERRQ(ierr)
        call VecDuplicate(x_react_loc,b_react_loc,ierr)
        CHKERRQ(ierr)
        call VecDuplicate(b_react_loc,r_react_loc,ierr)
        CHKERRQ(ierr)
        
        !> get range
        call VecGetOwnershipRange(x_react, istart, iend, ierr)
        CHKERRQ(ierr)
        dmda_react%range_start = istart + 1
        dmda_react%range_end = iend
        
        !> Check the result
#ifdef DEBUG
        info_debug = 0
        if(info_debug > 0) then
            write(idbg, '(a/,26(1x,a,1x,i4))')                         &
                  "reactive transport","dof",dmda_react%dof,           &
                  "stencil_width", dmda_react%swidth,                  &
                  "dim",dmda_react%dim,"nvxgbl",dmda_react%nvxgbl,     &
                  "nvygbl",dmda_react%nvygbl,                          &
                  "nvzgbl",dmda_react%nvzgbl,                          &
                  "xs",dmda_react%xs,"xe",dmda_react%xe,               &
                  "xl",dmda_react%xl,"gxs",dmda_react%gxs,             &
                  "gxe",dmda_react%gxe,"gxl",dmda_react%gxl,           &
                  "ys",dmda_react%ys,"ye",dmda_react%ye,               &
                  "yl",dmda_react%yl,"gys",dmda_react%gys,             &
                  "gye",dmda_react%gye,"gyl",dmda_react%gyl,           &
                  "zs",dmda_react%zs,"ze",dmda_react%ze,               &
                  "zl",dmda_react%zl,"gzs",dmda_react%gzs,             &
                  "gze",dmda_react%gze,"gzl",dmda_react%gzl,           &
                  "vec_range_start", dmda_react%range_start,           &
                  "vec_range_end", dmda_react%range_end
        end if
#endif
    
    end subroutine    
    
    !>Set global and local node index map
    subroutine solver_dd_mapping_set
    
        use gen, only: idbg, nvxgbl, nvygbl, nvzgbl, nvxls, nvxle,     &
                       nvyls, nvyle, nvzls, nvzle, nvxgls, nvxgle,     &
                       nvygls, nvygle, nvzgls, nvzgle, nn, nngl,       &
                       nngbl, node_idx_lg2l, node_idx_lg2g,            &
                       node_idx_lg2pg, node_idx_l2lg, rank,            &
                       node_idx_vel_lg2g
        use petsc_mpi_common, only : petsc_mpi_finalize
    
        implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#include <petsc/finclude/petscis.h>
#include <petsc/finclude/petscdmdef.h>
#include <petsc/finclude/petscdm.h>
#include <petsc/finclude/petscdmda.h>
#include <petsc/finclude/petscdmda.h90>
#elif PETSC
#include <finclude/petscsys.h>
#include <finclude/petscis.h>
#include <finclude/petscdmdef.h>
#include <finclude/petscdm.h>
#include <finclude/petscdmda.h>
#include <finclude/petscdmda.h90>
#endif

        
        PetscErrorCode :: ierr
               
        PetscInt :: ivx, ivy, ivz, ivol, ivol_l, ibase, ig, dof, ig_vel 

#ifdef PETSC_V3_5_X
        ISLocalToGlobalMapping :: ltogm
        !Method 1
        PetscInt :: ltog(1)
        PetscOffset :: idltog
        !Method 2
        !PetscInt, pointer :: idx(:)
#else
        PetscInt, pointer :: idx(:)  
#endif
        
        PetscInt :: info_debug
        
        
        allocate(node_idx_lg2g(nngl))  
        node_idx_lg2g = 0
        
        allocate(node_idx_vel_lg2g(nngl))
        node_idx_vel_lg2g = 0
        
        allocate(node_idx_lg2l(nngl))
        node_idx_lg2l = 0
        
        allocate(node_idx_lg2pg(nngl))
        node_idx_lg2pg = 0
        
        allocate(node_idx_l2lg(nn))
        node_idx_l2lg = 0
        
        
        ivol = 1
        ivol_l = 1
        
        select case (dmda_flow%dim)
            
        case (1)
            
            !1D x domain    
            if (nvxgbl > 1) then 
                do ivx = nvxgls,nvxgle  
                    node_idx_lg2g(ivol) = ivx
                    if (ivx == 1) then
                      node_idx_vel_lg2g(ivol) = -1
                    else
                      node_idx_vel_lg2g(ivol) = ivx-1 
                    end if
                    if(ivx < nvxls .or. ivx > nvxle) then
                        node_idx_lg2l(ivol) = -1
                    else
                        node_idx_lg2l(ivol) = ivol_l
                        node_idx_l2lg(ivol_l) = ivol
                        ivol_l = ivol_l + 1
                    end if
                    ivol = ivol + 1
                end do
            !1D y domain
            else if (nvygbl > 1) then  
                do ivy = nvygls,nvygle
                    node_idx_lg2g(ivol) = ivy
                    if (ivy == 1) then
                      node_idx_vel_lg2g(ivol) = -1
                    else
                      node_idx_vel_lg2g(ivol) = ivy-1 
                    end if
                    if(ivy < nvyls .or. ivy > nvyle) then
                        node_idx_lg2l(ivol) = -1
                    else
                        node_idx_lg2l(ivol) = ivol_l
                        node_idx_l2lg(ivol_l) = ivol
                        ivol_l = ivol_l + 1
                    end if
                    ivol = ivol + 1
                end do
            !1D z domain
            else if (nvzgbl > 1) then 
                do ivz = nvzgls, nvzgle
                    node_idx_lg2g(ivol) = ivz
                    if (ivz == 1) then
                      node_idx_vel_lg2g(ivol) = -1
                    else
                      node_idx_vel_lg2g(ivol) = ivz-1 
                    end if
                    if(ivz < nvzls .or. ivz > nvzle) then
                        node_idx_lg2l(ivol) = -1
                    else
                        node_idx_lg2l(ivol) = ivol_l
                        node_idx_l2lg(ivol_l) = ivol
                        ivol_l = ivol_l + 1
                    end if
                    ivol = ivol + 1
                end do  
            end if              
            
        case (2)
           
            !2D xy domain    
            if (nvxgbl > 1 .and. nvygbl > 1) then
                do ivy = nvygls,nvygle
                    ig = (ivy-1)*nvxgbl
                    ig_vel = (ivy-2)*(nvxgbl-1)
                    do ivx = nvxgls,nvxgle
                        node_idx_lg2g(ivol) = ig + ivx
                        if (ivx == 1 .or. ivy == 1) then
                          node_idx_vel_lg2g(ivol) = -1
                        else
                          node_idx_vel_lg2g(ivol) = ig_vel+ivx-1 
                        end if
                        if(ivx < nvxls .or. ivx > nvxle .or.           &
                           ivy < nvyls .or. ivy > nvyle) then
                            node_idx_lg2l(ivol) = -1
                        else
                            node_idx_lg2l(ivol) = ivol_l
                            node_idx_l2lg(ivol_l) = ivol
                            ivol_l = ivol_l + 1     
                        end if
                        ivol = ivol + 1   
                    end do
                end do
            !2D yz domain    
            else if (nvygbl > 1 .and. nvzgbl > 1) then
                do ivz = nvzgls, nvzgle
                    ig = (ivz-1)*nvygbl
                    ig_vel = (ivz-2)*(nvygbl-1)
                    do ivy = nvygls,nvygle            
                        node_idx_lg2g(ivol) = ig + ivy
                        if (ivz == 1 .or. ivy == 1) then
                          node_idx_vel_lg2g(ivol) = -1
                        else
                          node_idx_vel_lg2g(ivol) = ig_vel+ivy-1 
                        end if
                        if(ivy < nvyls .or. ivy > nvyle .or.           &
                           ivz < nvzls .or. ivz > nvzle) then
                            node_idx_lg2l(ivol) = -1
                        else    
                            node_idx_lg2l(ivol) = ivol_l
                            node_idx_l2lg(ivol_l) = ivol
                            ivol_l = ivol_l + 1
                        end if
                        ivol = ivol + 1     
                    end do
                end do
            !2D xz domain    
            else if (nvzgbl > 1 .and. nvxgbl > 1) then
                do ivz = nvzgls, nvzgle
                    ig = (ivz-1)*nvxgbl
                    ig_vel = (ivz-2)*(nvxgbl-1)
                    do ivx = nvxgls,nvxgle                   
                        node_idx_lg2g(ivol) = ig + ivx
                        if (ivz == 1 .or. ivx == 1) then
                          node_idx_vel_lg2g(ivol) = -1
                        else
                          node_idx_vel_lg2g(ivol) = ig_vel+ivx-1 
                        end if
                        if(ivx < nvxls .or. ivx > nvxle .or.           &
                           ivz < nvzls .or. ivz > nvzle) then
                            node_idx_lg2l(ivol) = -1
                        else    
                            node_idx_lg2l(ivol) = ivol_l
                            node_idx_l2lg(ivol_l) = ivol
                            ivol_l = ivol_l + 1
                        end if
                        ivol = ivol + 1
                    end do
                end do
            end if
            
        case (3)             

            do ivz = nvzgls, nvzgle                
                do ivy = nvygls,nvygle
                    ig = (ivz-1)*nvygbl*nvxgbl+(ivy-1)*nvxgbl
                    ig_vel = (ivz-2)*(nvygbl-1)*(nvxgbl-1)+            &
                             (ivy-2)*(nvxgbl-1)
                    do ivx = nvxgls,nvxgle   
                        node_idx_lg2g(ivol) = ig + ivx
                        if (ivx == 1 .or. ivy == 1 .or. ivz == 1) then
                          node_idx_vel_lg2g(ivol) = -1
                        else
                          node_idx_vel_lg2g(ivol) = ig_vel+ivx-1 
                        end if
                        if(ivx < nvxls .or. ivx > nvxle .or.           &
                           ivy < nvyls .or. ivy > nvyle .or.           &
                           ivz < nvzls .or. ivz > nvzle) then
                            node_idx_lg2l(ivol) = -1
                        else
                            node_idx_lg2l(ivol) = ivol_l
                            node_idx_l2lg(ivol_l) = ivol
                            ivol_l = ivol_l + 1    
                        end if
                        ivol = ivol + 1                
                    end do
                end do
            end do
          
        end select
        
        info_debug = 0
#ifdef DEBUG
        if(info_debug > 0) then
            do ivol = 1, nngl
                write(idbg,'(5(a,1x,i6,1x))') "ivol_l",ivol,           &
                      "ivol_l_no_ghost",node_idx_lg2l(ivol),           &
                      "ivol_g",node_idx_lg2g(ivol),                    &
                      "ivol_vel_g",node_idx_vel_lg2g(ivol)
                      
            end do
        end if
#endif        
        
        !Check DMDA pointer to the list of global indices in the matrix
        !When dof == 2, size(idx,1) = 2*nngl
!cdsu Note:  DMDAGetGlobalIndicesF90 has been removed from PETSc 3.5, 
!cdsu Note:  use DMGetLocalToGlobalMapping instead.
!cdsu For the windows version, we still use PETSc 3.4. 
#ifdef PETSC_V3_5_X
        !Method 1
        call DMGetLocalToGlobalMapping(dmda_flow%da,ltogm,ierr)
        CHKERRQ(ierr)
        call ISLocalToGlobalMappingGetIndices(ltogm,ltog,idltog,ierr)
        CHKERRQ(ierr)
        
        !Method 2
        !call DMGetLocalToGlobalMapping(dmda_flow%da,ltogm,ierr)
        !CHKERRQ(ierr)
        !call ISLocalToGlobalMappingGetIndicesF90(ltogm,idx,ierr)  !stack overflow here
        !CHKERRQ(ierr)
#else
        call DMDAGetGlobalIndicesF90(dmda_flow%da,PETSC_NULL_INTEGER,  &
                                     idx,ierr)
        CHKERRQ(ierr)
#endif
        
        dof = dmda_flow%dof     
        
        do ivol = 1, nngl
#ifdef PETSC_V3_5_X
            !Method 1
            node_idx_lg2pg(ivol) = (ltog(ivol*dof + idltog)+1)/dof
            !Method 2
            !node_idx_lg2pg(ivol) = (idx(ivol*dof)+1)/dof
#else
            node_idx_lg2pg(ivol) = (idx(ivol*dof)+1)/dof
#endif

#ifdef DEBUG
            if(info_debug > 0) then
              write(idbg,'(2(a,1x,i10,1x))')"ivol",ivol,"global index",&
                                          node_idx_lg2pg(ivol)
            end if
#endif
        end do

#ifdef PETSC_V3_5_X
        !Method 1 
        call ISLocalToGlobalMappingRestoreIndices(ltogm,ltog,idltog,ierr)
        CHKERRQ(ierr)
        !Method 2
        !call ISLocalToGlobalMappingRestoreIndicesF90(ltogm,idx,ierr)
        !CHKERRQ(ierr)
#endif
        
        if(info_debug > 1) then
            call petsc_mpi_finalize
            stop
        end if
        
   
    end subroutine
   
    !> set DMDA coordinates 
    subroutine solver_dd_coordinates_set
    
        use gen, only: idbg, nvxgbl, nvygbl, nvzgbl, nvxls, nvxle,     &
                       nvyls, nvyle, nvzls, nvzle, nvxgls, nvxgle,     &
                       nvygls, nvygle, nvzgls, nvzgle,                 &
                       nvxgl, nvygl, nvzgl, xglat, yglat, zglat
    
        implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#include <petsc/finclude/petscvec.h>
#include <petsc/finclude/petscdmdef.h>
#include <petsc/finclude/petscdm.h>
#include <petsc/finclude/petscdmda.h>
#include <petsc/finclude/petscdmda.h90>
#elif PETSC
#include <finclude/petscsys.h>
#include <finclude/petscvec.h>
#include <finclude/petscdmdef.h>
#include <finclude/petscdm.h>
#include <finclude/petscdmda.h>
#include <finclude/petscdmda.h90>
#endif
        
        PetscErrorCode :: ierr
        
        PetscScalar, pointer :: coords1d(:)
        !DMDACoor2d, pointer :: coords2d(:,:)
        !DMDACoor3d, pointer :: coords3d(:,:,:) 
        !Note: There is no DMDACoor2d or 3d in Fortran (maybe added later), 
        !should use PetscScalar instead. 
        !The first index is 0, 1 or 2 for the x, y, or z coordinate
        PetscScalar, pointer :: coords2d(:,:,:) 
        PetscScalar, pointer :: coords3d(:,:,:,:) 
        Vec :: gc,global
        DM :: cda
        PetscInt :: ivx, ivy, ivz, ivol, istart1, iend1,               &
                    istart2, iend2, istart3, iend3, istart4, iend4,    &
                    ibase        

        PetscReal :: r0
        
        
        PetscInt :: info_debug
        
        parameter (r0 = 0.0d0)
        
        info_debug = 0
      
        
        select case (dmda_flow%dim)
            
        case (1)
            
            call DMDASetUniformCoordinates(dmda_flow%da,               &
                    0.0d0,1.0d0,                                       &
                    PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,             &
                    PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
            
            call DMGetCoordinateDM(dmda_flow%da,cda,ierr)
            CHKERRQ(ierr)
            call DMGetCoordinatesLocal(dmda_flow%da,gc,ierr)
            CHKERRQ(ierr)
            call DMDAVecGetArrayF90(cda,gc,coords1d,ierr)
            CHKERRQ(ierr)
     
#ifdef DEBUG
            if(info_debug > 0) then
                !Please note the index is 0-based            
                istart1 = lbound(coords1d,1)
                iend1 = ubound(coords1d,1)  
                write(idbg,'(a/,2(a,1x,i10,1x))')                      &
                        "set the coordinates 1 dim",                   &
                        "start1",istart1,"end1",iend1
            end if
#endif
            
            ibase = 1 
            ivol = 0
            
            !1D x domain
            if (nvxgbl > 1) then                                
                do ivx = nvxls,nvxle
                    coords1d(ivx-ibase) = xglat(ivx)   
#ifdef DEBUG
                    if(info_debug > 0) then
                        ivol = ivx - nvxgls + 1
                        write(idbg,'(a,1x,i6,3(1x,a,1x,e13.6))')       &
                                "ivol_l", ivol,                        &
                                "xg", coords1d(ivx-ibase),             &
                                "yg", r0,                              &
                                "zg", r0
                    end if
#endif
                end do
            !1D y domain
            else if (nvygbl > 1) then                                
                do ivy = nvyls,nvyle
                    coords1d(ivy-ibase) = yglat(ivy)
#ifdef DEBUG
                    if(info_debug > 0) then
                        ivol = ivy - nvygls + 1
                        write(idbg,'(a,1x,i6,3(1x,a,1x,e13.6))')       &
                                "ivol_l", ivol,                        &
                                "xg", r0,                              &
                                "yg", coords1d(ivy-ibase),             &
                                "zg", r0
                    end if
#endif
                end do
            !1D z domain
            else if (nvzgbl > 1) then 
                do ivz = nvzls, nvzle
                    coords1d(ivz-ibase) = zglat(ivz)
#ifdef DEBUG
                    if(info_debug > 0) then
                        ivol = ivz - nvzgls + 1
                        write(idbg,'(a,1x,i6,3(1x,a,1x,e13.6))')       &
                                "ivol_l", ivol,                        &
                                "xg", r0,                              &
                                "yg", r0,                              &
                                "zg", coords1d(ivz-ibase)
                    end if
#endif
                end do  
            end if            

            call DMDAVecRestoreArrayF90(cda,gc,coords1d,ierr)
            CHKERRQ(ierr)
            
        case (2)
            
            call DMDASetUniformCoordinates(dmda_flow%da,               &
                    0.0d0,1.0d0,0.0d0,1.0d0,                           &
                    PETSC_NULL_INTEGER,PETSC_NULL_INTEGER,ierr)
            CHKERRQ(ierr)
            call DMGetCoordinateDM(dmda_flow%da,cda,ierr)
            CHKERRQ(ierr)
            call DMGetCoordinatesLocal(dmda_flow%da,gc,ierr)
            CHKERRQ(ierr)
            call DMDAVecGetArrayF90(cda,gc,coords2d,ierr)
            CHKERRQ(ierr)
            
            !Please note the index is 0-based
#ifdef DEBUG
            if(info_debug > 0) then
                istart1 = lbound(coords2d,1)
                iend1 = ubound(coords2d,1)  
            
                istart2 = lbound(coords2d,2)
                iend2 = ubound(coords2d,2) 
            
                istart3 = lbound(coords2d,3)
                iend3 = ubound(coords2d,3)
            
                write(idbg,'(a/,6(a,1x,i10,1x))')                      &
                      "set the coordinates 2 dim",                     &
                      "start1",istart1,"end1",iend1,                   &
                      "start2",istart2,"end2",iend2,                   &
                      "start3",istart3,"end3",iend3  
            end if
#endif
                                                                       
            ibase = 1 
            ivol = 1
                                                                       
            !2D xy domain                                              
            if (nvxgbl > 1 .and. nvygbl > 1) then                      
                do ivy = nvyls,nvyle                                   
                    do ivx = nvxls,nvxle                               
                        coords2d(1-ibase,ivx-ibase,ivy-ibase)          &
                            = xglat(ivx)                                 
                        coords2d(2-ibase,ivx-ibase,ivy-ibase)          &
                            = yglat(ivy)
#ifdef DEBUG
                        if(info_debug > 0) then
                          ivol = (ivy-nvygls)*nvxgl + ivx - nvxgls + 1   
                          write(idbg,'(a,1x,i6,3(1x,a,1x,e13.6))')     &
                               "ivol_l", ivol,                         &
                               "xg", coords2d(1-ibase,ivx-ibase,       &
                                              ivy-ibase),              &
                               "yg", coords2d(2-ibase,ivx-ibase,       &
                                              ivy-ibase),              &
                               "zg", r0 
                        end if
#endif
                    end do
                end do
            !2D yz domain    
            else if (nvygbl > 1 .and. nvzgbl > 1) then                  
                do ivz = nvzls, nvzle
                    do ivy = nvyls,nvyle
                        coords2d(1-ibase,ivy-ibase,ivz-ibase)          &
                            = yglat(ivy)                               
                        coords2d(2-ibase,ivy-ibase,ivz-ibase)          &
                            = zglat(ivz)   
#ifdef DEBUG
                        if(info_debug > 0) then
                          ivol = (ivz-nvzgls)*nvygl + ivy-nvygls+1   
                          write(idbg,'(a,1x,i6,3(1x,a,1x,e13.6))')     &
                               "ivol_l", ivol,                         &
                               "xg", r0,                               &
                               "yg", coords2d(1-ibase,ivy-ibase,       &
                                              ivz-ibase),              &
                               "zg", coords2d(2-ibase,ivy-ibase,       &
                                              ivz-ibase) 
                        end if
#endif
                    end do                                             
                end do                                                 
            !2D xz domain                                              
            else if (nvzgbl > 1 .and. nvxgbl > 1) then                   
                do ivz = nvzls, nvzle                                  
                    do ivx = nvxls,nvxle                               
                        coords2d(1-ibase,ivx-ibase,ivz-ibase)          &
                            = xglat(ivx)                               
                        coords2d(2-ibase,ivx-ibase,ivz-ibase)          &
                            = zglat(ivz)
#ifdef DEBUG
                        if(info_debug > 0) then
                          ivol = (ivz-nvzgls)*nvxgl + ivx-nvxgls+1  
                          write(idbg,'(a,1x,i6,3(1x,a,1x,e13.6))')     &
                               "ivol_l", ivol,                         &
                               "xg", coords2d(1-ibase,ivx-ibase,       &
                                              ivz-ibase),              &
                               "yg", r0,                               &
                               "zg", coords2d(2-ibase,ivx-ibase,       &
                                              ivz-ibase)
                        end if
#endif
                    end do
                end do
                
            end if            

            call DMDAVecRestoreArrayF90(cda,gc,coords2d,ierr)
            CHKERRQ(ierr)
            
        case (3) 
            
            call DMDASetUniformCoordinates(dmda_flow%da,               &
                    0.0d0,1.0d0,0.0d0,1.0d0,0.0d0,1.0d0,ierr)
            CHKERRQ(ierr)
            call DMGetCoordinateDM(dmda_flow%da,cda,ierr)
            CHKERRQ(ierr)
            call DMGetCoordinatesLocal(dmda_flow%da,gc,ierr)
            CHKERRQ(ierr)
            call DMDAVecGetArrayF90(cda,gc,coords3d,ierr)
            CHKERRQ(ierr)
        
            !Please note the index is 0-based
#ifdef DEBUG
            if(info_debug > 0) then
                istart1 = lbound(coords3d,1)
                iend1 = ubound(coords3d,1)  
            
                istart2 = lbound(coords3d,2)
                iend2 = ubound(coords3d,2) 
            
                istart3 = lbound(coords3d,3)
                iend3 = ubound(coords3d,3) 
            
                istart4 = lbound(coords3d,4)
                iend4 = ubound(coords3d,4) 
        
                write(idbg,'(a/,8(a,1x,i10,1x))')                      &
                      "set the coordinates 3 dim",                     &
                      "start1",istart1,"end1",iend1,                   &
                      "start2",istart2,"end2",iend2,                   &
                      "start3",istart3,"end3",iend3,                   &
                      "start4",istart4,"end4",iend4
            end if
#endif
        
            ibase = 1
            do ivz = nvzls,nvzle
                do ivy = nvyls,nvyle
                    do ivx = nvxls,nvxle
                        coords3d(1-ibase,ivx-ibase,ivy-ibase,ivz-ibase)& 
                            = xglat(ivx)
                        coords3d(2-ibase,ivx-ibase,ivy-ibase,ivz-ibase)&
                            = yglat(ivy)
                        coords3d(3-ibase,ivx-ibase,ivy-ibase,ivz-ibase)&
                            = zglat(ivz)
#ifdef DEBUG
                        if(info_debug > 0) then
                          ivol = (ivz-nvzgls)*nvygl*nvxgl +            &
                                 (ivy-nvygls)*nvxgl + ivx-nvxgls+1   
                          write(idbg,'(a,1x,i6,3(1x,a,1x,e13.6))')     & 
                                  "ivol_l", ivol,                      &
                                  "xg", coords3d(1-ibase,ivx-ibase,    &
                                           ivy-ibase,ivz-ibase),       &
                                  "yg", coords3d(2-ibase,ivx-ibase,    &
                                           ivy-ibase,ivz-ibase),       &
                                  "zg", coords3d(3-ibase,ivx-ibase,    &
                                           ivy-ibase,ivz-ibase)
                        end if
#endif
                    end do
                end do
            end do
            
            call DMDAVecRestoreArrayF90(cda,gc,coords3d,ierr)
            CHKERRQ(ierr)
            
        end select
        
        call DMGetCoordinates(dmda_flow%da,global,ierr)
        CHKERRQ(ierr)
        call DMLocalToGlobalBegin(cda,gc,INSERT_VALUES,global,ierr)
        CHKERRQ(ierr)
        call DMLocalToGlobalEnd(cda,gc,INSERT_VALUES,global,ierr)
        CHKERRQ(ierr)
        call DMRestoreLocalVector(cda,gc,ierr)
        CHKERRQ(ierr)

    end subroutine
    
    
    !> get DMDA coordinates
    subroutine solver_dd_coordinates_get
    
        use gen, only: idbg, nvxgbl, nvygbl, nvzgbl, nvxls, nvxle,     &
                       nvyls, nvyle, nvzls, nvzle, nvxgls, nvxgle,     &
                       nvygls, nvygle, nvzgls, nvzgle,                 &
                       nvxgl, nvygl, nvzgl, node_idx_lg2g
    
        implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#include <petsc/finclude/petscvec.h>
#include <petsc/finclude/petscdmdef.h>
#include <petsc/finclude/petscdm.h>
#include <petsc/finclude/petscdmda.h>
#include <petsc/finclude/petscdmda.h90>
#elif PETSC
#include <finclude/petscsys.h>
#include <finclude/petscvec.h>
#include <finclude/petscdmdef.h>
#include <finclude/petscdm.h>
#include <finclude/petscdmda.h>
#include <finclude/petscdmda.h90>
#endif
        
        PetscErrorCode :: ierr
        
        PetscScalar, pointer :: coords1d(:)
        !DMDACoor2d, pointer :: coords2d(:,:)
        !DMDACoor3d, pointer :: coords3d(:,:,:) 
        !Note: There is no DMDACoor2d or 3d in Fortran (maybe added later), 
        !should use PetscScalar instead. 
        !The first index is 0, 1 or 2 for the x, y, or z coordinate
        PetscScalar, pointer :: coords2d(:,:,:) 
        PetscScalar, pointer :: coords3d(:,:,:,:)   
        Vec :: gc
        DM :: cda
        PetscInt :: i, ivol, ivx, ivy, ivz, istart1, iend1,            &
                    istart2, iend2, istart3, iend3, istart4, iend4,    &
                    ibase
        PetscReal :: r0
        PetscReal :: lmin(3), lmax(3)
        PetscReal :: gmin(3), gmax(3)        
       
        PetscInt :: info_debug
        
        parameter (r0 = 0.0d0)
        
        info_debug = 0
        
        !Initialize coordinates for bounding box
        dmda_flow%xlmin = 0.0d0
        dmda_flow%xlmax = 0.0d0
        dmda_flow%ylmin = 0.0d0
        dmda_flow%ylmax = 0.0d0
        dmda_flow%zlmin = 0.0d0
        dmda_flow%zlmax = 0.0d0
        dmda_flow%xlmingbl = 0.0d0
        dmda_flow%xlmaxgbl = 0.0d0
        dmda_flow%ylmingbl = 0.0d0
        dmda_flow%ylmaxgbl = 0.0d0
        dmda_flow%zlmingbl = 0.0d0
        dmda_flow%zlmaxgbl = 0.0d0        
        
        !Check coordinates
        call DMGetCoordinateDM(dmda_flow%da,cda,ierr)
        CHKERRQ(ierr)
        call DMGetCoordinates(dmda_flow%da,gc,ierr)
        CHKERRQ(ierr)
        call DMDAGetLocalBoundingBox(dmda_flow%da,lmin,lmax,ierr)
        CHKERRQ(ierr)
        call DMDAGetBoundingBox(dmda_flow%da,gmin,gmax,ierr)
        CHKERRQ(ierr)
        
        select case (dmda_flow%dim)
            
        case (1)
#ifdef DEBUG
            if(info_debug > 0) then
                write(idbg,'(2(/a/,2(a,1x,e13.6,1x)))')                &
                      "local bounding box 1 dim",                      &
                      "lmin",lmin(1),"lmax",lmax(1),                   &
                      "global bounding box 1 dim",                     & 
                      "gmin",gmin(1),"gmax",gmax(1)
            end if
#endif
            
            call DMDAVecGetArrayF90(cda,gc,coords1d,ierr)
            CHKERRQ(ierr)
        
            !Please note the index is 0-based
#ifdef DEBUG
            if(info_debug > 0) then
                istart1 = lbound(coords1d,1)
                iend1 = ubound(coords1d,1)        
        
                write(idbg,'(a/,2(a,1x,i10,1x))')                      &
                      "get the coordinates 1 dim",                     &
                      "start1",istart1,"end1",iend1
            end if
#endif
            
            ibase = 1 
            ivol = 0
            
            !1D x domain    
            if (nvxgbl > 1) then 
                dmda_flow%xlmin=lmin(1)
                dmda_flow%xlmax=lmax(1)
                
                dmda_flow%xlmingbl=gmin(1)
                dmda_flow%xlmaxgbl=gmax(1)
#ifdef DEBUG
                if(info_debug > 0) then
                    do ivx = nvxls,nvxle  
                        ivol = ivx - nvxgls + 1
                        write(idbg,'(2(a,1x,i6,1x),3(a,1x,e13.6,1x))') &
                              "ivol_l", ivol,                          &
                              "ivol_g", node_idx_lg2g(ivol),            &
                              "xg", coords1d(ivx-ibase),               &
                              "yg", r0,                                &
                              "zg", r0
                    end do
                end if
#endif
            !1D y domain
            else if (nvygbl > 1) then  
                dmda_flow%ylmin=lmin(1)
                dmda_flow%ylmax=lmax(1)
                
                dmda_flow%ylmingbl=gmin(1)
                dmda_flow%ylmaxgbl=gmax(1)
#ifdef DEBUG
                if(info_debug > 0) then
                    do ivy = nvyls,nvyle
                        ivol = ivy - nvygls + 1
                        write(idbg,'(2(a,1x,i6,1x),3(a,1x,e13.6,1x))') &
                              "ivol_l", ivol,                          &
                              "ivol_g", node_idx_lg2g(ivol),            &
                              "xg", r0,                                &
                              "yg", coords1d(ivy-ibase),               &
                              "zg", r0
                    end do
                end if
#endif
            !1D z domain
            else if (nvzgbl > 1) then 
                dmda_flow%zlmin=lmin(1)
                dmda_flow%zlmax=lmax(1)
                
                dmda_flow%zlmingbl=gmin(1)
                dmda_flow%zlmaxgbl=gmax(1)
#ifdef DEBUG
                if(info_debug > 0) then
                    do ivz = nvzls, nvzle
                        ivol = ivz - nvzgls + 1
                        write(idbg,'(2(a,1x,i6,1x),3(a,1x,e13.6,1x))') &
                              "ivol_l", ivol,                          &
                              "ivol_g", node_idx_lg2g(ivol),            &
                              "xg", r0,                                &
                              "yg", r0,                                &
                              "zg", coords1d(ivz-ibase)
                    end do  
                end if
#endif
            end if              
        
            call DMDAVecRestoreArrayF90(cda,gc,coords1d,ierr)
            CHKERRQ(ierr)
            
        case (2)
#ifdef DEBUG
            if(info_debug > 0) then
                write(idbg,'(2(/a/,4(a,1x,e13.6,1x)))')                &
                      "local bounding box 2 dim",                      &
                      "lmin",lmin(1),"lmax",lmax(1),                   &
                      "lmin",lmin(2),"lmax",lmax(2),                   &
                      "global bounding box 2 dim",                     &
                      "gmin",gmin(1),"gmax",gmax(1),                   &
                      "gmin",gmin(2),"gmax",gmax(2)
            end if
#endif
            
            call DMDAVecGetArrayF90(cda,gc,coords2d,ierr)
            CHKERRQ(ierr)
        
            !Please note the index is 0-based
#ifdef DEBUG
            if(info_debug > 0) then
                istart1 = lbound(coords2d,1)
                iend1 = ubound(coords2d,1)  
            
                istart2 = lbound(coords2d,2)
                iend2 = ubound(coords2d,2)
            
                istart3 = lbound(coords2d,3)
                iend3 = ubound(coords2d,3)
        
                write(idbg,'(a/,6(a,1x,i10,1x))')                      &
                      "get the coordinates 2 dim",                     &
                      "start1",istart1,"end1",iend1,                   &
                      "start2",istart2,"end2",iend2,                   &
                      "start3",istart3,"end3",iend3 
            end if
#endif

            ibase = 1
            ivol = 0
            
            !2D xy domain    
            if (nvxgbl > 1 .and. nvygbl > 1) then
                dmda_flow%xlmin=lmin(1)
                dmda_flow%xlmax=lmax(1)
                dmda_flow%ylmin=lmin(2)
                dmda_flow%ylmax=lmax(2)
                
                dmda_flow%xlmingbl=gmin(1)
                dmda_flow%xlmaxgbl=gmax(1)
                dmda_flow%ylmingbl=gmin(2)
                dmda_flow%ylmaxgbl=gmax(2)
#ifdef DEBUG
                if(info_debug > 0) then
                    do ivy = nvyls,nvyle
                        do ivx = nvxls,nvxle
                          ivol = (ivy-nvygls)*nvxgl + ivx-nvxgls+1 
                          write(idbg,                                  &
                               '(2(a,1x,i6,1x),3(a,1x,e13.6,1x))')     &
                               "ivol_l", ivol,                         &
                               "ivol_g", node_idx_lg2g(ivol),           &
                               "xg", coords2d(1-ibase,ivx-ibase,       &
                                              ivy-ibase),              &
                               "yg", coords2d(2-ibase,ivx-ibase,       &
                                              ivy-ibase),              &
                               "zg", r0 
                        end do
                    end do
                end if
#endif
            !2D yz domain    
            else if (nvygbl > 1 .and. nvzgbl > 1) then  
                dmda_flow%ylmin=lmin(1)
                dmda_flow%ylmax=lmax(1)
                dmda_flow%zlmin=lmin(2)
                dmda_flow%zlmax=lmax(2)
                
                dmda_flow%ylmingbl=gmin(1)
                dmda_flow%ylmaxgbl=gmax(1)
                dmda_flow%zlmingbl=gmin(2)
                dmda_flow%zlmaxgbl=gmax(2)
#ifdef DEBUG
                if(info_debug > 0) then
                    do ivz = nvzls, nvzle
                        do ivy = nvyls,nvyle   
                          ivol = (ivz-nvzgls)*nvygl + ivy-nvygls+1    
                          write(idbg,                                  &
                               '(2(a,1x,i6,1x),3(a,1x,e13.6,1x))')     &
                               "ivol_l", ivol,                         &
                               "ivol_g", node_idx_lg2g(ivol),           &
                               "xg", r0,                               &
                               "yg", coords2d(1-ibase,ivy-ibase,       &
                                              ivz-ibase),              &
                               "zg", coords2d(2-ibase,ivy-ibase,       &
                                              ivz-ibase)   
                        end do
                    end do
                end if
#endif
            !2D xz domain    
            else if (nvzgbl > 1 .and. nvxgbl > 1) then
                dmda_flow%xlmin=lmin(1)
                dmda_flow%xlmax=lmax(1)
                dmda_flow%zlmin=lmin(2)
                dmda_flow%zlmax=lmax(2)
                
                dmda_flow%xlmingbl=gmin(1)
                dmda_flow%xlmaxgbl=gmax(1)
                dmda_flow%zlmingbl=gmin(2)
                dmda_flow%zlmaxgbl=gmax(2)
#ifdef DEBUG
                if(info_debug > 0) then
                    do ivz = nvzls, nvzle
                        do ivx = nvxls,nvxle 
                          ivol = (ivz-nvzgls)*nvxgl + ivx-nvxgls+1   
                          write(idbg,                                  &
                               '(2(a,1x,i6,1x),3(a,1x,e13.6,1x))')     &
                               "ivol_l", ivol,                         &
                               "ivol_g", node_idx_lg2g(ivol),          &
                               "xg", coords2d(1-ibase,ivx-ibase,       &
                                              ivz-ibase),              &
                               "yg", r0,                               &
                               "zg", coords2d(2-ibase,ivx-ibase,       &
                                              ivz-ibase)
                        end do
                    end do
                end if
#endif
            end if
            
            call DMDAVecRestoreArrayF90(cda,gc,coords2d,ierr)
            CHKERRQ(ierr)
            
        case (3) 
#ifdef DEBUG
            if(info_debug > 0) then
                write(idbg,'(2(/a/,6(a,1x,e13.6,1x)))')                &
                      "local bounding box 3 dim",                      &
                      "lmin",lmin(1),"lmax",lmax(1),                   &
                      "lmin",lmin(2),"lmax",lmax(2),                   &
                      "lmin",lmin(3),"lmax",lmax(3),                   &
                      "global bounding box 3 dim",                     &
                      "gmin",gmin(1),"gmax",gmax(1),                   &
                      "gmin",gmin(2),"gmax",gmax(2),                   &
                      "gmin",gmin(3),"gmax",gmax(3)  
            end if
#endif
            call DMDAVecGetArrayF90(cda,gc,coords3d, ierr)
            CHKERRQ(ierr)
        
            dmda_flow%xlmin=lmin(1)
            dmda_flow%xlmax=lmax(1)
            dmda_flow%ylmin=lmin(2)
            dmda_flow%ylmax=lmax(2)
            dmda_flow%zlmin=lmin(3)
            dmda_flow%zlmax=lmax(3)
            
            dmda_flow%xlmingbl=gmin(1)
            dmda_flow%xlmaxgbl=gmax(1)
            dmda_flow%ylmingbl=gmin(2)
            dmda_flow%ylmaxgbl=gmax(2)
            dmda_flow%zlmingbl=gmin(3)
            dmda_flow%zlmaxgbl=gmax(3)
            
            !Please note the index is 0-based
#ifdef DEBUG
            if(info_debug > 0) then
                istart1 = lbound(coords3d,1)
                iend1 = ubound(coords3d,1)  
            
                istart2 = lbound(coords3d,2)
                iend2 = ubound(coords3d,2) 
            
                istart3 = lbound(coords3d,3)
                iend3 = ubound(coords3d,3) 
            
                istart4 = lbound(coords3d,4)
                iend4 = ubound(coords3d,4)
        
                write(idbg,'(a/,8(a,1x,i10,1x))')                      &
                      "get the coordinates 3 dim",                     &
                      "start1",istart1,"end1",iend1,                   &
                      "start2",istart2,"end2",iend2,                   &
                      "start3",istart3,"end3",iend3,                   &
                      "start4",istart4,"end4",iend4
            end if
#endif
            ibase = 1
            ivol = 0
#ifdef DEBUG
            if(info_debug > 0) then
                do ivz = nvzls, nvzle
                    do ivy = nvyls,nvyle
                        do ivx = nvxls,nvxle   
                          ivol = (ivz-nvzgls)*nvygl*nvxgl +            &
                                 (ivy-nvygls)*nvxgl + ivx-nvxgls+1  
                          write(idbg,                                  &
                                  '(2(a,1x,i6,1x),3(a,1x,e13.6,1x))')  &
                                  "ivol_l", ivol,                      &
                                  "ivol_g", node_idx_lg2g(ivol),       &
                                  "xg", coords3d(1-ibase,ivx-ibase,    &
                                           ivy-ibase,ivz-ibase),       &
                                  "yg", coords3d(2-ibase,ivx-ibase,    &
                                           ivy-ibase,ivz-ibase),       &
                                  "zg", coords3d(3-ibase,ivx-ibase,    &
                                           ivy-ibase,ivz-ibase)             
                        end do
                    end do
                end do
            end if
#endif
            call DMDAVecRestoreArrayF90(cda,gc,coords3d,ierr)
            CHKERRQ(ierr)
          
        end select


    end subroutine
    
  
    !> create ksp solver space for flow and reactive transport problem
    subroutine solver_dd_snes_create
    
        use gen, only: varsat_flow, reactive_transport
    
        implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
        
        PetscErrorCode :: ierr
        

        if(varsat_flow) then
            call solver_dd_snes_create_flow
        end if
        
        if(reactive_transport) then
            call solver_dd_snes_create_react 
        end if
        
    end subroutine
    
    !>
    !> mykspconverged_flow
    !> This is a user-defined routine for testing
    !> convergence of the KSP iterative solvers.
    !>  Input Parameters:
    !>    ksp   - iterative context
    !>    n     - iteration number
    !>    rnorm - 2-norm (preconditioned) residual value (may be estimated)
    !>    dummy - optional user-defined monitor context (unused here)
    subroutine mykspconverged_flow(ksp_flow,n,rnorm,flag,dummy,ierr)
    
        use gen, only : rank
    
        implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#include <petsc/finclude/petscvec.h>
#include <petsc/finclude/petscksp.h>
#elif PETSC
#include <finclude/petscsys.h>
#include <finclude/petscvec.h>
#include <finclude/petscksp.h>
#endif
        
        KSP                :: ksp_flow
        Vec                :: x_flow
        PetscErrorCode     :: ierr
        PetscInt           :: n,dummy
        KSPConvergedReason :: flag
        PetscReal          :: rnorm
        PetscReal          :: rnorm_relative
        PetscReal          :: neg_one
       
        neg_one = -1.0d0
        
        if(n == 0) then
            rnorm_init_flow = rnorm
        end if
        
        rnorm_relative = rnorm / rnorm_init_flow
       
        !Get true residual norm
        !This operation is expensive, use -ksp_norm_type unpreconditioned instead
        if(n > 0) then
            call KSPBuildSolution(ksp_flow,PETSC_NULL_OBJECT,x_flow,   &
                                  ierr)
            CHKERRQ(ierr)
            call KSPGetRhs(ksp_flow, b_flow, ierr)
            CHKERRQ(ierr)
            call KSPGetOperators(ksp_flow,a_flow,PETSC_NULL_OBJECT,    &
                                 PETSC_NULL_OBJECT, ierr)
            CHKERRQ(ierr)
            
            call calculate_norm(a_flow, x_flow, b_flow, r_flow,        &
                                rnorm_flow)
            
        else
            rnorm_flow = 1.0d30
        end if

        if (n > 0 .and. (rnorm_flow < abstol_flow .or.                 &
            rnorm_relative < rtol_flow)) then
          flag = 1
#ifdef DEBUG
          if(rank == 0) then
              if(rnorm_flow < abstol_flow .and.                        &
                      rnorm_relative < rtol_flow) then
                  write(*,'(2(1x, a, 1x, e15.7))')                     &
                        "KSP converged due to abstol", rnorm_flow,     &
                        "and rstol", rnorm_relative
              else if (rnorm_flow < abstol_flow) then
                  write(*,'(1x, a, 1x, e15.7)')                        &
                        "KSP converged due to abstol", rnorm_flow
              else if (rnorm_relative < rtol_flow) then
                  write(*,'(1x, a, 1x, e15.7)')                        &
                        "KSP converged due to rstol", rnorm_relative
              end if
          end if
#endif
        else
          flag = 0
        endif
        
        ierr = 0

    end subroutine mykspconverged_flow
    
    
    !>
    !> mykspconverged_react
    !> This is a user-defined routine for testing
    !> convergence of the KSP iterative solvers.
    !>  Input Parameters:
    !>    ksp   - iterative context
    !>    n     - iteration number
    !>    rnorm - 2-norm (preconditioned) residual value (may be estimated)
    !>    dummy - optional user-defined monitor context (unused here)
    subroutine mykspconverged_react(ksp_react,n,rnorm,flag,dummy,ierr)
    
        use gen, only : rank
    
        implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#include <petsc/finclude/petscvec.h>
#include <petsc/finclude/petscksp.h>
#elif PETSC
#include <finclude/petscsys.h>
#include <finclude/petscvec.h>
#include <finclude/petscksp.h>
#endif
        
        KSP                :: ksp_react
        Vec                :: x_react
        PetscErrorCode     :: ierr
        PetscInt           :: n,dummy
        KSPConvergedReason :: flag
        PetscReal          :: rnorm
        PetscReal          :: rnorm_relative
        PetscReal          :: neg_one
       
        neg_one = -1.0d0
        
        if(n == 0) then
            rnorm_init_react = rnorm
        end if
        
        rnorm_relative = rnorm / rnorm_init_react
       
        !Get true residual norm
        !This operation is expensive, use -ksp_norm_type unpreconditioned instead
        if(n > 0) then
            call KSPBuildSolution(ksp_react,PETSC_NULL_OBJECT,x_react, &
                                  ierr)
            CHKERRQ(ierr)
            call KSPGetRhs(ksp_react, b_react, ierr)
            CHKERRQ(ierr)
            call KSPGetOperators(ksp_react,a_react,PETSC_NULL_OBJECT,  &
                                 PETSC_NULL_OBJECT, ierr)
            CHKERRQ(ierr)
            
            call calculate_norm(a_react, x_react, b_react, r_react,    &
                                rnorm_react)
            
        else
            rnorm_react = 1.0d30
        end if

        if (n > 0 .and. (rnorm_react < abstol_react .or.               &
            rnorm_relative < rtol_react)) then
          flag = 1
#ifdef DEBUG
          if(rank == 0) then
              if(rnorm_react < abstol_react .and.                      &
                      rnorm_relative < rtol_react) then
                  write(*,'(2(1x, a, 1x, e15.7))')                     &
                        "KSP converged due to abstol", rnorm_react,    &
                        "and rstol", rnorm_relative
              else if (rnorm_react < abstol_react) then
                  write(*,'(1x, a, 1x, e15.7)')                        &
                        "KSP converged due to abstol", rnorm_react
              else if (rnorm_relative < rtol_react) then
                  write(*,'(1x, a, 1x, e15.7)')                        &
                        "KSP converged due to rstol", rnorm_relative
              end if
          end if
#endif
        else
          flag = 0
        endif
        
        ierr = 0

    end subroutine mykspconverged_react
    

    !>
    !> calculate norm for the current solution
    !>
    subroutine calculate_norm(a, x, b, u, rnorm)

      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      ! passing variables
      Mat                :: a
      Vec                :: x, b, u
      PetscReal          :: rnorm
      PetscReal          :: neg_one

      ! local variables
      PetscErrorCode     :: ierr

      neg_one = -1.0d0

      rnorm = 1.0d30

      call MatMult(a, x, u, ierr)
      CHKERRQ(ierr)

      call VecAXPY(u, neg_one, b, ierr)
      CHKERRQ(ierr)

      call VecNorm(u,NORM_2,rnorm,ierr)
      CHKERRQ(ierr)

    end subroutine

    !> create petsc solver space for flow problem
    subroutine solver_dd_snes_create_flow
    
        use gen, only : nn, nngl, nngbl, rank, nprcs,                  &
                        row_idx_l2pg_vs, col_idx_l2pg_vs, iavs,        &
                        row_idx_l2pg_glob, col_idx_l2pg_glob, iaglob,  &
                        ilog, b_enable_output

        use petsc_mpi_common, only : petsc_mpi_finalize
    
        implicit none   
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#include <petsc/finclude/petscdef.h>
#elif PETSC
#include <finclude/petscsys.h>
#include <finclude/petscdef.h>
#endif

#ifdef PETSC_HAVE_MUMPS
        PetscInt  :: ival,icntl,infog34
        PetscReal :: cntl,rinfo12,rinfo13,val
#endif

        PetscErrorCode :: ierr  
        PetscInt, allocatable :: d_nnz(:)
        PetscInt, allocatable :: o_nnz(:)        
        PetscInt :: i, j, k, nndof, nngldof, nngbldof, istart, iend,   &
                    range_s, range_e, d_nz, o_nz
        
        PetscBool ::  bflag  
        MatSolverPackage :: solver_pkg_flow
        
        !> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
        !>  Create matrix data structure for Jacobian
        !> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
        !>
        !>  Note:  For the parallel case, vectors and matrices MUST be partitioned
        !>  accordingly.  When using distributed arrays (DMDAs) to create vectors,
        !>  the DMDAs determine the problem partitioning.  We must explicitly
        !>  specify the local matrix dimensions upon its creation for compatibility
        !>  with the vector distribution.
        !>
        !>  Note: Here we only approximately preallocate storage space for the
        !>  Jacobian.  See the users manual for a discussion of better techniques
        !>  for preallocating matrix memory.
        bflag = .false.
        if(bflag) then

          if(dmda_flow%dim == 1) then
              d_nz = 3
              o_nz = 3
          else if (dmda_flow%dim == 2) then
              d_nz = 5
              o_nz = 5
          else if (dmda_flow%dim == 3) then
              d_nz = 7
              o_nz = 7
          end if

          nndof = nn * dmda_flow%dof
          nngldof = nngl * dmda_flow%dof
          nngbldof = nngbl * dmda_flow%dof

          d_nz = d_nz * dmda_flow%dof
          o_nz = o_nz * dmda_flow%dof
        
        else        
          nndof = nn * dmda_flow%dof
          nngldof = nngl * dmda_flow%dof
          nngbldof = nngbl * dmda_flow%dof

          allocate(d_nnz(nndof))
          d_nnz = 0

          allocate(o_nnz(nndof))
          o_nnz = 0

          range_s = dmda_flow%range_start
          range_e = dmda_flow%range_end

          if(dmda_flow%dof == 1) then
              
            do i = 1, nngldof
                j = row_idx_l2pg_vs(i)
                if(j < 0) then
                    cycle
                end if

                j = j - range_s + 1

                istart = iavs(i)
                iend = iavs(i+1)-1
                do k = istart, iend

                    if(col_idx_l2pg_vs(k) >= range_s .and.               &
                       col_idx_l2pg_vs(k) <= range_e) then

                        d_nnz(j) = d_nnz(j) + 1
                    else
                        o_nnz(j) = o_nnz(j) + 1
                    end if
                end do

            end do

          else if(dmda_flow%dof == 2) then
              
            do i = 1, nngldof
                j = row_idx_l2pg_glob(i)
                if(j < 0) then
                    cycle
                end if

                j = j - range_s + 1

                istart = iaglob(i)
                iend = iaglob(i+1)-1
                do k = istart, iend

                    if(col_idx_l2pg_glob(k) >= range_s .and.             &
                       col_idx_l2pg_glob(k) <= range_e) then

                        d_nnz(j) = d_nnz(j) + 1
                    else
                        o_nnz(j) = o_nnz(j) + 1
                    end if
                end do

            end do
              
          end if

        end if
        
        if(bflag) then
          call MatCreateAIJ(Petsc_Comm_World,nndof,nndof,nngbldof,     &
                            nngbldof,d_nz,PETSC_NULL_INTEGER,o_nz,     &
                            PETSC_NULL_INTEGER,a_flow,ierr)
          CHKERRQ(ierr)
        else
          call MatCreateAIJ(Petsc_Comm_World, nndof,                   &
                            nndof, nngbldof, nngbldof,                 &
                            Petsc_Null_Integer, d_nnz(1:nndof),        &
                            Petsc_Null_Integer, o_nnz(1:nndof),        &
                            a_flow, ierr)
          CHKERRQ(ierr)
        end if
        
        if(.not.bflag) then
          deallocate(d_nnz)
          deallocate(o_nnz)
        end if

        !c MatOptions
#ifdef PETSC_HAVE_SUPERLU
#ifdef PETSC_V3_7_X
        if (trim(strKSPType_react) == "kspsuperlu" .or. &
            trim(strKSPType_react) == "superlu") then
          call PetscOptionsInsertString(PETSC_NULL_OBJECT,"-mat_superlu_diagpivotthresh 0.0",ierr)
          CHKERRQ(ierr)
          call PetscOptionsInsertString(PETSC_NULL_OBJECT,"-mat_superlu_dist_fact SamePattern",ierr)
          CHKERRQ(ierr)
        end if
#else
        if (trim(strKSPType_react) == "kspsuperlu" .or. &
            trim(strKSPType_react) == "superlu") then
          call PetscOptionsInsertString("-mat_superlu_diagpivotthresh 0.0",ierr)
          CHKERRQ(ierr)
          call PetscOptionsInsertString("-mat_superlu_dist_fact SamePattern",ierr)
          CHKERRQ(ierr)
        end if
#endif
#endif
        call MatSetFromOptions(a_flow,ierr)
        CHKERRQ(ierr)

        ! Create the linear solver and set various options
        !    - First, set the KSP linear operators.  Here the matrix that
        !      defines the linear system also serves as the preconditioning
        !      matrix.
        call KSPCreate(Petsc_Comm_World, ksp_flow, ierr)
        CHKERRQ(ierr)

        ! set options for flow
        call KSPAppendOptionsPrefix(ksp_flow,"flow_",ierr)
        CHKERRQ(ierr)

        call KSPSetInitialGuessNonzero(ksp_flow,                       &
                b_initial_guess_nonzero_flow, ierr)
        CHKERRQ(ierr)
        
#ifdef PETSC_V3_5_X
        if (b_reuse_preconditioner_flow) then
          if (.not.b_set_preconditioner_flow) then
            b_set_preconditioner_flow = .true.
            call MatConvert(a_flow,MATSAME,MAT_INITIAL_MATRIX,a_flow_j,&
                            ierr)
            CHKERRQ(ierr)
          end if
          call KSPSetOperators(ksp_flow,a_flow,a_flow_j,ierr)
        else
          call KSPSetOperators(ksp_flow,a_flow,a_flow,ierr)
        end if
        CHKERRQ(ierr)
#else
        if (b_reuse_preconditioner_flow) then
          if (.not.b_set_preconditioner_flow) then
            b_set_preconditioner_flow = .true.
            call MatConvert(a_flow,MATSAME,MAT_INITIAL_MATRIX,a_flow_j,&
                            ierr)
            CHKERRQ(ierr)
          end if
          call KSPSetOperators(ksp_flow,a_flow,a_flow_j,               &
                               SAME_NONZERO_PATTERN,ierr)
        else
          call KSPSetOperators(ksp_flow,a_flow,a_flow,                 &
                               SAME_NONZERO_PATTERN,ierr)
        end if
        CHKERRQ(ierr)
#endif
        call KSPSetDM(ksp_flow,dmda_flow%da,ierr)
        CHKERRQ(ierr)
        call KSPSetDMActive(ksp_flow,PETSC_FALSE,ierr)
        CHKERRQ(ierr)

        !c set convergence tolerance

        b_recal_norm_flow = .false.

        if(.not. b_use_petsc_default_flow) then

          if (trim(strKSPConvergenceType_flow) == "kspuserdefined" .or.&
              trim(strKSPConvergenceType_flow) == "userdefined") then
              b_mykspconverged_flow = .true.
              call KSPSetConvergenceTest(ksp_flow,mykspconverged_flow, &
                   PETSC_NULL_OBJECT,PETSC_NULL_FUNCTION,ierr)
              CHKERRQ(ierr)
          else
              b_mykspconverged_flow = .false.
          end if

          !Set linear solver defaults for this problem (optional).
          call KSPSetTolerances(ksp_flow, rtol_flow, abstol_flow,      &
                                dtol_flow, maxits_flow, ierr)
          CHKERRQ(ierr)

          if (rank == 0 .and. b_enable_output) then
            write(*,'(a)') "PETSc convergence parameters for flow"
            write(*,'(3a14,a7)') "rtol","abstol","dtol","maxits"
            write(*,'(3(1x,e13.6),1x,i6)') rtol_flow,abstol_flow,      &
                                        dtol_flow,maxits_flow

            write(ilog,'(a)')"PETSc convergence parameters for flow"
            write(ilog,'(3a14,a7)') "rtol","abstol","dtol","maxits"
            write(ilog,'(3(1x,e13.6),1x,i6)') rtol_flow,abstol_flow,   &
                                        dtol_flow,maxits_flow
          end if

        end if

        !c set KSP options
        if(.not. b_use_petsc_default_flow) then

#ifdef PETSC_HAVE_MUMPS
          if (trim(strKSPType_flow) == "kspmumps" .or. &
            trim(strKSPType_flow) == "mumps") then
            call KSPSetType(ksp_flow, KSPPREONLY, ierr)
            CHKERRQ(ierr)
            b_recal_norm_flow = .true.
            goto 101
          end if
#endif

#ifdef PETSC_HAVE_SUPERLU
          if (trim(strKSPType_flow) == "kspsuperlu" .or. &
            trim(strKSPType_flow) == "superlu") then
            call KSPSetType(ksp_flow, KSPPREONLY, ierr)
            CHKERRQ(ierr)
            b_recal_norm_flow = .true.
            goto 101
          end if
#endif

          if (trim(strKSPType_flow) == "kspgmres" .or. &
              trim(strKSPType_flow) == "gmres") then
            call KSPSetType(ksp_flow, KSPGMRES, ierr)
            CHKERRQ(ierr)
            goto 101
          else if (trim(strKSPType_flow) == "kspbcgs" .or. &
                   trim(strKSPType_flow) == "bcgs") then
            call KSPSetType(ksp_flow, KSPBCGS, ierr)
            CHKERRQ(ierr)
            goto 101
          else
            call KSPSetType(ksp_flow, KSPGMRES, ierr)
            CHKERRQ(ierr)
            goto 101
          end if

        end if

101     continue

        !c set PC options
        if(.not. b_use_petsc_default_flow) then

          call KSPGetPC(ksp_flow, pc_flow, ierr)
          CHKERRQ(ierr)

#ifdef PETSC_HAVE_MUMPS
          if (trim(strKSPType_flow) == "kspmumps" .or. &
            trim(strKSPType_flow) == "mumps") then

            !c force pctype to pclu for mumps solver
            call PCSetType(pc_flow,PCLU, ierr)
            CHKERRQ(ierr)

            call PCFactorSetMatSolverPackage(pc_flow,MATSOLVERMUMPS,ierr)
            CHKERRQ(ierr)

            call PCFactorSetUpMatSolverPackage(pc_flow,ierr)
            CHKERRQ(ierr)

            call PCFactorGetMatrix(pc_flow,a_flow_fac,ierr)
            CHKERRQ(ierr)

            goto 201

          end if
#endif

#ifdef PETSC_HAVE_SUPERLU
          if (trim(strKSPType_flow) == "kspsuperlu" .or. &
            trim(strKSPType_flow) == "superlu") then

            !c force pctype to pclu for superlu_dist solver
            call PCSetType(pc_flow,PCLU, ierr)
            CHKERRQ(ierr)

            call PCFactorSetMatSolverPackage(pc_flow,MATSOLVERSUPERLU_DIST,ierr)
            CHKERRQ(ierr)

            call PCFactorSetUpMatSolverPackage(pc_flow,ierr)
            CHKERRQ(ierr)

            call PCFactorGetMatrix(pc_flow,a_flow_fac,ierr)
            CHKERRQ(ierr)

            goto 201

          end if
#endif

          if(trim(strPCType_flow) == "pcnone" .or. &
             trim(strPCType_flow) == "none") then
              call PCSetType(pc_flow,PCNONE, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_flow) == "pcjacobi" .or. &
             trim(strPCType_flow) == "jacobi") then
              call PCSetType(pc_flow,PCJACOBI, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_flow) == "pclu" .or. &
             trim(strPCType_flow) == "lu") then
              call PCSetType(pc_flow,PCLU, ierr)
              CHKERRQ(ierr)

           else if(trim(strPCType_flow) == "pcbjacobi" .or. &
             trim(strPCType_flow) == "bjacobi") then
              call PCSetType(pc_flow,PCBJACOBI, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_flow) == "pcilu" .or. &
             trim(strPCType_flow) == "ilu") then
              call PCSetType(pc_flow,PCILU, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_flow) == "pcasm" .or. &
             trim(strPCType_flow) == "asm") then
              call PCSetType(pc_flow,PCASM, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_flow) == "pcksp" .or. &
             trim(strPCType_flow) == "ksp") then
              call PCSetType(pc_flow,PCKSP, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_flow) == "pchypre" .or. &
             trim(strPCType_flow) == "hypre") then
              call PCSetType(pc_flow,PCHYPRE, ierr)
              CHKERRQ(ierr)

          else
              call PCSetType(pc_flow,PCBJACOBI, ierr)
              CHKERRQ(ierr)
          end if
          

          if ((trim(strKSPType_flow) /= "kspmumps"   .and.  &
              trim(strKSPType_flow) /= "mumps"       .and.  &
              trim(strKSPType_flow) /= "kspsuperlu"  .and.  &
              trim(strKSPType_flow) /= "superlu")    .and.  &
              (trim(strPCType_flow) == "pcilu"       .or.   &
              trim(strPCType_flow) == "ilu"          .or.   &
              trim(strPCType_flow) == "pclu"         .or.   &
              trim(strPCType_flow) == "lu")          .and.  &
              nprcs > 1) then
              if(rank == 0) then
                write(*,'(5a,i4,a)') "Error: PCTYPE ",              &
                      trim(strPCType_flow)," is not supported for ",&
                      trim(strKSPType_flow)," using ", nprcs,       &
                      " processors"
                write(ilog,'(5a,i4,a)') "Error: PCTYPE ",           &
                      trim(strPCType_flow)," is not supported for ",&
                      trim(strKSPType_flow)," using ", nprcs,       &
                      " processors"
              end if
              call petsc_mpi_finalize
              stop
          end if

        end if

201     continue
        
        !c check solver package if not from configuration file
        call KSPGetPC(ksp_flow, pc_flow, ierr)
        CHKERRQ(ierr)
        
        call PCFactorGetMatSolverPackage(pc_flow,solver_pkg_flow,ierr)
        CHKERRQ(ierr)
        
        if (solver_pkg_flow == "superlu" .or.                   &
            solver_pkg_flow == "superlu_dist" .or.              &
            solver_pkg_flow == "mumps" .or.                     &
            solver_pkg_flow == "mkl_pardiso" .or.               &
            solver_pkg_flow == "mkl_cpardiso") then
          b_recal_norm_flow = .true. 
        else
          b_check_norm_flow = .false.
        end if

        !> If not doing matrix free then matrix operator and matrix used
        !> to construct preconditioner are the same
        !a_flow_j = a_flow
    
    end subroutine
    
    !> solve petsc solver space for flow problem
    subroutine solver_dd_snes_solve_flow(ilog,idetail,a_in,b_in,       &
                      x_inout,ia_in,ja_in,nngl_in,itsolv,              &
                      over_flow,rnorm,row_idx_l2pg,col_idx_l2pg,       &
                      b_non_interlaced)
    
        use gen, only : rank, node_idx_l2lg, ittot_vs, ittotglob,      &
                        b_output_matrix_petsc, b_enable_output,        &
                        itimestep_output_matrix, mtime
        use solver_snes_function, only : form_initial_guess,           & 
                                         compute_function,             &
                                         compute_jacobian
        use petsc_mpi_common, only : petsc_mpi_finalize
        
        implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#include <petsc/finclude/petscvec.h>
#include <petsc/finclude/petscvec.h90>
#include <petsc/finclude/petscdmda.h>
#include <petsc/finclude/petscviewer.h>
#include <petsc/finclude/petscviewer.h90>
#include <petsc/finclude/petscksp.h>
#elif PETSC
#include <finclude/petscsys.h>
#include <finclude/petscvec.h>
#include <finclude/petscvec.h90>
#include <finclude/petscdmda.h>
#include <finclude/petscviewer.h>
#include <finclude/petscviewer.h90>
#include <finclude/petscksp.h>
#endif


#ifdef PETSC_HAVE_MUMPS
        PetscInt  :: ival,icntl,infog34
        PetscReal :: cntl,rinfo12,rinfo13,val
#endif

        PetscInt :: ilog
        PetscInt :: idetail
        PetscInt :: nngl_in
        PetscInt :: ilocal
        PetscInt :: nlocal
        PetscReal, allocatable :: a_in(:)
        PetscReal, allocatable :: b_in(:)
        PetscReal, allocatable :: x_inout(:)
        PetscInt, allocatable  :: ia_in(:)
        PetscInt, allocatable  :: ja_in(:)
        PetscInt, allocatable :: row_idx_l2pg(:)
        PetscInt, allocatable :: col_idx_l2pg(:)
        PetscInt  :: itsolv
        PetscBool :: over_flow
        PetscBool :: b_non_interlaced
        PetscReal :: rnorm
        
        PetscViewer :: viewer        
        PetscScalar,pointer :: vecpointer(:)


        PC :: subpc_flow
        KSP :: subksp_flow(100)         !This is just pointer, just make the array big enough,
                                        !by default, is 1 for each processor
        PetscBool :: b_pc_factor_shift_flow
        
        PetscErrorCode :: ierr
        PetscInt :: i, j, info_debug     
        character(72) :: strinum
        
        info_debug = 0

        over_flow = .false.
      
        if(b_enable_output .and. (b_output_matrix_petsc .or.           &
           itimestep_output_matrix==mtime)) then
            if(ittot_vs > 0) then
                write(strinum, *) ittot_vs
            else
                write(strinum, *) ittotglob
            end if
            strinum = "_"//trim(adjustl(strinum))
        end if
                
        !Form initial guess X, only assemble the local owned part, without ghost nodes
        if (b_form_initial_guess_flow) then
          call form_initial_guess(rank,dmda_flow%da,x_inout,x_flow_loc,&
                    x_flow,nngl_in,row_idx_l2pg,col_idx_l2pg,          &
                    b_non_interlaced)

          if(b_output_matrix_petsc .and. b_enable_output) then
            if(nngl_in <= 1024 .and. nngl_in < n_binary_limit) then
              call PetscViewerASCIIOpen(Petsc_Comm_World,              &
                        "x_flow_in"//trim(strinum)//".txt",viewer,ierr)
              CHKERRQ(ierr)
            else
              call PetscViewerBinaryOpen(Petsc_Comm_World,             &
                        "x_flow_in"//trim(strinum)//".bin",            &
                        FILE_MODE_WRITE, viewer,ierr)
              CHKERRQ(ierr)
            end if
            call VecView(x_flow, viewer, ierr)
            CHKERRQ(ierr)
            call PetscViewerDestroy(viewer, ierr)
            CHKERRQ(ierr)
          end if

        end if
        
        !Compute function B, only assemble the local part, without ghost nodes
        call compute_function(rank,dmda_flow%da,b_in,b_flow_loc,       &
                     b_flow,nngl_in,row_idx_l2pg,col_idx_l2pg,         &
                     b_non_interlaced)

        if(b_enable_output .and. (b_output_matrix_petsc .or.           &
           itimestep_output_matrix==mtime)) then
          if(nngl_in <= 1024 .and. nngl_in < n_binary_limit) then
            call PetscViewerASCIIOpen(Petsc_Comm_World,                &
                      "b_flow_in"//trim(strinum)//".txt",viewer,ierr)
            CHKERRQ(ierr)
          else
            call PetscViewerBinaryOpen(Petsc_Comm_World,               &
                      "b_flow_in"//trim(strinum)//".bin",              &
                      FILE_MODE_WRITE, viewer,ierr)
            CHKERRQ(ierr)
          end if
          call VecView(b_flow, viewer, ierr)
          CHKERRQ(ierr)
          call PetscViewerDestroy(viewer, ierr)
          CHKERRQ(ierr)
        end if

!!cdsu  debug part, write matrix in petsc binary format
!        if(ittot_vs > 0) then
!            write(strinum, *) ittot_vs
!        else
!            write(strinum, *) ittotglob
!        end if
!        strinum = "_"//trim(adjustl(strinum))
!
!        if (mtime == 1 .or. mtime == 22) then
!          call PetscViewerBinaryOpen(Petsc_Comm_World,               &
!                    "b_flow_check"//trim(strinum)//".bin",              &
!                      FILE_MODE_WRITE, viewer,ierr)
!          CHKERRQ(ierr)
!          call VecView(b_flow, viewer, ierr)
!          CHKERRQ(ierr)
!          call PetscViewerDestroy(viewer, ierr)
!          CHKERRQ(ierr)
!        end if
!cdsu  debug part, write matrix in petsc binary format,end

        !Check if the initial residual norm to see if it meets the convergence
        call VecNormBegin(b_flow, Norm_2, rnorm, ierr)
        CHKERRQ(ierr)
        call VecNormEnd(b_flow, Norm_2, rnorm, ierr)
        CHKERRQ(ierr)
        if(rnorm < 1.0d-300) then
            if(idetail > 1 .and. rank == 0 .and. b_enable_output) then
                write(ilog,100)
            end if
            itsolv = 0
            return
        end if


        !Compute jacobian matrix A, only assemble the local part, without ghost nodes
        call compute_jacobian(rank,dmda_flow%da,                       &
                              a_flow,a_in,ia_in,ja_in,nngl_in,         &
                              row_idx_l2pg,col_idx_l2pg,               &
                              b_non_interlaced)

        if(b_enable_output .and. (b_output_matrix_petsc .or.           &
           itimestep_output_matrix==mtime)) then
          if(nngl_in <= 1024 .and. nngl_in < n_binary_limit) then
            call PetscViewerASCIIOpen(Petsc_Comm_World,                &
                      "a_flow_in"//trim(strinum)//".txt",viewer,ierr)
            CHKERRQ(ierr)
          else
            call PetscViewerBinaryOpen(Petsc_Comm_World,               &
                      "a_flow_in"//trim(strinum)//".bin",              &
                      FILE_MODE_WRITE, viewer,ierr)
            CHKERRQ(ierr)
          end if
          call MatView(a_flow, viewer, ierr)
          CHKERRQ(ierr)
          call PetscViewerDestroy(viewer, ierr)
          CHKERRQ(ierr)
        end if

!cdsu  debug part, write matrix in petsc binary format
!        if (mtime == 1 .or. mtime == 22) then
!          call PetscViewerBinaryOpen(Petsc_Comm_World,               &
!                    "a_flow_check"//trim(strinum)//".bin",              &
!                    FILE_MODE_WRITE, viewer,ierr)
!          CHKERRQ(ierr)
!          call MatView(a_flow, viewer, ierr)
!          CHKERRQ(ierr)
!          call PetscViewerDestroy(viewer, ierr)
!          CHKERRQ(ierr)
!        end if
!cdsu  debug part, write matrix in petsc binary format,end

        !> Set runtime options (e.g., -ksp_monitor -ksp_rtol <rtol> -ksp_type <type>)
        !> Set different options prefix for linear system of flow.
        !> Set runtime options (e.g., -flow_pc_type <type>)
        call KSPSetFromOptions(ksp_flow,ierr)
        CHKERRQ(ierr)

        call KSPSetUp(ksp_flow,ierr)
        CHKERRQ(ierr)

        !c set PC options
        if(.not. b_use_petsc_default_flow) then

          if (trim(strKSPType_flow) == "kspgmres" .or. &
              trim(strKSPType_flow) == "gmres" .or.    &
              trim(strKSPType_flow) == "kspbcgs" .or.  &
              trim(strKSPType_flow) == "bcgs") then

            call KSPGetPC(ksp_flow, pc_flow, ierr)
            CHKERRQ(ierr)

            b_pc_factor_shift_flow = .true.

            !c Extract the array of KSP contexts for the local blocks 
            if(trim(strPCType_flow) == "pcbjacobi" .or. &
               trim(strPCType_flow) == "bjacobi") then
              call PCBJacobiGetSubKSP(pc_flow,nlocal,PETSC_NULL_INTEGER,subksp_flow,ierr)
              CHKERRQ(ierr)
            else if(trim(strPCType_flow) == "pcasm" .or. &
                    trim(strPCType_flow) == "asm") then
              call PCASMGetSubKSP(pc_flow,nlocal,PETSC_NULL_INTEGER,subksp_flow,ierr)
              CHKERRQ(ierr)
            else
              b_pc_factor_shift_flow = .false.
            end if

            if (b_pc_factor_shift_flow) then

              if (trim(pc_factor_shift_flow) == "none") then
                do ilocal = 1, nlocal
                  call KSPGetPC(subksp_flow(ilocal),subpc_flow,ierr)
                  CHKERRQ(ierr)
                  call PCFactorSetShiftType(subpc_flow,MAT_SHIFT_NONE, ierr)
                  CHKERRQ(ierr)
                end do
              else if (trim(pc_factor_shift_flow) == "nonzero") then
                do ilocal = 1, nlocal
                  call KSPGetPC(subksp_flow(ilocal),subpc_flow,ierr)
                  CHKERRQ(ierr)
                  call PCFactorSetShiftType(subpc_flow,MAT_SHIFT_NONZERO, ierr)
                  CHKERRQ(ierr)
                end do
              else if (trim(pc_factor_shift_flow) == "positive_definite") then
                do ilocal = 1, nlocal
                  call KSPGetPC(subksp_flow(ilocal),subpc_flow,ierr)
                  CHKERRQ(ierr)
                  call PCFactorSetShiftType(subpc_flow,MAT_SHIFT_POSITIVE_DEFINITE, ierr)
                  CHKERRQ(ierr)
                end do
              else if (trim(pc_factor_shift_flow) == "inblocks") then
                do ilocal = 1, nlocal
                  call KSPGetPC(subksp_flow(ilocal),subpc_flow,ierr)
                  CHKERRQ(ierr)
                  call PCFactorSetShiftType(subpc_flow,MAT_SHIFT_INBLOCKS, ierr)
                  CHKERRQ(ierr)
                end do
              end if
            end if
          end if
        end if

        call KSPSetUpOnBlocks(ksp_flow,ierr)
        CHKERRQ(ierr)

        !  Solve a x = b, where a is the Jacobian matrix.
        call KSPSolve(ksp_flow,b_flow,x_flow,ierr)
        CHKERRQ(ierr)
        

        if(b_enable_output .and. (b_output_matrix_petsc .or.           &
           itimestep_output_matrix==mtime)) then
          if(nngl_in <= 1024 .and. nngl_in < n_binary_limit) then
            call PetscViewerASCIIOpen(Petsc_Comm_World,                &
                      "x_flow_out"//trim(strinum)//".txt",viewer,ierr)
            CHKERRQ(ierr)
          else
            call PetscViewerBinaryOpen(Petsc_Comm_World,               &
                      "x_flow_out"//trim(strinum)//".bin",             &
                      FILE_MODE_WRITE, viewer, ierr)
            CHKERRQ(ierr)
          end if
          call VecView(x_flow, viewer, ierr)
          CHKERRQ(ierr)
          call PetscViewerDestroy(viewer, ierr)
          CHKERRQ(ierr)
        end if  

!cdsu  debug part, write matrix in petsc binary format
!        if (mtime == 1 .or. mtime == 22) then
!          call PetscViewerBinaryOpen(Petsc_Comm_World,               &
!                    "x_flow_check"//trim(strinum)//".bin",           &
!                    FILE_MODE_WRITE, viewer, ierr)
!          CHKERRQ(ierr)
!          call VecView(x_flow, viewer, ierr)
!          CHKERRQ(ierr)
!          call PetscViewerDestroy(viewer, ierr)
!          CHKERRQ(ierr)
!        end if
!cdsu  debug part, write matrix in petsc binary format,end

       
        !  Get iteration and convergence information
        call KSPGetIterationNumber(ksp_flow,itsolv,ierr)
        CHKERRQ(ierr)

        call KSPGetErrorIfNotConverged(ksp_flow, over_flow,ierr)
        CHKERRQ(ierr)

        if(itsolv == 0) then
            over_flow = .true.
        end if
        
        !Get residual norm, by default, preconditioned residual norm is calculated.
        if (b_recal_norm_flow) then
          call calculate_norm(a_flow, x_flow, b_flow, r_flow, rnorm)
        else
          if (b_mykspconverged_flow .and.                                &
                .not. b_use_petsc_default_flow) then
            rnorm = rnorm_flow
          else
            call KSPGetResidualNorm(ksp_flow, rnorm, ierr)
            CHKERRQ(ierr)
          end if
        end if
        
        if(itsolv >= maxits_flow .and.                                 &
            (b_check_norm_flow .and. abs(rnorm)>abstol_flow)) then
            over_flow = .true.
          if(rank == 0 .and. idetail > 1) then
            write(*,'(1x,a,1x,i6,1x,a,1x,e16.8)')                      &
                  "solver failure: iteration",itsolv,"rnorm",rnorm
            write(ilog,'(1x,a,1x,i6,1x,a,1x,e16.8)')                   &
                  "solver failure: iteration",itsolv,"rnorm",rnorm
          end if
        end if

        if(over_flow) then
            return
        end if

        !  Scatter ghost points to local vector, using the 2-step process
        !     DMGlobalToLocalBegin(), DMGlobalToLocalEnd().
        !  By placing code between these two statements, computations can be
        !  done while messages are in transition. 
        call DMGlobalToLocalBegin(dmda_flow%da,x_flow,INSERT_VALUES,   &
                                  x_flow_loc,ierr)
        CHKERRQ(ierr)
        call DMGlobalToLocalEnd(dmda_flow%da,x_flow,INSERT_VALUES,     &
                                  x_flow_loc,ierr) 
        CHKERRQ(ierr)
       
        call VecGetArrayF90(x_flow_loc,vecpointer,ierr)
        CHKERRQ(ierr)
        
        if(b_non_interlaced) then
          j = nngl_in/2  
          do i = 1, j
              x_inout(i) = vecpointer(2*i-1)
              x_inout(i+j) = vecpointer(2*i)
          end do
        else
          x_inout = vecpointer
        end if
        
        call VecRestoreArrayF90(x_flow_loc,vecpointer,ierr)
        CHKERRQ(ierr)
        
#ifdef DEBUG
        if(info_debug > 1) then
            call petsc_mpi_finalize
            stop
        end if
#endif
        
100     FORMAT (/1x,'Maximum error from previous solution is less',    &
              /1x,'than the specified convergence tolerance.')
        
        return
    
    end subroutine
    
    !> create petsc solver space for reactive transport problem
    subroutine solver_dd_snes_create_react
    
        use gen, only : nn, nngl, nngbl, rank, nprcs, row_idx_l2pg_rt, &
                        col_idx_l2pg_rt, iart, ilog, b_enable_output

        use petsc_mpi_common, only : petsc_mpi_finalize
    
        implicit none   
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#include <petsc/finclude/petscdef.h>
#elif PETSC
#include <finclude/petscsys.h>
#include <finclude/petscdef.h>
#endif

#ifdef PETSC_HAVE_MUMPS
        PetscInt  :: ival,icntl,infog34
        PetscReal :: cntl,rinfo12,rinfo13,val
#endif
        
        PetscErrorCode :: ierr  
        PetscInt, allocatable :: d_nnz(:)
        PetscInt, allocatable :: o_nnz(:)        
        PetscInt :: i, j, k, nndof, nngldof, nngbldof, istart, iend,   &
                    range_s, range_e, d_nz, o_nz
        
        PetscBool ::  bflag  
        
        MatSolverPackage :: solver_pkg_react
        
        !> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
        !>  Create matrix data structure for Jacobian
        !> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
        !>
        !>  Note:  For the parallel case, vectors and matrices MUST be partitioned
        !>  accordingly.  When using distributed arrays (DMDAs) to create vectors,
        !>  the DMDAs determine the problem partitioning.  We must explicitly
        !>  specify the local matrix dimensions upon its creation for compatibility
        !>  with the vector distribution.
        !>
        !>  Note: Here we only approximately preallocate storage space for the
        !>  Jacobian.  See the users manual for a discussion of better techniques
        !>  for preallocating matrix memory.
        bflag = .false.
        if(bflag) then        

          if(dmda_react%dim == 1) then
              d_nz = 3
              o_nz = 1
          else if (dmda_react%dim == 2) then
              d_nz = 5
              o_nz = 3
          else if (dmda_react%dim == 3) then
              d_nz = 7
              o_nz = 5
          end if

          nndof = nn * dmda_react%dof
          nngldof = nngl * dmda_react%dof
          nngbldof = nngbl * dmda_react%dof

          d_nz = d_nz * dmda_react%dof
          o_nz = o_nz * dmda_react%dof
        
        else
          nndof = nn * dmda_react%dof
          nngldof = nngl * dmda_react%dof
          nngbldof = nngbl * dmda_react%dof

          !Method 2: precisely preallocating
          allocate(d_nnz(nndof))
          d_nnz = 0

          allocate(o_nnz(nndof))
          o_nnz = 0

          range_s = dmda_react%range_start
          range_e = dmda_react%range_end

          do i = 1, nngldof
              j = row_idx_l2pg_rt(i)
              if(j < 0) then
                  cycle
              end if

              j = j - range_s + 1

              istart = iart(i)
              iend = iart(i+1)-1
              do k = istart, iend

                  if(col_idx_l2pg_rt(k) >= range_s .and.                 &
                     col_idx_l2pg_rt(k) <= range_e) then

                      d_nnz(j) = d_nnz(j) + 1
                  else
                      o_nnz(j) = o_nnz(j) + 1
                  end if
              end do

          end do

        end if

        if(bflag) then
          call MatCreateAIJ(Petsc_Comm_World,nndof,nndof,nngbldof,     &
                            nngbldof,d_nz,PETSC_NULL_INTEGER,o_nz,     &
                           PETSC_NULL_INTEGER,a_react,ierr)
          CHKERRQ(ierr)
        else
          call MatCreateAIJ(Petsc_Comm_World, nndof,                   &
                            nndof, nngbldof, nngbldof,                 &
                            Petsc_Null_Integer, d_nnz(1:nndof),        &
                            Petsc_Null_Integer, o_nnz(1:nndof),        &
                            a_react, ierr)
          CHKERRQ(ierr)
        end if
        
        if(.not.bflag) then
          deallocate(d_nnz)
          deallocate(o_nnz)
        end if

        !c MatOptions
#ifdef PETSC_HAVE_SUPERLU
#ifdef PETSC_V3_7_X
        if (trim(strKSPType_react) == "kspsuperlu" .or. &
            trim(strKSPType_react) == "superlu") then
          call PetscOptionsInsertString(PETSC_NULL_OBJECT,"-mat_superlu_diagpivotthresh 0.0",ierr)
          CHKERRQ(ierr)
          call PetscOptionsInsertString(PETSC_NULL_OBJECT,"-mat_superlu_dist_fact SamePattern",ierr)
          CHKERRQ(ierr)
        end if
#else
        if (trim(strKSPType_react) == "kspsuperlu" .or. &
            trim(strKSPType_react) == "superlu") then
          call PetscOptionsInsertString("-mat_superlu_diagpivotthresh 0.0",ierr)
          CHKERRQ(ierr)
          call PetscOptionsInsertString("-mat_superlu_dist_fact SamePattern",ierr)
          CHKERRQ(ierr)
        end if
#endif
#endif
        call MatSetFromOptions(a_react,ierr)
        CHKERRQ(ierr)

        ! Create the linear solver and set various options
        !    - First, set the KSP linear operators.  Here the matrix that
        !      defines the linear system also serves as the preconditioning
        !      matrix.
        call KSPCreate(Petsc_Comm_World, ksp_react, ierr)
        CHKERRQ(ierr)

        ! Set options for reactive transport
        call KSPAppendOptionsPrefix(ksp_react,"react_",ierr)
        CHKERRQ(ierr)

        call KSPSetInitialGuessNonzero(ksp_react,                       &
                b_initial_guess_nonzero_react, ierr)
        CHKERRQ(ierr)
        
#ifdef PETSC_V3_5_X
        if (b_reuse_preconditioner_react) then
          if (.not.b_set_preconditioner_react) then
            b_set_preconditioner_react = .true.
            call MatConvert(a_react,MATSAME,MAT_INITIAL_MATRIX,a_react_j,&
                            ierr)
            CHKERRQ(ierr)
          end if
          call KSPSetOperators(ksp_react,a_react,a_react_j,ierr)
        else
          call KSPSetOperators(ksp_react,a_react,a_react,ierr)
        end if
        CHKERRQ(ierr)
#else
        if (b_reuse_preconditioner_react) then
          if (.not.b_set_preconditioner_react) then
            b_set_preconditioner_react = .true.
            call MatConvert(a_react,MATSAME,MAT_INITIAL_MATRIX,a_react_j,&
                            ierr)
            CHKERRQ(ierr)
          end if
          call KSPSetOperators(ksp_react,a_react,a_react_j,               &
                               SAME_NONZERO_PATTERN,ierr)
        else
          call KSPSetOperators(ksp_react,a_react,a_react,                 &
                               SAME_NONZERO_PATTERN,ierr)
        end if
        CHKERRQ(ierr)
#endif
        call KSPSetDM(ksp_react,dmda_react%da,ierr)
        CHKERRQ(ierr)
        call KSPSetDMActive(ksp_react,PETSC_FALSE,ierr)
        CHKERRQ(ierr)

        !c set convergence tolerance
        b_recal_norm_react = .false.
        if(.not. b_use_petsc_default_react) then

          if (trim(strKSPConvergenceType_react) == "kspuserdefined" .or.&
              trim(strKSPConvergenceType_react) == "userdefined") then
              b_mykspconverged_react = .true.
              call KSPSetConvergenceTest(ksp_react,mykspconverged_react, &
                   PETSC_NULL_OBJECT,PETSC_NULL_FUNCTION,ierr)
              CHKERRQ(ierr)
          else
              b_mykspconverged_react = .false.
          end if

          !Set linear solver defaults for this problem (optional).
          call KSPSetTolerances(ksp_react, rtol_react, abstol_react,      &
                                dtol_react, maxits_react, ierr)
          CHKERRQ(ierr)

          if (rank == 0 .and. b_enable_output) then
            write(*,'(a)') "PETSc convergence parameters for reactive transport"
            write(*,'(3a14,a7)') "rtol","abstol","dtol","maxits"
            write(*,'(3(1x,e13.6),1x,i6)') rtol_react,abstol_react,      &
                                        dtol_react,maxits_react

            write(ilog,'(a)')"PETSc convergence parameters for reactive"
            write(ilog,'(3a14,a7)') "rtol","abstol","dtol","maxits"
            write(ilog,'(3(1x,e13.6),1x,i6)') rtol_react,abstol_react,   &
                                        dtol_react,maxits_react
          end if

        end if

        !c set KSP options
        if(.not. b_use_petsc_default_react) then

#ifdef PETSC_HAVE_MUMPS
          if (trim(strKSPType_react) == "kspmumps" .or. &
            trim(strKSPType_react) == "mumps") then
            call KSPSetType(ksp_react, KSPPREONLY, ierr)
            CHKERRQ(ierr)
            b_recal_norm_react = .true.
            goto 101
          end if
#endif

#ifdef PETSC_HAVE_SUPERLU
          if (trim(strKSPType_react) == "kspsuperlu" .or. &
            trim(strKSPType_react) == "superlu") then
            call KSPSetType(ksp_react, KSPPREONLY, ierr)
            CHKERRQ(ierr)
            b_recal_norm_react = .true.
            goto 101
          end if
#endif

          if (trim(strKSPType_react) == "kspgmres" .or. &
              trim(strKSPType_react) == "gmres") then
            call KSPSetType(ksp_react, KSPGMRES, ierr)
            CHKERRQ(ierr)
            goto 101
          else if (trim(strKSPType_react) == "kspbcgs" .or. &
                   trim(strKSPType_react) == "bcgs") then
            call KSPSetType(ksp_react, KSPBCGS, ierr)
            CHKERRQ(ierr)
            goto 101
          else
            call KSPSetType(ksp_react, KSPGMRES, ierr)
            CHKERRQ(ierr)
            goto 101
          end if

        end if

101     continue

        !c set PC options
        if(.not. b_use_petsc_default_react) then

          call KSPGetPC(ksp_react, pc_react, ierr)
          CHKERRQ(ierr)

#ifdef PETSC_HAVE_MUMPS
          if (trim(strKSPType_react) == "kspmumps" .or. &
            trim(strKSPType_react) == "mumps") then

            !c force pctype to pclu for mumps solver
            call PCSetType(pc_react,PCLU, ierr)
            CHKERRQ(ierr)

            call PCFactorSetMatSolverPackage(pc_react,MATSOLVERMUMPS,ierr)
            CHKERRQ(ierr)

            call PCFactorSetUpMatSolverPackage(pc_react,ierr)
            CHKERRQ(ierr)

            call PCFactorGetMatrix(pc_react,a_react_fac,ierr)
            CHKERRQ(ierr)

            goto 201

          end if
#endif

#ifdef PETSC_HAVE_SUPERLU
          if (trim(strKSPType_react) == "kspsuperlu" .or. &
            trim(strKSPType_react) == "superlu") then

            !c force pctype to pclu for superlu_dist solver
            call PCSetType(pc_react,PCLU, ierr)
            CHKERRQ(ierr)

            call PCFactorSetMatSolverPackage(pc_react,MATSOLVERSUPERLU_DIST,ierr)
            CHKERRQ(ierr)

            call PCFactorSetUpMatSolverPackage(pc_react,ierr)
            CHKERRQ(ierr)

            call PCFactorGetMatrix(pc_react,a_react_fac,ierr)
            CHKERRQ(ierr)

            goto 201

          end if
#endif

          if(trim(strPCType_react) == "pcnone" .or. &
             trim(strPCType_react) == "none") then
              call PCSetType(pc_react,PCNONE, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_react) == "pcjacobi" .or. &
             trim(strPCType_react) == "jacobi") then
              call PCSetType(pc_react,PCJACOBI, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_react) == "pclu" .or. &
             trim(strPCType_react) == "lu") then
              call PCSetType(pc_react,PCLU, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_react) == "pcbjacobi" .or. &
             trim(strPCType_react) == "bjacobi") then
              call PCSetType(pc_react,PCBJACOBI, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_react) == "pcilu" .or. &
             trim(strPCType_react) == "ilu") then
              call PCSetType(pc_react,PCILU, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_react) == "pcasm" .or. &
             trim(strPCType_react) == "asm") then
              call PCSetType(pc_react,PCASM, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_react) == "pcksp" .or. &
             trim(strPCType_react) == "ksp") then
              call PCSetType(pc_react,PCKSP, ierr)
              CHKERRQ(ierr)

          else if(trim(strPCType_react) == "pchypre" .or. &
             trim(strPCType_react) == "hypre") then
              call PCSetType(pc_react,PCHYPRE, ierr)
              CHKERRQ(ierr)

          else
              call PCSetType(pc_react,PCBJACOBI, ierr)
              CHKERRQ(ierr)

          end if          

          if ((trim(strKSPType_react) /= "kspmumps"   .and.  &
              trim(strKSPType_react) /= "mumps"       .and.  &
              trim(strKSPType_react) /= "kspsuperlu"  .and.  &
              trim(strKSPType_react) /= "superlu")    .and.  &
              (trim(strPCType_react) == "pcilu"       .or.   &
              trim(strPCType_react) == "ilu"          .or.   &
              trim(strPCType_react) == "pclu"         .or.   &
              trim(strPCType_react) == "lu")          .and.  &
              nprcs > 1) then
              if(rank == 0) then
                write(*,'(5a,i4,a)') "Error: PCTYPE ",               &   
                      trim(strPCType_react)," is not supported for ",&
                      trim(strKSPType_react)," using ", nprcs,       &
                      " processors"
                write(ilog,'(5a,i4,a)') "Error: PCTYPE ",            &
                      trim(strPCType_react)," is not supported for ",&
                      trim(strKSPType_react)," using ", nprcs,       &
                      " processors"
              end if
              call petsc_mpi_finalize
              stop
          end if

        end if

201     continue
        
        !c check solver package if not from configuration file
        call KSPGetPC(ksp_react, pc_react, ierr)
        CHKERRQ(ierr)
        
        call PCFactorGetMatSolverPackage(pc_react,solver_pkg_react,ierr)
        CHKERRQ(ierr)
        
        if (solver_pkg_react == "superlu" .or.                   &
            solver_pkg_react == "superlu_dist" .or.              &
            solver_pkg_react == "mumps" .or.                     &
            solver_pkg_react == "mkl_pardiso" .or.               &
            solver_pkg_react == "mkl_cpardiso") then
          b_recal_norm_react = .true.
        else
          b_check_norm_react = .false.
        end if

        return

        !> If not doing matrix free then matrix operator and matrix used
        !> to construct preconditioner are the same
        !a_react_j = a_react

    end subroutine

    !> solve petsc solver space for reactive transport problem
    subroutine solver_dd_snes_solve_react(ilog,idetail,a_in,b_in,      &
                      x_inout,ia_in,ja_in,nngl_in,itsolv,              &
                      over_flow,rnorm,row_idx_l2pg,col_idx_l2pg,       &
                      b_non_interlaced)

        use gen, only : rank, node_idx_l2lg, ittot_rt,                 &
                        b_output_matrix_petsc, b_enable_output,        &
                        itimestep_output_matrix, mtime
        use solver_snes_function, only : form_initial_guess,           &
                                         compute_function,             &
                                         compute_jacobian

        use petsc_mpi_common, only : petsc_mpi_finalize

        implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#include <petsc/finclude/petscvec.h>
#include <petsc/finclude/petscvec.h90>
#include <petsc/finclude/petscdmda.h>
#include <petsc/finclude/petscviewer.h>
#include <petsc/finclude/petscviewer.h90>
#include <petsc/finclude/petscksp.h>
#elif PETSC
#include <finclude/petscsys.h>
#include <finclude/petscvec.h>
#include <finclude/petscvec.h90>
#include <finclude/petscdmda.h>
#include <finclude/petscviewer.h>
#include <finclude/petscviewer.h90>
#include <finclude/petscksp.h>
#endif

#ifdef PETSC_HAVE_MUMPS
        PetscInt  :: ival,icntl,infog34
        PetscReal :: cntl,rinfo12,rinfo13,val
#endif

        PetscInt :: ilog
        PetscInt :: idetail
        PetscInt :: nngl_in
        PetscInt :: ilocal
        PetscInt :: nlocal
        PetscReal, allocatable :: a_in(:)
        PetscReal, allocatable :: b_in(:)
        PetscReal, allocatable :: x_inout(:)
        PetscInt, allocatable  :: ia_in(:)
        PetscInt, allocatable  :: ja_in(:)
        PetscInt, allocatable :: row_idx_l2pg(:)
        PetscInt, allocatable :: col_idx_l2pg(:)
        PetscInt  :: itsolv
        PetscBool :: over_flow
        PetscBool :: b_non_interlaced
        PetscReal :: rnorm

        PetscViewer :: viewer
        PetscScalar,pointer :: vecpointer(:)

        PC :: subpc_react
        KSP :: subksp_react(100)        !This is just pointer, just make the array big enough,
                                        !by default, is 1 for each processor
        PetscBool :: b_pc_factor_shift_react

        PetscErrorCode :: ierr
        PetscInt :: info_debug
        character(72) :: strinum

        info_debug = 0

        over_flow = .false.

        if(b_enable_output .and. (b_output_matrix_petsc .or.           &
           itimestep_output_matrix==mtime)) then
          write(strinum, *) ittot_rt
          strinum = "_"//trim(adjustl(strinum))
        end if


        !Form initial guess, only assemble the local owned part, without ghost nodes
        if (b_form_initial_guess_react) then

          call form_initial_guess(rank,dmda_react%da,x_inout,          &
                    x_react_loc, x_react,nngl_in, row_idx_l2pg,        &
                    col_idx_l2pg, b_non_interlaced)


          if(b_enable_output .and. (b_output_matrix_petsc .or.         &
             itimestep_output_matrix==mtime)) then
            if(nngl_in <= 1024 .and. nngl_in < n_binary_limit) then
              call PetscViewerASCIIOpen(Petsc_Comm_World,              &
                        "x_react_in"//trim(strinum)//".txt",viewer,ierr)
              CHKERRQ(ierr)
            else
              call PetscViewerBinaryOpen(Petsc_Comm_World,             &
                        "x_react_in"//trim(strinum)//".bin",           &
                        FILE_MODE_WRITE, viewer, ierr)
              CHKERRQ(ierr)
            end if
            call VecView(x_react, viewer, ierr)
            CHKERRQ(ierr)
            call PetscViewerDestroy(viewer, ierr)
            CHKERRQ(ierr)
          end if

        end if

        !Compute function, only assemble the local part, without ghost nodes
        call compute_function(rank,dmda_react%da,b_in,b_react_loc,     &
                     b_react,nngl_in,row_idx_l2pg,col_idx_l2pg,        &
                     b_non_interlaced)

        if(b_enable_output .and. (b_output_matrix_petsc .or.           &
           itimestep_output_matrix==mtime)) then
          if(nngl_in <= 1024 .and. nngl_in < n_binary_limit) then
            call PetscViewerASCIIOpen(Petsc_Comm_World,                &
                      "b_react_in"//trim(strinum)//".txt",viewer, ierr)
            CHKERRQ(ierr)
          else
            call PetscViewerBinaryOpen(Petsc_Comm_World,               &
                      "b_react_in"//trim(strinum)//".bin",             &
                      FILE_MODE_WRITE, viewer, ierr)
            CHKERRQ(ierr)
          end if
          call VecView(b_react, viewer, ierr)
          CHKERRQ(ierr)
          call PetscViewerDestroy(viewer, ierr)
          CHKERRQ(ierr)
        end if


        !Check if the initial residual norm to see if it meets the convergence
        call VecNormBegin(b_react, Norm_2, rnorm, ierr)
        CHKERRQ(ierr)
        call VecNormEnd(b_react, Norm_2, rnorm, ierr)
        CHKERRQ(ierr)
        if(rnorm < 1.0d-300) then
            if(idetail > 1) then
                write(ilog,100)
            end if
            itsolv = 0
            return
        end if

        !Compute jacobian matrix, only assemble the local part, without ghost nodes
        call compute_jacobian(rank,dmda_react%da,                      &
                              a_react,a_in,ia_in,ja_in,nngl_in,        &
                              row_idx_l2pg,col_idx_l2pg,               &
                              b_non_interlaced)

        if(b_enable_output .and. (b_output_matrix_petsc .or.           &
           itimestep_output_matrix==mtime)) then
          if(nngl_in <= 1024 .and. nngl_in < n_binary_limit) then
            call PetscViewerASCIIOpen(Petsc_Comm_World,                &
                      "a_react_in"//trim(strinum)//".txt",viewer, ierr)
            CHKERRQ(ierr)
          else
            call PetscViewerBinaryOpen(Petsc_Comm_World,               &
                      "a_react_in"//trim(strinum)//".bin",             &
                      FILE_MODE_WRITE, viewer, ierr)
            CHKERRQ(ierr)
          end if
          call MatView(a_react, viewer, ierr)
          CHKERRQ(ierr)
          call PetscViewerDestroy(viewer, ierr)
          CHKERRQ(ierr)
        end if

        !> Set runtime options (e.g., -ksp_monitor -ksp_rtol <rtol> -ksp_type <type>) for reactive transport
        !> Set different options prefix for linear system of flow.
        !> Set runtime options (e.g., -react_pc_type <type>)

        call KSPSetFromOptions(ksp_react,ierr)
        CHKERRQ(ierr)


        call KSPSetUp(ksp_react,ierr)
        CHKERRQ(ierr)

        !c set PC options
        if(.not. b_use_petsc_default_react) then

          if (trim(strKSPType_react) == "kspgmres" .or. &
              trim(strKSPType_react) == "gmres" .or.    &
              trim(strKSPType_react) == "kspbcgs" .or.  &
              trim(strKSPType_react) == "bcgs") then

            call KSPGetPC(ksp_react, pc_react, ierr)
            CHKERRQ(ierr)

            b_pc_factor_shift_react = .true.

            !c Extract the array of KSP contexts for the local blocks 
            if(trim(strPCType_react) == "pcbjacobi" .or. &
               trim(strPCType_react) == "bjacobi") then
              call PCBJacobiGetSubKSP(pc_react,nlocal,PETSC_NULL_INTEGER,subksp_react,ierr)
              CHKERRQ(ierr)
            else if(trim(strPCType_react) == "pcasm" .or. &
                    trim(strPCType_react) == "asm") then
              call PCASMGetSubKSP(pc_react,nlocal,PETSC_NULL_INTEGER,subksp_react,ierr)
              CHKERRQ(ierr)
            else
              b_pc_factor_shift_react = .false.
            end if

            if (b_pc_factor_shift_react) then

              if (trim(pc_factor_shift_react) == "none") then
                do ilocal = 1, nlocal
                  call KSPGetPC(subksp_react(ilocal),subpc_react,ierr)
                  CHKERRQ(ierr)
                  call PCFactorSetShiftType(subpc_react,MAT_SHIFT_NONE, ierr)
                  CHKERRQ(ierr)
                end do
              else if (trim(pc_factor_shift_react) == "nonzero") then
                do ilocal = 1, nlocal
                  call KSPGetPC(subksp_react(ilocal),subpc_react,ierr)
                  CHKERRQ(ierr)
                  call PCFactorSetShiftType(subpc_react,MAT_SHIFT_NONZERO, ierr)
                  CHKERRQ(ierr)
                end do
              else if (trim(pc_factor_shift_react) == "positive_definite") then
                do ilocal = 1, nlocal
                  call KSPGetPC(subksp_react(ilocal),subpc_react,ierr)
                  CHKERRQ(ierr)
                  call PCFactorSetShiftType(subpc_react,MAT_SHIFT_POSITIVE_DEFINITE, ierr)
                  CHKERRQ(ierr)
                end do
              else if (trim(pc_factor_shift_react) == "inblocks") then
                do ilocal = 1, nlocal
                  call KSPGetPC(subksp_react(ilocal),subpc_react,ierr)
                  CHKERRQ(ierr)
                  call PCFactorSetShiftType(subpc_react,MAT_SHIFT_INBLOCKS, ierr)
                  CHKERRQ(ierr)
                end do
              end if
            end if
          end if
        end if

        call KSPSetUpOnBlocks(ksp_react,ierr)
        CHKERRQ(ierr)

        call KSPSolve(ksp_react,b_react,x_react,ierr)
        CHKERRQ(ierr)

        if(b_enable_output .and. (b_output_matrix_petsc .or.           &
           itimestep_output_matrix==mtime)) then
          if(nngl_in <= 1024 .and. nngl_in < n_binary_limit) then
            call PetscViewerASCIIOpen(Petsc_Comm_World,                &
                      "x_react_out"//trim(strinum)//".txt",viewer, ierr)
            CHKERRQ(ierr)
          else
            call PetscViewerBinaryOpen(Petsc_Comm_World,               &
                      "x_react_out"//trim(strinum)//".bin",            &
                      FILE_MODE_WRITE, viewer, ierr)
            CHKERRQ(ierr) 
          end if
          call VecView(x_react, viewer, ierr)
          CHKERRQ(ierr)
          call PetscViewerDestroy(viewer, ierr)
          CHKERRQ(ierr)
        end if

       
        !  Get iteration and convergence information
        call KSPGetIterationNumber(ksp_react,itsolv,ierr)
        CHKERRQ(ierr)
        call KSPGetErrorIfNotConverged(ksp_react, over_flow,ierr)
        CHKERRQ(ierr)
        if(itsolv == 0) then
            over_flow = .true.
        end if
        
        !Get residual norm, by default, preconditioned residual norm is calculated.
        if (b_recal_norm_react) then
          call calculate_norm(a_react, x_react, b_react, r_react, rnorm)
        else
          if (b_mykspconverged_react .and.                               &
                .not. b_use_petsc_default_react) then
            rnorm = rnorm_react
          else
            call KSPGetResidualNorm(ksp_react, rnorm, ierr)
            CHKERRQ(ierr)
          end if
        end if
        
        if(itsolv >= maxits_react  .and.                               &
            (b_check_norm_react .and. abs(rnorm) > abstol_react)) then
            over_flow = .true.
          if(rank == 0 .and. idetail > 1) then
            write(*,'(1x,a,1x,i6,1x,a,1x,e16.8)')                      &
                  "solver failure: iteration",itsolv,"rnorm",rnorm
            write(ilog,'(1x,a,1x,i6,1x,a,1x,e16.8)')                   &
                  "solver failure: iteration",itsolv,"rnorm",rnorm
          end if
        end if

        if(over_flow) then
            return
        end if

        !  Scatter ghost points to local vector, using the 2-step process
        !     DMGlobalToLocalBegin(), DMGlobalToLocalEnd().
        !  By placing code between these two statements, computations can be
        !  done while messages are in transition. 
        call DMGlobalToLocalBegin(dmda_react%da,x_react,INSERT_VALUES, &
                                  x_react_loc,ierr)
        CHKERRQ(ierr)
        call DMGlobalToLocalEnd(dmda_react%da,x_react,INSERT_VALUES,   &
                                  x_react_loc,ierr) 
        CHKERRQ(ierr)
        call VecGetArrayF90(x_react_loc,vecpointer,ierr)
        CHKERRQ(ierr)
        
        x_inout = vecpointer
        call VecRestoreArrayF90(x_react_loc,vecpointer,ierr)
        CHKERRQ(ierr)
        
#ifdef DEBUG
        if(info_debug > 1) then
            call petsc_mpi_finalize
            stop
        end if
#endif
        
 100    FORMAT (/1x,'Maximum error from previous solution is less',    &
              /1x,'than the specified convergence tolerance.')
        
        return
    
    end subroutine
    
   
    !> Release solver space
    subroutine solver_dd_release
    
        use gen, only: varsat_flow, reactive_transport
    
        implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
        
        PetscErrorCode :: ierr
        
        if(varsat_flow) then  
            call MatDestroy(a_flow,ierr)
            CHKERRQ(ierr)

            if (b_reuse_preconditioner_flow) then
              call MatDestroy(a_flow_j,ierr)
              CHKERRQ(ierr)
            end if

            call VecDestroy(x_flow_loc,ierr)
            CHKERRQ(ierr)
            call VecDestroy(x_flow,ierr)
            CHKERRQ(ierr)
            call VecDestroy(r_flow_loc,ierr)
            CHKERRQ(ierr)
            call VecDestroy(r_flow,ierr)
            CHKERRQ(ierr)
            call VecDestroy(b_flow_loc,ierr)
            CHKERRQ(ierr)
            call VecDestroy(b_flow,ierr)
            CHKERRQ(ierr)

            if (trim(strKSPType_flow) == "kspsuperlu" .or. &
                trim(strKSPType_flow) == "superlu"    .or. &
                trim(strKSPType_flow) == "kspmumps"   .or. &
                trim(strKSPType_flow) == "mpmps") then
              call MatDestroy(a_flow_fac,ierr)
              CHKERRQ(ierr)
            else
              call KSPDestroy(ksp_flow,ierr)
              CHKERRQ(ierr)
            end if

        end if
        
        if(reactive_transport) then
            call MatDestroy(a_react,ierr)
            CHKERRQ(ierr)

            if (b_reuse_preconditioner_react) then
              call MatDestroy(a_react_j,ierr)
              CHKERRQ(ierr)
            end if

            call VecDestroy(x_react_loc,ierr)
            CHKERRQ(ierr)
            call VecDestroy(x_react,ierr)
            CHKERRQ(ierr)
            call VecDestroy(r_react_loc,ierr)
            CHKERRQ(ierr)
            call VecDestroy(r_react,ierr)
            CHKERRQ(ierr)
            call VecDestroy(b_react_loc,ierr)
            CHKERRQ(ierr)
            call VecDestroy(b_react,ierr)
            CHKERRQ(ierr)

            if (trim(strKSPType_react) == "kspsuperlu" .or. &
                trim(strKSPType_react) == "superlu"    .or. &
                trim(strKSPType_react) == "kspmumps"   .or. &
                trim(strKSPType_react) == "mpmps") then
              call MatDestroy(a_react_fac,ierr)
              CHKERRQ(ierr)
            else
              call KSPDestroy(ksp_react,ierr)
              CHKERRQ(ierr)
            end if

        end if
   
    end subroutine solver_dd_release    
   
end module solver_dd
    
#endif
