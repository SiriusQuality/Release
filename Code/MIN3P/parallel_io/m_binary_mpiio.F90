!*****Revision Informations Automatically Generated by VisualSVN*****!
!---------------------------------------------------------------------
!> $ID:$
!> $Revision: 413 $
!> $Author: dsu $
!> $Date: 2016-03-25 15:17:31 +0100 (Fri, 25 Mar 2016) $
!> $URL: https://biot.eos.ubc.ca/svn/min3p_thcm/branches/fgerard_new/src/parallel_io/m_binary_mpiio.F90 $
!---------------------------------------------------------------------
!********************************************************************!


!> module: module_binary_mpiio
!>
!> written by: Danyang Su
!>
!> module description:
!>
!> Module of binary output tecplot results
!>
!> Note: 
module module_binary_mpiio

    use gen, only : rank, nprcs,                                       &
                    mpiarray_ndim, mpiarray_sizes_gbl,                 &
                    mpiarray_sizes_sub, mpiarray_starts_sub,           &
                    mpiarray_sizes_vel_gbl, mpiarray_sizes_vel_sub,    &
                    mpiarray_starts_vel_sub, mpiarray_filetype,        &
                    mpiarray_filetype_vel

    implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
    !> markers used in tecplot
    real*4, parameter :: zonemarker            = 299.0,    &
                         geommarker            = 399.0,    &
                         textmarker            = 499.0,    &
                         customlabelmarker     = 599.0,    &
                         userrecmarker         = 699.0,    &
                         datasetauxdatamarker  = 799.0,    &
                         varauxdatamarker      = 899.0,    &
                         eohmarker             = 357.0
    integer*4, parameter :: ione               = 1,        &
                            ione_neg           = -1,       &
                            izero              = 0
#ifdef MPI    
    integer :: wstatus(MPI_STATUS_SIZE)
#endif
    integer :: ierrcode
    
    interface binary_write_data
        module procedure binary_write_int4
        module procedure binary_write_real4
        module procedure binary_write_real8
        module procedure binary_write_int4_subarray
        module procedure binary_write_real4_subarray
        module procedure binary_write_real8_subarray
    end interface binary_write_data
    
    interface binary_read_data
        module procedure binary_read_int4
        module procedure binary_read_real4
        module procedure binary_read_real8
    end interface binary_read_data

    interface binary_subarray_initialize
        module procedure binary_subarray_init
        module procedure binary_subarray_init_nvars
    end interface binary_subarray_initialize
      
    contains
    
    !>
    !> collect error information regarding MPI IO
    !>
    subroutine mpi_io_check_error(errorcode)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer :: errorcode
#ifdef MPI
      integer :: resultlen, ierrcode
      character(len=512) :: string
      if (errorcode /= MPI_SUCCESS) then
        call MPI_ERROR_STRING(errorcode, string, resultlen, ierrcode)
        if (rank == 0) then
          write(*,'(a,1x,a)') "Error in MPI IO: ", trim(string)
        end if
      end if
#endif
    
    end subroutine mpi_io_check_error
   
    !>
    !> Open/Create file for binary output
    !>
    subroutine binary_file_open(comm_id, iunit, strfilename,   &
                                        b_mpi)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer :: comm_id
      integer*4 :: iunit
      character(*) :: strfilename
      logical :: b_mpi
      
#ifdef MPI
      if (b_mpi) then
        call MPI_FILE_OPEN(comm_id, trim(strfilename),                 & 
                           MPI_MODE_RDWR + MPI_MODE_CREATE,            & 
                           MPI_INFO_NULL, iunit, ierrcode)
        call mpi_io_check_error(ierrcode)
      else
#endif
        open(iunit,file=trim(strfilename),status='unknown',            &
             form='unformatted',access='stream')
#ifdef MPI
      end if
#endif
    
    end subroutine binary_file_open
    
    !>
    !> Write tecplot title and header information
    !>
    subroutine tecplot_binary_write_header(comm_id, iunit,             &
               strtecversion, strtitle, offset, b_mpi, b_single_rank)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: comm_id, iunit
      character(*) :: strtecversion
      character(*) :: strtitle
#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif
      logical :: b_mpi, b_single_rank
      
      external :: dumpstring
      
!c       I. The header section.
!c    The header section contains The version number of the file, a title
!c    of the file, the names of the varialles to be plotted, the
!c    descriptions of all zones to be read in and all text and geometry
!c    definitions.
#ifdef MPI
      if (b_mpi .and. (rank == 0 .or. b_single_rank)) then
        call MPI_File_write_at(iunit, offset, trim(strtecversion),     &
             len_trim(strtecversion), MPI_CHARACTER, wstatus, ierrcode) 
        call mpi_io_check_error(ierrcode)
        offset =  offset + len_trim(strtecversion)
        
        call MPI_File_write_at(iunit, offset, ione, 1, MPI_INTEGER4,   &
             wstatus, ierrcode) 
        call mpi_io_check_error(ierrcode)
        offset = offset + 4
        
        call dumpstring(iunit, offset, len_trim(strtitle)+1,           &
             trim(strtitle), .true.)
        
        offset = offset + (1+len_trim(strtitle))*4
      else if (.not. b_mpi) then
#endif
!c------1.1 Magic number, Version number        
        write(iunit) trim(strtecversion)
!c------1.2. Integer value of 1.----------------------------------------------------------
!c         +-----------+
!c         | INT32     |       This is used to determine the byte order
!c         +-----------+       of the reader relative to the writer.
        write(iunit) 1  
!c------1.3. Title and variable names.-------------------------------------------------
!c------1.3.1. The TITLE.
        call dumpstring(iunit, offset, len_trim(strtitle)+1,           &
              trim(strtitle), .false.)
        
        !lenght of the header, important, change the value accordingly if header changes        
#ifdef MPI
      end if
#endif
      
#ifdef MPI
      if (b_mpi) then
        call MPI_BCAST(offset, 1, MPI_INTEGER8, 0,                     &
                       comm_id, ierrcode)
        call mpi_io_check_error(ierrcode)
      end if
#endif 
    
    end subroutine tecplot_binary_write_header
    
    !>
    !> Write tecplot variable informations
    !>
    subroutine tecplot_binary_write_variable(comm_id, iunit, nvar,     &
                       strvariables, offset, b_mpi, b_single_rank)
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: comm_id, iunit, nvar
      character*72 :: strvariables(nvar)
      integer*4 :: i
#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif
      logical :: b_mpi, b_single_rank
      
      external :: dumpstring
     
#ifdef MPI
      if (b_mpi .and. (rank == 0 .or. b_single_rank)) then
!c -----1.3.2 Number of variables (NumVar) in the datafile.
        call MPI_File_write_at(iunit, offset, nvar, 1, MPI_INTEGER4,   &
             wstatus, ierrcode) 
        call mpi_io_check_error(ierrcode)
        offset = offset + 4
!c------1.3.3 Variable names. N = L[1] + L[2] + .... L[NumVar] 
        do i = 1, nvar
          call dumpstring(iunit, offset, len_trim(strvariables(i))+1,  &
               trim(strvariables(i)), .true.)          
          offset = offset + (1+len_trim(strvariables(i)))*4
        end do
      else if (.not. b_mpi) then
#endif
!c -----1.3.2 Number of variables (NumVar) in the datafile.
        write(iunit) nvar 
!c------1.3.3 Variable names. N = L[1] + L[2] + .... L[NumVar] 
        do i = 1, nvar
          call dumpstring(iunit, offset, len_trim(strvariables(i))+1,  &
               trim(strvariables(i)), .false.)
        end do
        
#ifdef MPI
      end if
#endif
      
#ifdef MPI
      if (b_mpi) then
        call MPI_BCAST(offset, 1, MPI_INTEGER8, 0,                     &
                       comm_id, ierrcode)
        call mpi_io_check_error(ierrcode)
      end if
#endif
    
    end subroutine tecplot_binary_write_variable
    
    !>
    !> Write tecplot zone header informations
    !>
    subroutine tecplot_binary_write_zoneinfo(comm_id, iunit, strzone,  &
               offset, itec, jtec, ktec, b_mpi, b_single_rank,         &
               b_multizone)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: comm_id, iunit
      character(*) :: strzone
#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif
      integer*4 :: itec, jtec, ktec
      
      logical :: b_mpi, b_single_rank, b_multizone
      
      integer*4 :: teczoneinfo(9)
      
      external :: dumpstring
      
#ifdef MPI
      if (b_mpi) then
        !important, change accordingly if zone information changes
        !important, change accordingly if number of output results changes 
        !or the type of output variables changes
        if (.not. b_single_rank) then
          if (b_multizone) then
            offset = offset + (11+len_trim(strzone))*4*rank
          end if
        end if
        
        if (b_single_rank .or. b_multizone .or. rank == 0) then
  
!c-----1.4. Zones-------------------------------------------------------------------
!c-----1.4.1 Zone 1+++++++++++++++++++++++++++++++++++++++++++
!c--------Zone marker. Value = 299.0
          call MPI_File_write_at(iunit, offset, zonemarker, 1,         &
               MPI_REAL4, wstatus, ierrcode) 
          call mpi_io_check_error(ierrcode)
          offset = offset + 4
!c--------Zone name. (See note 1.) N = length of zone name + 1.          
          call dumpstring(iunit, offset, len_trim(strzone)+1,          &
               trim(strzone), .true.)
          offset = offset + (1+len_trim(strzone))*4
              
!c-----------tecplot zone informations, combined              
          teczoneinfo(1:9) = (/-1, 0, 1, 0, 0, itec, jtec, ktec, 0/)            
          call MPI_File_write_at(iunit, offset, teczoneinfo, 9,        &
               MPI_INTEGER4, wstatus, ierrcode)
          call mpi_io_check_error(ierrcode)
          offset = offset + 9*4
        end if
              
!c-----I HEADER OVER--------------------------------------------------------------------
!C         EOHMARKER, value=357.0
        if (b_multizone) then 
          if(rank == nprcs - 1 .or. b_single_rank) then
            call MPI_File_write_at(iunit, offset, eohmarker, 1,        &
                 MPI_REAL4, wstatus, ierrcode)
            call mpi_io_check_error(ierrcode)
            offset = offset + 4
          end if 
        else
          if(rank == 0 .or. b_single_rank) then
            call MPI_File_write_at(iunit, offset, eohmarker, 1,        &
                 MPI_REAL4, wstatus, ierrcode) 
            call mpi_io_check_error(ierrcode)
            offset = offset + 4
          end if
        end if
        
        if (.not. b_multizone .and. .not. b_single_rank) then
          call MPI_BCAST(offset, 1, MPI_INTEGER8, 0,                   &
                         comm_id, ierrcode)
          call mpi_io_check_error(ierrcode)
        end if
      else
#endif
!c-----1.4. Zones-------------------------------------------------------------------
!c-----1.4.1 Zone 1+++++++++++++++++++++++++++++++++++++++++++
!c--------Zone marker. Value = 299.0
        write(iunit) zonemarker
!c--------Zone name. (See note 1.) N = length of zone name + 1.
        call dumpstring(iunit, offset, len_trim(strzone)+1,            &
             trim(strzone), .false.)
!c---------Zone Color (set to -1 if you want tecplot todetermine).
        write(iunit) -1
!c---------ZoneType 0=ORDERED,1=FELINESEG,2=FETRIANGLE,3=FEQUADRILATERAL,4=FETETRAHEDRON,5=FEBRICK
        write(iunit) 0
!c---------DataPacking 0=Block, 1=Point
        write(iunit) 1
!c---------Specify Var Location. 0 = Don't specify, all data is located at the nodes. 1 = Specify
        write(iunit) 0
!c---------Number of user defined face neighbor connections (value >= 0)
        write(iunit) 0

!c---------IMax,JMax,KMax
        write(iunit) itec
        write(iunit) jtec
        write(iunit) ktec
!c-----------1=Auxiliary name/value pair to follow   0=No more Auxiliar name/value pairs.
        write(iunit) 0
!c-----1.4.2 Zone 2+++++++++++++++++++++++++++++++++++++++++++            
!c---------- ... ... ...  ------------------------------------
!c
!c-----I HEADER OVER-----------------------------------------------------------------------
!C         EOHMARKER, value=357.0
        write(iunit) eohmarker
#ifdef MPI
      end if
#endif
    
    end subroutine tecplot_binary_write_zoneinfo
    
    !>
    !> Write tecplot data section
    !>
    subroutine tecplot_binary_write_section(comm_id, iunit, nvar,      &
               noffset_vols, offset, b_mpi,b_single_rank, b_multizone)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: comm_id, iunit, nvar, noffset_vols
      
#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif
      
      logical :: b_mpi, b_single_rank, b_multizone

      integer*4 :: i
      
      integer*4 :: iprecision
      
      integer*4, allocatable :: tecvarinfo(:)
     
      allocate(tecvarinfo(nvar+2))
      
      !tecplot outout data type double
#ifdef OUTPUT_DOUBLE
      iprecision = 2
#else
      iprecision = 1
#endif

      tecvarinfo(1:nvar) = iprecision
      tecvarinfo(nvar+1) = 0
      tecvarinfo(nvar+2) = -1
            
      !c++++++++II. Data section++++++++++++++++++++++++++++++++++++++++++++++
#ifdef MPI
      if (b_mpi) then
        if (.not. b_single_rank) then
          if (b_multizone) then  
            offset = offset + (nvar+3)*4*rank +                        &
                     noffset_vols*nvar*iprecision*4 
          end if
        end if
        
        if (b_single_rank .or. b_multizone .or. rank == 0) then
          call MPI_File_write_at(iunit, offset, zonemarker, 1,         &
               MPI_REAL4, wstatus, ierrcode) 
          call mpi_io_check_error(ierrcode)
          offset = offset + 4
          
          call MPI_File_write_at(iunit, offset, tecvarinfo, nvar+2,    &
               MPI_INTEGER4, wstatus, ierrcode)  
          call mpi_io_check_error(ierrcode)
          offset = offset + (nvar+2)*4
        end if
        
        if (.not. b_multizone .and. .not. b_single_rank) then
          call MPI_BCAST(offset, 1, MPI_INTEGER8, 0,                   &
                         comm_id, ierrcode)
          call mpi_io_check_error(ierrcode)
        end if
      else
#endif
!c-----2.1 zone 1------------------------------------------------------
!C--------Zone marker Value = 299.0
        write(iunit) Zonemarker
!C--------variable data format, 1=Float, 2=Double, 3=LongInt, 4=ShortInt, 5=Byte, 6=Bit
        do i = 1, nvar
          write(iunit) iprecision
        end do
      
!C--------Has variable sharing 0 = no, 1 = yes.       
        write(iunit) 0                                  
!C----------Zone number to share connectivity list with (-1 = no sharing).
        write(iunit) -1
#ifdef MPI
      end if
#endif
      
      deallocate(tecvarinfo)
    
    end subroutine tecplot_binary_write_section
    
    !>
    !> Write binary dataset, double precision
    !>
    subroutine binary_write_real4(iunit, ndatavalue,           &
               datavalue, offset, b_mpi)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: iunit
      integer :: ndatavalue
      real*4 :: datavalue(ndatavalue)

#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif

      logical :: b_mpi
     
#ifdef MPI
      if (b_mpi) then
        call MPI_File_write_at(iunit, offset, datavalue, ndatavalue,   &
             MPI_REAL4, wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
      else
#endif
        write(iunit) datavalue(1:ndatavalue)
#ifdef MPI
      end if
#endif
    
    end subroutine binary_write_real4
               
    !>
    !> Write binary dataset, real*4
    !>
    subroutine binary_write_real4_subarray(iunit, ndatavalue,           &
                       datavalue, offset, filetype)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: iunit
      integer*4 :: ndatavalue
      real*4 :: datavalue(ndatavalue)
      integer*4 :: filetype

#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif

#ifdef MPI
      call MPI_FILE_SET_VIEW(iunit,offset,MPI_REAL4,filetype,          &
                             'native',MPI_INFO_NULL,ierrcode) 
      call mpi_io_check_error(ierrcode)
      call MPI_FILE_WRITE_ALL(iunit,datavalue,ndatavalue,MPI_REAL4,    &
                              wstatus, ierrcode)
      call mpi_io_check_error(ierrcode)
#endif
    
    end subroutine binary_write_real4_subarray
                       
    !>
    !> read binary dataset, single precision
    !>
    subroutine binary_read_real4(iunit, ndatavalue,datavalue,          &
                                 offset, b_mpi)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: iunit
      integer :: ndatavalue
      real*4 :: datavalue(ndatavalue)

#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif

      logical :: b_mpi

#ifdef MPI
      if (b_mpi) then
        call MPI_File_read_at(iunit, offset, datavalue, ndatavalue,    &
             MPI_REAL4, wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
      else
#endif
        read(iunit) datavalue(1:ndatavalue)
#ifdef MPI
      end if
#endif
    
    end subroutine binary_read_real4
                                 
                                 
    !>
    !> Write binary dataset, double precision
    !>
    subroutine binary_write_real8(iunit, ndatavalue,       &
               datavalue, offset, b_mpi)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: iunit
      integer :: ndatavalue
      real*8 :: datavalue(ndatavalue)

#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif

      logical :: b_mpi
#ifdef MPI
      if (b_mpi) then
        call MPI_File_write_at(iunit, offset, datavalue, ndatavalue,   &
             MPI_REAL8, wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
      else
#endif
        write(iunit) datavalue(1:ndatavalue)
#ifdef MPI
      end if
#endif
    
      end subroutine binary_write_real8
               
               
    !>
    !> Write binary dataset, real*8
    !>
    subroutine binary_write_real8_subarray(iunit, ndatavalue,           &
                       datavalue, offset, filetype)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: iunit
      integer*4 :: ndatavalue
      real*8 :: datavalue(ndatavalue)
      integer*4 :: filetype

#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif

#ifdef MPI
      call MPI_FILE_SET_VIEW(iunit,offset,MPI_REAL8,filetype,          &
                             'native',MPI_INFO_NULL,ierrcode) 
      call mpi_io_check_error(ierrcode)
      call MPI_FILE_WRITE_ALL(iunit,datavalue,ndatavalue,MPI_REAL8,    &
                              wstatus, ierrcode)
      call mpi_io_check_error(ierrcode)
#endif
    
      end subroutine binary_write_real8_subarray
               
    !>
    !> read binary dataset, double precision
    !>
    subroutine binary_read_real8(iunit, ndatavalue,datavalue,          &
                                 offset, b_mpi)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: iunit
      integer :: ndatavalue
      real*8 :: datavalue(ndatavalue)

#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif

      logical :: b_mpi
#ifdef MPI
      if (b_mpi) then
        call MPI_File_read_at(iunit, offset, datavalue, ndatavalue,    &
             MPI_REAL8, wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
      else
#endif
        read(iunit) datavalue(1:ndatavalue)
#ifdef MPI
      end if
#endif
    
      end subroutine binary_read_real8       
               
    !>
    !> Write binary dataset, integer4
    !>
    subroutine binary_write_int4(iunit, ndatavalue,            &
                       datavalue, offset, b_mpi)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: iunit
      integer*4 :: ndatavalue
      integer*4 :: datavalue(ndatavalue)

#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif

      logical :: b_mpi
#ifdef MPI
      if (b_mpi) then
        call MPI_File_write_at(iunit, offset, datavalue, ndatavalue,   &
             MPI_INTEGER4, wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
      else
#endif
        write(iunit) datavalue(1:ndatavalue)
#ifdef MPI
      end if
#endif
    
      end subroutine binary_write_int4

    !>
    !> Write binary dataset, integer*4
    !>
    subroutine binary_write_int4_subarray(iunit, ndatavalue,           &
                       datavalue, offset, filetype)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: iunit
      integer*4 :: ndatavalue
      integer*4 :: datavalue(ndatavalue)
      integer*4 :: filetype

#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif

#ifdef MPI
      call MPI_FILE_SET_VIEW(iunit,offset,MPI_INTEGER4,filetype,       &
                             'native',MPI_INFO_NULL,ierrcode) 
      call mpi_io_check_error(ierrcode)
      call MPI_FILE_WRITE_ALL(iunit,datavalue,ndatavalue,MPI_INTEGER4, &
                              wstatus, ierrcode)
      call mpi_io_check_error(ierrcode)
#endif
    
      end subroutine binary_write_int4_subarray                       
                       
    !>
    !> read dataset, integer4
    !>
    subroutine binary_read_int4(iunit, ndatavalue, datavalue,          &
                                offset, b_mpi)
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: iunit
      integer*4 :: ndatavalue
      integer*4 :: datavalue(ndatavalue)

#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif

      logical :: b_mpi

#ifdef MPI
      if (b_mpi) then
        call MPI_File_read_at(iunit, offset, datavalue, ndatavalue,    &
             MPI_INTEGER4, wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
      else
#endif
        read(iunit) datavalue(1:ndatavalue)
#ifdef MPI
      end if
#endif
    
    end subroutine binary_read_int4               
    
    !>
    !> Close tecplot binary file 
    !>
    subroutine binary_file_close(iunit, b_mpi)
    
      implicit none 
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: iunit
      logical :: b_mpi
      
#ifdef MPI
      if (b_mpi) then
        call MPI_FILE_CLOSE(iunit, ierrcode)
        call mpi_io_check_error(ierrcode)
      else
#endif
        close(iunit)
#ifdef MPI
      end if
#endif
    
    end subroutine binary_file_close
    
    
    !>
    !> write restart file header
    !>
    subroutine restart_binary_write_header(comm_id,iunit,offset,b_mpi, &
                       time_io,delt_rt,delt_vs,time_bcvs,igstime,np)
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: comm_id, iunit
#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif
      logical :: b_mpi
      real*8 :: time_io,delt_rt,delt_vs,time_bcvs
      integer*4 :: igstime,np
      
      
!c    I. The header section.
!c    time_io,delt_rt,delt_vs,time_bcvs,igstime,nprcs
#ifdef MPI
      if (b_mpi .and. rank == 0 ) then
        call MPI_File_write_at(iunit,offset,time_io,1,MPI_REAL8,       &
                               wstatus,ierrcode)
        call mpi_io_check_error(ierrcode)
        offset = offset + 8
        
        call MPI_File_write_at(iunit,offset,delt_rt,1,MPI_REAL8,       &
                               wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
        offset = offset + 8
        
        call MPI_File_write_at(iunit,offset,delt_vs,1,MPI_REAL8,       &
                               wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
        offset = offset + 8
        
        call MPI_File_write_at(iunit,offset,time_bcvs,1,MPI_REAL8,     &
                               wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
        offset = offset + 8        
        
        call MPI_File_write_at(iunit,offset,igstime,1,MPI_INTEGER4,    &
                               wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
        offset = offset + 4
        
        call MPI_File_write_at(iunit,offset,np,1,MPI_INTEGER4,         &
                               wstatus,ierrcode)
        call mpi_io_check_error(ierrcode)
        offset = offset + 4
      else if (.not. b_mpi) then
#endif
        write(iunit) time_io,delt_rt,delt_vs,time_bcvs,igstime,np
#ifdef MPI
      end if
#endif
      
#ifdef MPI
      if (b_mpi) then
        call MPI_BCAST(offset, 1, MPI_INTEGER8, 0,                     &
                       comm_id, ierrcode)
        call mpi_io_check_error(ierrcode)
      end if
#endif 
    end subroutine restart_binary_write_header
                       
                       
    !>
    !> read restart file header
    !>
    subroutine restart_binary_read_header(comm_id,iunit,offset,b_mpi,  &
                       time_io,delt_rt,delt_vs,time_bcvs,igstime,np)
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: comm_id, iunit
#ifdef MPI
      integer(kind=MPI_OFFSET_KIND) :: offset
#else
      integer*8 :: offset
#endif
      logical :: b_mpi
      real*8 :: time_io,delt_rt,delt_vs,time_bcvs
      integer*4 :: igstime,np
      
!c    I. The header section.
!c    time_io,delt_rt,delt_vs,time_bcvs,igstime,nprcs
#ifdef MPI
      if (b_mpi) then        
        call MPI_File_read_at(iunit,offset,time_io,1,MPI_REAL8,        &
                              wstatus,ierrcode)
        call mpi_io_check_error(ierrcode)
        offset = offset + 8
        
        call MPI_File_read_at(iunit,offset,delt_rt,1,MPI_REAL8,        &
                              wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
        offset = offset + 8
        
        call MPI_File_read_at(iunit,offset,delt_vs,1,MPI_REAL8,        &
                              wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
        offset = offset + 8
        
        call MPI_File_read_at(iunit,offset,time_bcvs,1,MPI_REAL8,      &
                              wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
        offset = offset + 8
        
        call MPI_File_read_at(iunit,offset,igstime,1,MPI_INTEGER4,     &
                              wstatus, ierrcode)
        call mpi_io_check_error(ierrcode)
         offset = offset + 4
        
        call MPI_File_read_at(iunit,offset,np,1,MPI_INTEGER4,          &
                              wstatus,ierrcode)
        call mpi_io_check_error(ierrcode)
        offset = offset + 4
      else
#endif
        read(iunit) time_io,delt_rt,delt_vs,time_bcvs,igstime,np
#ifdef MPI
      end if
#endif

    end subroutine restart_binary_read_header
                       
    !>
    !> Initialize mpi subarray for binary output
    !>
    subroutine binary_subarray_init()
    
      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      if (mpiarray_ndim < 1) then
        !> Initialize mpi subarray parameters
        mpiarray_ndim = 1
        mpiarray_sizes_gbl = 1
        mpiarray_sizes_sub = 1
        mpiarray_starts_sub = 0
        mpiarray_sizes_vel_gbl = 1
        mpiarray_sizes_vel_sub = 1
        mpiarray_starts_vel_sub = 0
      end if
    
#ifdef MPI
#ifdef OUTPUT_DOUBLE
        call MPI_TYPE_CREATE_SUBARRAY(mpiarray_ndim,                   &
                 mpiarray_sizes_gbl, mpiarray_sizes_sub,               &
                 mpiarray_starts_sub, MPI_ORDER_FORTRAN,               &
                 MPI_REAL8, mpiarray_filetype, ierrcode)      
        call mpi_io_check_error(ierrcode)
#else                                                                  
        call MPI_TYPE_CREATE_SUBARRAY(mpiarray_ndim,                   &
                 mpiarray_sizes_gbl, mpiarray_sizes_sub,               &
                 mpiarray_starts_sub, MPI_ORDER_FORTRAN,               &
                 MPI_REAL4, mpiarray_filetype, ierrcode)
        call mpi_io_check_error(ierrcode)
#endif                                                                 
        call MPI_TYPE_COMMIT(mpiarray_filetype, ierrcode)
        call mpi_io_check_error(ierrcode)
     
                                                                  
#ifdef OUTPUT_DOUBLE                                                   
        call MPI_TYPE_CREATE_SUBARRAY(mpiarray_ndim,                   &
                 mpiarray_sizes_vel_gbl, mpiarray_sizes_vel_sub,       &
                 mpiarray_starts_vel_sub, MPI_ORDER_FORTRAN,           &
                 MPI_REAL8, mpiarray_filetype_vel, ierrcode)
        call mpi_io_check_error(ierrcode)
#else                                                                  
        call MPI_TYPE_CREATE_SUBARRAY(mpiarray_ndim,                   &
                 mpiarray_sizes_vel_gbl, mpiarray_sizes_vel_sub,       &
                 mpiarray_starts_vel_sub, MPI_ORDER_FORTRAN,           &
                 MPI_REAL4, mpiarray_filetype_vel, ierrcode)
        call mpi_io_check_error(ierrcode)
#endif
        call MPI_TYPE_COMMIT(mpiarray_filetype_vel, ierrcode)
        call mpi_io_check_error(ierrcode)
#endif
    
    end subroutine

    !>
    !> Initialize mpi subarray for mulit-variables binary output
    !>
    subroutine binary_subarray_init_nvars(nvars,b_init,b_vel,filetype, &
                      sizes_gbl,sizes_sub,starts_sub)

      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: nvars, filetype
      integer*4 :: sizes_gbl(3), sizes_sub(3), starts_sub(3)
      logical :: b_init,b_vel

      ! local variables
      integer*4 :: ndim
      
      if (b_init) then
        return
      end if

      if (mpiarray_ndim < 1) then
        !> Initialize mpi subarray parameters
        mpiarray_ndim = 1
        mpiarray_sizes_gbl = 1
        mpiarray_sizes_sub = 1
        mpiarray_starts_sub = 0
        mpiarray_sizes_vel_gbl = 1
        mpiarray_sizes_vel_sub = 1
        mpiarray_starts_vel_sub = 0
      end if

      ndim = mpiarray_ndim

#ifdef MPI
      if (b_vel) then
        sizes_gbl(1) = mpiarray_sizes_vel_gbl(1)*nvars
        sizes_sub(1) = mpiarray_sizes_vel_sub(1)*nvars
        starts_sub(1) = mpiarray_starts_vel_sub(1)*nvars
        if (ndim > 1) then
          sizes_gbl(2:ndim) = mpiarray_sizes_vel_gbl(2:ndim)
          sizes_sub(2:ndim) = mpiarray_sizes_vel_sub(2:ndim)
          starts_sub(2:ndim) = mpiarray_starts_vel_sub(2:ndim)
        end if
      else
        sizes_gbl(1) = mpiarray_sizes_gbl(1)*nvars
        sizes_sub(1) = mpiarray_sizes_sub(1)*nvars
        starts_sub(1) = mpiarray_starts_sub(1)*nvars
        if (ndim > 1) then
          sizes_gbl(2:ndim) = mpiarray_sizes_gbl(2:ndim)
          sizes_sub(2:ndim) = mpiarray_sizes_sub(2:ndim)
          starts_sub(2:ndim) = mpiarray_starts_sub(2:ndim)
        end if
      end if
#ifdef OUTPUT_DOUBLE
      call MPI_TYPE_CREATE_SUBARRAY(ndim, sizes_gbl,                   &
               sizes_sub, starts_sub, MPI_ORDER_FORTRAN,               &
               MPI_REAL8, filetype, ierrcode)
      call mpi_io_check_error(ierrcode)
#else                                                                  
      call MPI_TYPE_CREATE_SUBARRAY(ndim, sizes_gbl,                   &
               sizes_sub, starts_sub, MPI_ORDER_FORTRAN,               &
               MPI_REAL4, filetype, ierrcode)
      call mpi_io_check_error(ierrcode)
#endif                                                                 
      call MPI_TYPE_COMMIT(filetype, ierrcode)
      call mpi_io_check_error(ierrcode)
      b_init = .true.
#endif

    end subroutine

    !>
    !> Initialize mpi subarray for restart file binary output
    !> Forced to double precision
    !>
    subroutine binary_subarray_init_restart(nvars,b_init,filetype,    &
                      sizes_gbl,sizes_sub,starts_sub)

      implicit none
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      integer*4 :: nvars, filetype
      integer*4 :: sizes_gbl(3), sizes_sub(3), starts_sub(3)
      logical :: b_init

      ! local variables
      integer*4 :: ndim
      
      if (b_init) then
        return
      end if

      if (mpiarray_ndim < 1) then
        !> Initialize mpi subarray parameters
        mpiarray_ndim = 1
        mpiarray_sizes_gbl = 1
        mpiarray_sizes_sub = 1
        mpiarray_starts_sub = 0
        mpiarray_sizes_vel_gbl = 1
        mpiarray_sizes_vel_sub = 1
        mpiarray_starts_vel_sub = 0
      end if

      ndim = mpiarray_ndim

#ifdef MPI
        sizes_gbl(1) = mpiarray_sizes_gbl(1)*nvars
        sizes_sub(1) = mpiarray_sizes_sub(1)*nvars
        starts_sub(1) = mpiarray_starts_sub(1)*nvars
        if (ndim >1) then
          sizes_gbl(2:ndim) = mpiarray_sizes_gbl(2:ndim)
          sizes_sub(2:ndim) = mpiarray_sizes_sub(2:ndim)
          starts_sub(2:ndim) = mpiarray_starts_sub(2:ndim)
        end if

      call MPI_TYPE_CREATE_SUBARRAY(ndim, sizes_gbl,                   &
               sizes_sub, starts_sub, MPI_ORDER_FORTRAN,               &
               MPI_REAL8, filetype, ierrcode)
      call mpi_io_check_error(ierrcode)

      call MPI_TYPE_COMMIT(filetype, ierrcode)
      call mpi_io_check_error(ierrcode)
#endif
      b_init = .true.

    end subroutine


end module module_binary_mpiio
    
