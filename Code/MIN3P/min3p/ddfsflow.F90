!*****Revision Informations Automatically Generated by VisualSVN*****!
!---------------------------------------------------------------------
!> $ID:$
!> $Revision: 453 $
!> $Author: dsu $
!> $Date: 2017-02-21 19:54:05 +0100 (Tue, 21 Feb 2017) $
!> $URL: https://biot.eos.ubc.ca/svn/min3p_thcm/branches/fgerard_new/src/min3p/ddfsflow.F90 $
!---------------------------------------------------------------------
!********************************************************************!

!c ----------------------------------------------------------------------
!c subroutine ddfsflow
!c -----------------
!c
!c driver subroutine for fully saturated flow
!c
!c from Uli Mayer template 
!c
!c written by:      Tom Henderson - September 15, 2002
!c
!c last modified:   Tom Henderson - October 7, 2002
!c
!c definition of variables:
!c
!c I --> on input   * arbitrary  - initialized  + entries expected
!c O --> on output  * arbitrary  - unaltered    + altered
!c                                                                    I O
!c passed:   -
!c
!c common:   
!c gen.f:    real*8:
!c           -------
!c           avs(njavs)         = jacobian matrix                     * +
!c           afvs(njafvs)       = incomplete factorization            * +
!c           bvs(nn)            = rhs vector                          * +
!c           deltol_vs          = solver update tolerance             + -
!c           resvs(nn)          = residual                            * *
!c           restol_vs          = solver residual tolerance           + -
!c           rmupdate           = maximum solution update (solver)    * +
!c           rnorm              = residual 2-norm                     * +
!c           rwork(8*nn)        = real*8 work array                   * *
!c           uvs(nn)            = update towards solution-vector      * +
!c           uvsnew(nn)         = solution vector (new time level)    + +
!c 
!c           integer*4:
!c           ----------
!c           igen               = unit number, generic output file    + -
!c           ilog               = unit number, logbook                + -
!c           idbg               = unit number, debugging information  + -
!c           iavs(nn+1)         = row pointer array for avs           + -
!c           iafvs(nn+1)        = row pointer array for afvs          + -
!c           iafdvs(nn)         = diagonal pointer array for afvs     + -
!c           idetail_vs         = solver information level            + -
!c           ittot_vs           = total number of iterations          + +
!c                                (variably saturated flow)
!c           iwork(2*nn+njafvs) = integer work array                  * *
!c           javs(njavs)        = connectivity list                   + -
!c           jafvs(njafvs)      = column pointer array for afvs       + -
!c           lordervs(nn)       = array containing ordering           + -
!c           invordvs(nn)       = array containing inverse ordering   + -
!c           nn                 = total number of control volumes     + -
!c           njavs              = number of global connections        + -
!c           njafvs             = number of factored connections      + -
!c           idbg               = unit number, debugging file         + -
!c           msolvit_vs         = max. number of solver iterations    + -
!c           itsolv             = actual number of solver iterations  * +
!c           itsolvtot_vs       = total number of solver              + +
!c                                iterations
!c                                (variably saturated flow)
!c           
!c           logical:
!c           --------
!c           transient_flow     = .true.  -> .not.steady_flow,        + -
!c                                        -> transient flow
!c
!c dens.f:   real*8:
!c           -------
!c           pressure(nn)       = fluid pressure                      + +
!c           density(nn)        = fluid density                       + -
!c
!c local:    real*8:
!c           -------
!c           gacc               = gravitational acceleration [m s^-2]  
!c
!c           integer*4:
!c           ----------
!c           ierr               = 0 -> memory allocation successful
!c           ilist              = pointer (integer work array)
!c           ivol               = counter (control volumes)
!c
!c           logical:
!c           --------
!c           over_flow          = .true.  -> ||r||_2 norm -> inf
!c
!c external: checkerr = check for error during memory allocation
!c           zero_r8   = clear real*8 array
!c           jacddfs   = construct jacobian matrix for fully 
!c                       saturated density dependent flow problem
!c           jacbvs    = incorporate boundary terms in Jacobian 
!c                       matrix for flow problem
!c           incompletefactorization = incomplete lu-decomposition
!c                                     of jacobian matrix
!c           ws209     = iterative solution of matrix equation
!c ----------------------------------------------------------------------
 
      subroutine ddfsflow
 
      use parm
      use gen
      use dens
      use phys
      use dgml, only : dgm, maxwell 
      use file_unit, only : lun_get, lun_free
      use matrix_utility, only : export_arrays1d, export_mmformat,   &
                                 export_mmformat_gbl                   !for test, dsu
      use solver_results, only : solver_results_check_output
#ifdef PARDISO
      use solver_pardiso, only : pardiso_symbolicfactorization,      &
                                 pardiso_numfactorization,           &
                                 pardiso_substitution, ptvs,         &
                                 ptglob, iparm_vs, iparm_glob
#endif 

#ifdef OPENMP
      use omp_lib 
#endif 

#ifdef PETSC
      use solver_dd, only : solver_dd_snes_solve_flow
      use petsc_mpi_common, only : petsc_mpi_finalize
#endif

      implicit none
      
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif

      integer :: info_debug, i, ierr, ilist, iter, maxiter,            &
                 n_unknown_vs, n_unknown_glob
      real*8 :: cputime, errormax 

      integer :: ifile, idummy, ivol, iskip, nskip
      character*256 :: strdummy, strfile
      
      external checkerr, zero_r8, infcvs_cp, jacddfs, jacbvs,          &
              incompletefactorization, ws209, cputime
      
      logical :: over_flow, b_redo_symbfac
      
      real*8, parameter ::    &
      r0=0.0d0,               &
      r1=1.0d0,               &
      r2=2.0d0,               &
      r3=3.0d0
      integer, parameter ::   &
      i0=0
      
     
!cprovi------------------------------------------------------------------
!cprovi------------------------------------------------------------------
!cprovi------------------------------------------------------------------
      info_debug = 0

      not_converged = .true.
!cprovi--------------------------------------------------------------------
!cprovi If energy balance is solved, then allocate specific arrays
!cprovi--------------------------------------------------------------------
      if (heat_transport) then
        
        if (.not. allocated(aglob)) then
            allocate (aglob(njaglob), stat = ierr)
            aglob = 0.0d0
            call checkerr(ierr,'aglob',ilog)
        end if
        
        if (i_solver_type_flow == 0) then
            if (.not. allocated(afglob)) then
                allocate (afglob(njafglob), stat = ierr)
                afglob = 0.0d0
                call checkerr(ierr,'afglob',ilog)
            end if
        end if

        iterglob = i0
         
         !ittotglob = i0  
         
      else   
      
!c  allocate memory for solver
        if(.not. allocated(avs)) then
            allocate (avs(njavs), stat = ierr)
            avs = 0.0d0
            call checkerr(ierr,'avs',ilog)
        end if
        
        if (i_solver_type_flow == 0) then
            if(.not. allocated(afvs)) then
                allocate (afvs(njafvs), stat = ierr)
                afvs = 0.0d0
                call checkerr(ierr,'afvs',ilog)       
            end if
        end if

        iter_vs = i0
         
         !ittot_vs = i0 
         
      end if
!cprovi--------------------------------------------------------------------
!cprovi 
!cprovi--------------------------------------------------------------------
      do while (not_converged)          !newton iteration loop

        prt_flow_tot = cputime()
          
        errormax=r0

!cprovi--------------------------------------------
!cprovi Energy balance 
!cprovi--------------------------------------------        
        if (heat_transport) then
        
           iterglob = iterglob + 1         !iteration counter (current)
           ittotglob = ittotglob + 1       !iteration counter (total)
           
           if (idetailglob.eq.2 .and. rank == 0 .and. b_enable_output) then
             write(ilog,'(/a,i3,a)') 'Newton iteration ',iterglob,':'
             write(ilog,'(a)') '---------------------'
           end if
           
!cprovi---------------------------------------------------------------------
!cprovi Initialice arrays
!cprovi--------------------------------------------------------------------  
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp parallel
    !$omp sections
#endif
#endif
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif  
         call zero_r8(aglob, size(aglob, 1), 1, 1)
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif  
         call zero_r8(bglob, size(bglob, 1), 1, 1)
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif  
         call zero_r8(uglob, size(uglob, 1), 1, 1)
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif  
         if (i_solver_type_flow == 0) then
             call zero_r8(afglob, size(afglob, 1), 1, 1) 
         end if
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp end sections
    !$omp end parallel
#endif
#endif
         
         prt_flow_jac = cputime()
         
!c  compute influence coefficients in terms of conductivities
         if (gas_advection .or. dgm .or. maxwell) then
           call infcvs_cp
         end if 
         
!cprovi--------------------------------------------------------------------
!cprovi assemble matrix and rhs-vector for flow and heat equation  
!cprovi Parallelized, OpenMP, DSU
!cprovi--------------------------------------------------------------------
         
         call jacddfs_energybal
!cprovi--------------------------------------------------------------------
!cprovi adjust matrix and rhs vector for boundary conditions for flow
!cprovi and heat equations 
!cprovi Parallelized, OpenMP, DSU
!cprovi--------------------------------------------------------------------
         call jacbvs_energybal
       
         
         !Export sparse matrix dataset and right hand side. For test only, dsu.
             
         if((b_output_matrix.or.itimestep_output_matrix == mtime).and.&
             b_enable_output) then
             if(itype_matrix_format == 0) then
                call export_arrays1d(2*nngl, njaglob, iaglob, jaglob, &
                aglob, bglob, uglob, .true., .true., .false.,         &
                "ddfsflow_glob", ittotglob)
             else if(itype_matrix_format == 1) then
                call export_mmformat(2*nngl, njaglob, iaglob, jaglob, &
                aglob, bglob, uglob, .true., .true., .false.,         &
                "ddfsflow_glob", ittotglob)
#ifdef PETSC
                call export_mmformat_gbl(2*nngl,njaglob,iaglob,jaglob, &
                     aglob, bglob, uglob, .true., .true., .false.,     &
                     "ddfsflow_glob", nngl, nngbl, .false., ittotglob)
#endif
             end if
         end if
         
!cdsu  debug part, use external solution (written in sequential order) to test
!         if (mtime == 1 .or. mtime == 7 .or. mtime == 13) then
!                call export_mmformat_gbl(2*nngl,njaglob,iaglob,jaglob, &
!                        aglob, bglob, uglob, .true., .true., .false., &
!                        "ddfsflow_glob_check",nngl, nngbl, .false., ittotglob)
!         end if
!cdsu  debug part, use external solution (written in sequential order) to test, end

!cprovi--------------------------------------------------------------------
!cprovi Estimate condition number for the current matrix. 
!cprovi This is used for testing when newton iteration failed.
!cprovi--------------------------------------------------------------------   
#ifdef CONDITION_NUMBER

         if(b_output_condition_number) then
            call cond_num_cal(2*nngl, njaglob, iaglob, jaglob, aglob,  &
                      condition_number, condition_number_info) 
            
            if (rank == 0 .and. b_enable_output) then
            
            if (condition_number_info(1) .ge. 0 ) then
              write(*,"(2(a, e10.3, 1x))")                             &
                    " classical cond. num. ", condition_number(1),     &
                    " skeel cond. num. ", condition_number(2)
              write(ilog,"(2(a, e10.3, 1x))")                          &
                    " classical cond. num. ", condition_number(1),     &
                    " skeel cond. num. ", condition_number(2)
            else
              write(*,*)                                               &
                    ' error in estimating condition number, info(1) ', &
                    condition_number_info(1)
              write(ilog,*)                                            &
                    ' error in estimating condition number, info(1) ', &
                    condition_number_info(1)
            endif 
            
            if(i_solver_type_flow == 1) then
              if(condition_number(1) > 1.0e10 .and.                    &
                     condition_number(2) > 1.0e10) then
                  write(*,"(a)")                                       &
                        " Warning: matrix is ill-conditioned."
                  write(ilog,"(a)")                                    &
                        " Warning: matrix is ill-conditioned."
              end if
            end if
            
            end if
            
         end if

#endif         
         prt_flow_jac = cputime() - prt_flow_jac
         
         prt_flow_solver = 0.0d0
         
        !! use ws209 solver
        if (i_solver_type_flow == 0) then
#ifdef PARDISO
         
         if (b_solver_test_pardiso) then
    !$omp parallel                                                    &
    !$omp if (njaglob > numofloops_thred_global)                      &
    !$omp num_threads(numofthreads_global)                            &
    !$omp default(shared)                                             &
    !$omp private (i)  
    !$omp do schedule(static)
            do i = 1, njaglob
                aglob_std(i) = aglob(imapglob_std(i))
            end do 
    !$omp end do
    !$omp end parallel
            
            b_redo_symbfac = .true.
            
100         prt_flow_symbfac_comp = cputime()
            if(bsymbolicfactor_glob.or.i_symfactor_type_flow == 1) then
                call pardiso_symbolicfactorization(iparm_glob,ptglob,  &
                         2*nngl,njaglob,iaglob,jaglob_std,aglob_std)
                n_unknown_glob = 2*nngl
                bsymbolicfactor_glob = .false.                
            end if  
            prt_flow_symbfac_comp = cputime() - prt_flow_symbfac_comp
            
            prt_flow_fac_comp = cputime()
            call pardiso_numfactorization(iparm_glob,ptglob,           &
                     2*nngl,njaglob, iaglob, jaglob_std, aglob_std)
            prt_flow_fac_comp = cputime() - prt_flow_fac_comp
            
            prt_flow_sub_comp = cputime()
            call pardiso_substitution(ilog,msolvitglob,itsolvtotglob,  &
                     idetailglob,resglob,restolglob,deltolglob,        &
                     over_flow,rnorm,rmupdate,iparm_glob, ptglob,      &
                     2*nngl, njaglob, iaglob, jaglob_std, aglob_std,   &
                     bglob, uglob_std) 
            prt_flow_sub_comp = cputime() - prt_flow_sub_comp
            
            if (b_redo_symbfac .and.                                   &
                   (itsolvtotglob > n_max_iteration_flow .or.           &
                   rnorm > r_max_residual_flow .or. over_flow)) then
                bsymbolicfactor_glob = .true.  
                b_redo_symbfac = .false.
                goto 100
            end if
            
         end if
         
#endif

#ifdef PETSC
         if(b_solver_test_petsc) then
            !only solver the local part, update the ghost value
            call solver_dd_snes_solve_flow(ilog,idetailglob,aglob,     &
                     bglob,uglob_std,iaglob,jaglob,2*nngl,             &
                     itsolvtotglob,over_flow,rnorm,                    &
                     row_idx_l2pg_glob,col_idx_l2pg_glob,.true.)
            over_flow_vs = over_flow
#ifdef DEBUG
             if(rank == 0 .and. b_enable_output) then
                write(*,'(a, 2(1x, i5), 1x, l1, 1x, e12.4)')          &
                "ddfsflow-A: rank, iteration, over_flow, rnorm ",     &
                 rank, itsolvtotglob, over_flow, rnorm
             end if  
#endif
         end if
#endif
         
!cprovi--------------------------------------------------------------------
!cprovi Scale [avs] and {bvs} to produce unit diagonal
!cprovi Generate re-ordered preconditioner [af]
!cprovi--------------------------------------------------------------------
         ilist = 1
         prt_flow_fac = cputime()

             
         call incompletefactorization (2*nngl,njaglob,njafglob,bglob,  &
                                      aglob,afglob,rwork_max,iaglob,   &
                                      jaglob,iafglob,iafdglob,         &
                                      jafglob,iwork_max(ilist),        &
                                      lorderglob,invordglob,           &
                                      numofthreads_ws209)
         
         prt_flow_fac = cputime() - prt_flow_fac 
 
!c  solve [avs] * {uvs} = {bvs}
         prt_flow_sub = cputime() 
         
         call ws209(ilog,2*nngl,msolvitglob,itsolvtotglob,idetailglob, &
                iaglob,jaglob,iafglob,iafdglob,jafglob,lorderglob,     &
                aglob,afglob,uglob,bglob,resglob,rwork_max,            &
                restolglob,deltolglob,njaglob,njafglob,over_flow,      &
                rnorm,rmupdate,numofthreads_ws209,b_enable_output)
        
         prt_flow_sub = cputime() - prt_flow_sub

#ifdef PARDISO

         if (b_solver_test_pardiso) then     
           call solver_results_check_output(ittotglob, 2*nngl, uglob,  &
                    uglob_std, "ddfsflow_glob")
         end if

#endif

#ifdef PETSC
         if (b_solver_test_petsc) then        
             call solver_results_check_output(ittotglob, 2*nngl, uglob,&
                      uglob_std, "ddfsflow_glob_petsc") 
         end if
         
#endif
         prt_flow_solver = prt_flow_symbfac + prt_flow_fac + prt_flow_sub
        !! use pardiso solver
        else if (i_solver_type_flow == 1) then
#ifdef PARDISO

    !$omp parallel                                                    &
    !$omp if (njaglob > numofloops_thred_global)                      &
    !$omp num_threads(numofthreads_global)                            &
    !$omp default(shared)                                             &
    !$omp private (i)  
    !$omp do schedule(static)
            do i = 1, njaglob
                aglob_std(i) = aglob(imapglob_std(i))
            end do
    !$omp end do
    !$omp end parallel
            
           
            b_redo_symbfac = .true.
            
200         prt_flow_symbfac = cputime()
            if(bsymbolicfactor_glob  .or.                              &
                    i_symfactor_type_flow == 1) then
                !write(idbg, *) "pardiso symbolic factorization for ddfsflow line 269"
                call pardiso_symbolicfactorization(iparm_glob, ptglob, &
                         2*nngl, njaglob, iaglob, jaglob_std, aglob_std)
                n_unknown_glob = 2*nngl
                bsymbolicfactor_glob = .false.
            end if    
            prt_flow_symbfac = cputime() - prt_flow_symbfac
            
            !write(idbg, *) "pardiso numerical factorization for ddfsflow line 273"
            prt_flow_fac = cputime()
            call pardiso_numfactorization(iparm_glob, ptglob, 2*nngl,  &
                     njaglob, iaglob, jaglob_std, aglob_std)
            prt_flow_fac = cputime() - prt_flow_fac
            
            !write(idbg, *) "pardiso substitution for ddfsflow line 275"
            prt_flow_sub = cputime()
            call pardiso_substitution(ilog, msolvitglob, itsolvtotglob,&
                     idetailglob,resglob, restolglob, deltolglob,      &
                     over_flow, rnorm, rmupdate, iparm_glob, ptglob,   &
                     2*nngl, njaglob, iaglob, jaglob_std, aglob_std,   &
                     bglob, uglob) 
            prt_flow_sub = cputime() - prt_flow_sub
            
            if (b_redo_symbfac.and.                                    &
                    (itsolvtotglob > n_max_iteration_flow .or.         &
                     rnorm > r_max_residual_flow .or. over_flow)) then
                bsymbolicfactor_glob = .true. 
                b_redo_symbfac = .false.
                goto 200
            end if

#endif 
           prt_flow_solver = prt_flow_symbfac + prt_flow_fac + prt_flow_sub
        !! use PETSc solver
        else if (i_solver_type_flow == 2) then
#ifdef PETSC          
           prt_flow_solver = cputime()
            !only solver the local part, update the ghost value
            call solver_dd_snes_solve_flow(ilog,idetailglob,aglob,     &
                     bglob,uglob,iaglob,jaglob,2*nngl,                 &
                     itsolvtotglob,over_flow,rnorm,                    &
                     row_idx_l2pg_glob,col_idx_l2pg_glob,.true.)
            over_flow_vs = over_flow
           
           prt_flow_solver = cputime() - prt_flow_solver
#ifdef DEBUG
           if(rank == 0 .and. b_enable_output) then
             write(*,'(a, 2(1x, i5), 1x, l1, 1x, e12.4)')              &
                 "ddfsflow-B: rank, iteration, over_flow, rnorm ",     &
                 rank, itsolvtotglob, over_flow, rnorm 
           end if
#endif
#endif        
        end if
        
         !Export sparse matrix dataset and right hand side. For test only, dsu.       
         if((b_output_matrix.or.itimestep_output_matrix == mtime) .and.&
             b_enable_output) then
             if(itype_matrix_format == 0) then
                call export_arrays1d(2*nngl, njaglob, iaglob, jaglob,  &
                        aglob, bglob, uglob, .false., .false., .true., &
                        "ddfsflow_glob", ittotglob)
             else if(itype_matrix_format == 1) then
                call export_mmformat(2*nngl, njaglob, iaglob, jaglob,  &
                        aglob, bglob, uglob, .false., .false., .true., &
                        "ddfsflow_glob", ittotglob)
#ifdef PETSC
                call export_mmformat_gbl(2*nngl,njaglob,iaglob,jaglob, &
                        aglob, bglob, uglob, .false., .false., .true., &
                        "ddfsflow_glob",nngl, nngbl, .false., ittotglob)
#endif
             end if
         end if 
             
!cdsu  debug part, use external solution (written in sequential order) to test
!         if (mtime == 1 .or. mtime == 7 .or. mtime == 13) then
!                call export_mmformat_gbl(2*nngl,njaglob,iaglob,jaglob, &
!                        aglob, bglob, uglob, .false., .false., .true., &
!                        "ddfsflow_glob_check",nngl, nngbl, .false., ittotglob)
!         end if
!
!         if (rank == 0) then
!           write(*,*) "-->read hydraulic head and temperature change from external"
!         end if
!
!         ifile = lun_get()
!         write(strfile, *) ittotglob
!         strfile = "x_ddfsflow_glob_"//trim(adjustl(strfile))//"_natgbl.txt"
!         open(ifile,file=trim(strfile),status='old',form='formatted')
!         uglob = 0.0d0
!         nskip = 0
!         read(ifile,*) strdummy
!         do ivol = 1, nngl
!#ifdef PETSC
!           do iskip = 1, node_idx_lg2g(ivol) - nskip -1
!             read(ifile,*) idummy
!	        end do
!           nskip = node_idx_lg2g(ivol)
!#endif
!           read(ifile,*) idummy,uglob(ivol)
!         end do
!
!         rewind(ifile)
!         read(ifile,*) strdummy
!         do ivol = 1, nngbl
!           read(ifile,*) idummy
!         end do
!
!         nskip = 0
!         do ivol = 1, nngl
!#ifdef PETSC
!           do iskip = 1, node_idx_lg2g(ivol) - nskip -1
!             read(ifile,*) idummy
!           end do
!           nskip = node_idx_lg2g(ivol)
!#endif
!           read(ifile,*) idummy,uglob(ivol+nngl)
!         end do
!
!         call lun_free(ifile)
!cdsu  debug part, use external solution (written in sequential order) to test, end

         if (.not.transient_flow.and.itsolvtotglob.eq.msolvitglob) then
          
             if(rank == 0 .and. b_enable_output) then
               write(*,'(a/a)')                                        &
                   'maximum number of inner iterations exceeded',      &
                   'steady state flow solution non-convergent'
            
               write(ilog,'(a/a)')                                     &
                 'maximum number of inner iterations exceeded',        &
                 'steady state flow solution non-convergent' 
             end if  
             
#ifdef PETSC
             call petsc_mpi_finalize
#endif
             stop
         end if
        
        else 
!cprovi--------------------------------------------
!cprovi Only flow  
!cprovi--------------------------------------------         
           iter_vs = iter_vs+1             !iteration counter (current)
           ittot_vs = ittot_vs+1           !iteration counter (total)

           if (idetail_vs.eq.2 .and. rank == 0 .and. b_enable_output) then
             write(ilog,'(/a,i3,a)') 'Newton iteration ',iter_vs,':'
             write(ilog,'(a)') '---------------------'
           end if
!c  clear arrays
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp parallel
    !$omp sections
#endif
#endif

#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif 
           call zero_r8(avs, size(avs, 1), 1, 1)
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif 
           call zero_r8(bvs, size(bvs, 1), 1, 1)
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif 
           call zero_r8(uvs, size(uvs, 1), 1, 1)
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif 
           if (i_solver_type_flow == 0) then
               call zero_r8(afvs, size(afvs, 1), 1, 1)
           end if
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp end sections
    !$omp end parallel
#endif
#endif  
           
           prt_flow_jac = cputime()
           
!c  compute influence coefficients in terms of conductivities
           if (gas_advection .or. dgm .or. maxwell) then
             call infcvs_cp
           end if 

!c Compute the jacobian and residual
           call jacddfs
 
!c  adjust matrix and rhs vector for boundary conditions 
           call jacbvs
          
           !Export sparse matrix dataset and right hand side. For test only, dsu.   
           if((b_output_matrix.or.itimestep_output_matrix==mtime).and. &
               b_enable_output) then
               if(itype_matrix_format == 0) then
                   call export_arrays1d(nngl, njavs, iavs, javs,       &
                        avs, bvs, uvs, .true., .true., .false.,        &
                        "ddfsflow_vs", ittot_vs)
               else if(itype_matrix_format == 1) then
                   call export_mmformat(nngl, njavs, iavs, javs,       &
                        avs, bvs, uvs, .true., .true., .false.,        &
                        "ddfsflow_vs", ittot_vs)
#ifdef PETSC
                   call export_mmformat_gbl(nngl, njavs, iavs, javs,   &
                        avs, bvs, uvs, .true., .true., .false.,        &
                        "ddfsflow_vs",nngl,nngbl, .false., ittot_vs)
#endif
               end if
           end if

!cdsu  debug part, use external solution (written in sequential order) to test
!         if (mtime == 29) then
!                    call export_mmformat_gbl(nngl, njavs, iavs, javs,   &
!                         avs, bvs, uvs, .true., .true., .false.,        &
!                         "ddfsflow_vs_check",nngl,nngbl, .false., ittot_vs)
!         end if
!cdsu  debug part, use external solution (written in sequential order) to test, end

           prt_flow_jac = cputime() - prt_flow_jac
           
!cprovi--------------------------------------------------------------------
!cprovi Estimate condition number for the current matrix. 
!cprovi This is used for testing when newton iteration failed.
!cprovi-------------------------------------------------------------------- 
#ifdef CONDITION_NUMBER

         if(b_output_condition_number) then
            call cond_num_cal(nngl, njavs, iavs, javs, avs,            &
                 condition_number, condition_number_info) 
            
            if (rank == 0 .and. b_enable_output) then
                
            if (condition_number_info(1) .ge. 0) then
              write(*,"(2(a, e10.3, 1x))")                             &
                    " classical cond. num. ", condition_number(1),     &
                    " skeel cond. num. ", condition_number(2)
              write(ilog,"(2(a, e10.3, 1x))")                          &
                    " classical cond. num. ", condition_number(1),     &
                    " skeel cond. num. ", condition_number(2)
            else
              write(*,*)                                               &
                    ' error in estimating condition number, info(1) ', &
                    condition_number_info(1)
              write(ilog,*)                                            &
                    ' error in estimating condition number, info(1) ', &
                    condition_number_info(1)
            endif 
            
            
            if(i_solver_type_flow == 1) then
              if(condition_number(1) > 1.0e10 .and.                    &
                      condition_number(2) > 1.0e10) then
                  write(*,"(a)")                                       &
                        " Warning: matrix is ill-conditioned."
                  write(ilog,"(a)")                                    &
                        " Warning: matrix is ill-conditioned."
              end if
            end if
            
            end if
            
         end if
         
#endif           
         prt_flow_solver = 0.0d0
        !! use ws209 solver
        if (i_solver_type_flow == 0) then
#ifdef PARDISO
               
           if (b_solver_test_pardiso) then
    !$omp parallel                                                    &
    !$omp if (njavs > numofloops_thred_global)                        &
    !$omp num_threads(numofthreads_global)                            &
    !$omp default(shared)                                             &
    !$omp private (i)  
    !$omp do schedule(static)
                do i = 1, njavs
                    avs_std(i) = avs(imapvs_std(i))
                end do
    !$omp end do
    !$omp end parallel          
           
                b_redo_symbfac = .true.
300             prt_flow_symbfac_comp = cputime()
                if(bsymbolicfactor_vs  .or.                            &
                        i_symfactor_type_flow == 1) then
                    call pardiso_symbolicfactorization(iparm_vs, ptvs, &
                         nngl, njavs, iavs, javs_std, avs_std)
                    n_unknown_vs = nngl
                    bsymbolicfactor_vs = .false.
                end if 
                prt_flow_symbfac_comp=cputime()-prt_flow_symbfac_comp

                prt_flow_fac_comp = cputime()
                call pardiso_numfactorization(iparm_vs, ptvs, nngl,    &
                     njavs, iavs, javs_std, avs_std)
                prt_flow_fac_comp = cputime() - prt_flow_fac_comp

                prt_flow_sub_comp = cputime()
                call pardiso_substitution(ilog, msolvit_vs, itsolv,    &
                     idetail_vs, resvs, restol_vs, deltol_vs,          &
                     over_flow, rnorm, rmupdate,iparm_vs, ptvs, nngl,  &
                     njavs, iavs, javs_std, avs_std, bvs, uvs_std) 
                prt_flow_sub_comp = cputime() - prt_flow_sub_comp
                
                if (b_redo_symbfac .and.                               &
                      (itsolv > n_max_iteration_flow .or.              &
                      rnorm > r_max_residual_flow .or. over_flow)) then
                    bsymbolicfactor_vs = .true. 
                    b_redo_symbfac = .false.
                    goto 300
                end if
                
           end if

#endif 

#ifdef PETSC
           if(b_solver_test_petsc) then
            !only solver the local part, update the ghost value
               call solver_dd_snes_solve_flow(ilog,idetail_vs,avs,bvs, &
                       uvs_std,iavs,javs,nngl,itsolv,over_flow,rnorm,  &
                       row_idx_l2pg_vs,col_idx_l2pg_vs,.false.)
               over_flow_vs = over_flow
#ifdef DEBUG
               if(rank == 0 .and. b_enable_output) then 
                write(*,'(a, 2(1x, i5), 1x, l1, 1x, e12.4)')           &
                    "ddfsflow-C: rank, iteration, over_flow, rnorm ",  &
                    rank, itsolv, over_flow, rnorm   
               end if 
#endif
           end if
#endif
           
!c  Scale [avs] and {bvs} to produce unit diagonal
!c  Generate re-ordered preconditioner [af]

      ilist = 1
      prt_flow_fac = cputime()

      call incompletefactorization (nngl,njavs,njafvs,bvs,avs,afvs,    &
                                    rwork_max,iavs,javs,iafvs,iafdvs,  &
                                    jafvs,iwork_max(ilist),lordervs,   &
                                    invordvs,numofthreads_ws209)

      prt_flow_fac = cputime() - prt_flow_fac
 
!c  solve [avs] * {uvs} = {bvs}
      prt_flow_sub = cputime()

      call ws209(ilog,nngl,msolvit_vs,itsolv,idetail_vs,iavs,javs,iafvs,&
                iafdvs,jafvs,lordervs,avs,afvs,uvs,bvs,resvs,rwork_max, &
                restol_vs,deltol_vs,njavs,njafvs,over_flow,rnorm,       &
                rmupdate,numofthreads_ws209,b_enable_output)

      prt_flow_sub = cputime() - prt_flow_sub
#ifdef PARDISO
      if (b_solver_test_pardiso) then       
        call solver_results_check_output(ittot_vs, nngl, uvs, uvs_std, &
                                         "ddfsflow_vs") 
      end if  
#endif 

#ifdef PETSC 

          if (b_solver_test_petsc) then        
              call solver_results_check_output(ittot_vs, nngl, uvs,    &
                       uvs_std, "ddfsflow_vs_petsc") 
          end if
          
#endif     
          prt_flow_solver=prt_flow_symbfac+prt_flow_fac+prt_flow_sub
        !! use pardiso solver
        else if (i_solver_type_flow == 1) then
#ifdef PARDISO   
    !$omp parallel                                                    &
    !$omp if (njavs > numofloops_thred_global)                        &
    !$omp num_threads(numofthreads_global)                            &
    !$omp default(shared)                                             &
    !$omp private (i)  
    !$omp do schedule(static)
            do i = 1, njavs
                avs_std(i) = avs(imapvs_std(i))
            end do
    !$omp end do
    !$omp end parallel
           
            b_redo_symbfac = .true.
400         prt_flow_symbfac = cputime()
            if(bsymbolicfactor_vs  .or.                                &
                    i_symfactor_type_flow == 1) then
                !write(idbg, *) "pardiso symbolic factorization for ddfsflow line 363"
                call pardiso_symbolicfactorization(iparm_vs, ptvs,     &
                     nngl, njavs, iavs, javs_std, avs_std)
                n_unknown_vs = nngl
                bsymbolicfactor_vs = .false.
            end if  
            prt_flow_symbfac = cputime() - prt_flow_symbfac
            
            !write(idbg, *) "pardiso numerical factorization for ddfsflow line 367"
            prt_flow_fac = cputime()
            call pardiso_numfactorization(iparm_vs, ptvs, nngl,        &
                 njavs, iavs, javs_std, avs_std)
            prt_flow_fac = cputime() - prt_flow_fac
            
            !write(idbg, *) "pardiso substitution for ddfsflow line 369"
            prt_flow_sub = cputime() 
            call pardiso_substitution(ilog, msolvit_vs, itsolv,        &
                 idetail_vs, resvs, restol_vs, deltol_vs, over_flow,   &
                 rnorm, rmupdate, iparm_vs, ptvs, nngl, njavs, iavs,   &
                 javs_std, avs_std, bvs, uvs) 
            prt_flow_sub = cputime() - prt_flow_sub
            
            if (b_redo_symbfac .and.                                   &
                  (itsolv > n_max_iteration_flow .or.                  &
                  rnorm > r_max_residual_flow .or. over_flow)) then
                bsymbolicfactor_vs = .true.  
                b_redo_symbfac = .false.
                goto 400
            end if
#endif
            prt_flow_solver=prt_flow_symbfac+prt_flow_fac+prt_flow_sub
        !! use PETSc solver
        else if (i_solver_type_flow == 2) then
#ifdef PETSC     
            prt_flow_solver = cputime()
            !only solver the local part, update the ghost value
            call solver_dd_snes_solve_flow(ilog,idetail_vs,avs,bvs,    &
                     uvs,iavs,javs,nngl,itsolv,over_flow,rnorm,        &
                     row_idx_l2pg_vs,col_idx_l2pg_vs,.false.)
            over_flow_vs = over_flow
            prt_flow_solver = cputime() - prt_flow_solver
#ifdef DEBUG
            if(rank == 0 .and. b_enable_output) then
               write(*,'(a, 2(1x, i5), 1x, l1, 1x, e12.4)')           &
                   "ddfsflow-D: rank, iteration, over_flow, rnorm ",  &
                   rank, itsolv, over_flow, rnorm
            end if  
#endif
#endif        
        end if

        !Export sparse matrix dataset and right hand side. For test only, dsu.
        if((b_output_matrix.or.itimestep_output_matrix == mtime) .and. &
            b_enable_output) then
            if(itype_matrix_format == 0) then
                call export_arrays1d(nngl, njavs, iavs, javs, avs,     &
                     bvs, uvs, .false., .false., .true.,               &
                     "ddfsflow_vs", ittot_vs)
            else if(itype_matrix_format == 1) then
                call export_mmformat(nngl, njavs, iavs, javs, avs,     &
                     bvs, uvs, .false., .false., .true.,               &
                     "ddfsflow_vs", ittot_vs)
#ifdef PETSC
                   call export_mmformat_gbl(nngl, njavs, iavs, javs,   &
                        avs, bvs, uvs, .false., .false., .true.,       &
                        "ddfsflow_vs",nngl,nngbl, .false., ittot_vs)
#endif
            end if
        end if

!cdsu  debug part, use external solution (written in sequential order) to test
!         if (mtime == 29) then
!                    call export_mmformat_gbl(nngl, njavs, iavs, javs,   &
!                         avs, bvs, uvs, .false., .false., .true.,       &
!                         "ddfsflow_vs_check",nngl,nngbl, .false., ittot_vs)
!         end if
!
!         if (rank == 0) then
!           write(*,*) "-->read hydraulic head and temperature change from external"
!         end if
!
!         ifile = lun_get()
!         write(strfile, *) ittot_vs
!         strfile = "x_ddfsflow_vs_"//trim(adjustl(strfile))//"_natgbl.txt"
!         open(ifile,file=trim(strfile),status='old',form='formatted')
!         uvs = 0.0d0
!         nskip = 0
!         read(ifile,*) strdummy
!         do ivol = 1, nngl
!#ifdef PETSC
!           do iskip = 1, node_idx_lg2g(ivol) - nskip -1
!             read(ifile,*) idummy
!           end do
!           nskip = node_idx_lg2g(ivol)
!#endif
!           read(ifile,*) idummy,uvs(ivol)
!         end do
!
!         call lun_free(ifile)
!cdsu  debug part, use external solution (written in sequential order) to test, end

      if (.not.transient_flow.and.itsolv.eq.msolvit_vs) then

        if(rank == 0 .and. b_enable_output) then          !if MPI rank 0     
            write(*,'(a/a)')                                  &
            'maximum number of inner iterations exceeded',    &
            'steady state flow solution non-convergent'
            write(ilog,'(a/a)')                               &
            'maximum number of inner iterations exceeded',    &
            'steady state flow solution non-convergent' 
        end if                      !end if MPI rank 0

#ifdef PETSC
        call petsc_mpi_finalize
#endif
        stop
      end if

      end if ! energy balance 
!cprovi---------------------------------------------------------------------------------------------------
!cprovi End build jacobian and residual 
!cprovi---------------------------------------------------------------------------------------------------      
!c  total number of solver iterations

      itsolvtot_vs = itsolvtot_vs + itsolv  
      
      if (.not.over_flow) then
!cprovi---------------------------------------------------------------------------------------------------
!cprovi Update the solution 
!cprovi Parallelized, OpenMP, DSU
!cprovi---------------------------------------------------------------------------------------------------           
            if (heat_transport) then

               call updatedd_energybalance 

               iter=iterglob
               maxiter=maxiterglob
            else 

               call updatedd

               iter=iter_vs
               maxiter=maxit_vs
            end if
            
!cprovi---------------------------------------------------------------------------------------------------           
!cprovi---------------------------------------------------------------------------------------------------                 
!cprovi---------------------------------------------------------------------------------------------------            
                        
!c  max. number of iterations is exceeded and convergence tolerance
!c  not satisfied
!c  steady state problem -> terminate execution

            if ((iter==maxiter).and.(not_converged)) then
              if (steady_flow) then
                if (rank == 0 .and. b_enable_output) then 
                
                write(ilog,*)                                     &
                '-------------------------------------------'
                write(ilog,*)                                     &
                '   terminated in routine vsflow            '
                write(ilog,*)                                     &
                '   maximum number of iterations exceeded   '
                write(ilog,*)                                     &
                '   bye now ...                             '
                write(ilog,*)                                     &
                '-------------------------------------------'
                if (b_enable_output_gen) then
                  write(igen,*)                                   &
                  '-------------------------------------------'
                  write(igen,*)                                   &
                  '   terminated in routine vsflow            '
                  write(igen,*)                                   &
                  '   maximum number of iterations exceeded   '
                  write(igen,*)                                   &
                  '   bye now ...                             '
                  write(igen,*)                                   &
                  '-------------------------------------------'
                end if

                end if
#ifdef PETSC
                call petsc_mpi_finalize
#endif    
                stop

!c  transient problem -> reduce time step

              elseif (transient_flow) then 
                  
                if(rank == 0 .and. b_enable_output)  then
                  write(ilog,*)                                   & 
                  '-------------------------------------------'
                  write(ilog,*)                                   & 
                  '   maximum number of iterations exceeded   '
                  write(ilog,*)                                   & 
                  '             reducing time step            '
                  write(ilog,*)                                   & 
                  '-------------------------------------------'
                end if
                
                reduce_timestep = .true.
              end if
            end if

!c  overflow occurred
!c  steady state problem -> terminate execution

      elseif (over_flow) then
            if (steady_flow) then
              if (rank == 0 .and. b_enable_output) then
                write(ilog,*)'-------------------------------------------'
                write(ilog,*)'   failure in solver - overflow occurred in ddfsflow '
                write(ilog,*)'   bye now ...                             '
                write(ilog,*)'-------------------------------------------'
                
                if (b_enable_output_gen) then
                  write(igen,*)'-------------------------------------------'
                  write(igen,*)'   failure in solver - overflow occurred in ddfsflow '
                  write(igen,*)'   bye now ...                             '
                  write(igen,*)'-------------------------------------------'
                end if
              end if

              reduce_timestep = .true.

!c  transient problem -> reduce time step

            elseif (transient_flow) then

              if(rank == 0 .and. b_enable_output)  then  
                
              write(ilog,*)'-------------------------------------------'
              write(ilog,*)'   failure in solver - overflow occurred in ddfsflow '
              write(ilog,*)'             reducing time step            '
              write(ilog,*)'-------------------------------------------'
              
              end if

              reduce_timestep = .true.
            end if
      end if                      !(over_flow)
          
      prt_flow_tot = cputime() - prt_flow_tot

!c  write runtime to file
        if(rank == 0 .and. b_prtfile) then
            if (heat_transport) then
                write(iprt_flow, "(i8,1x,3(i3, 1x),i8,1x,7(e12.4,2x))")&
                      mtime, iter_sia, iter_seep, iterglob, ittotglob, &
                      prt_flow_jac, prt_flow_symbfac, prt_flow_fac,    &
                      prt_flow_sub, prt_flow_solver,                   &
                      (prt_flow_tot - prt_flow_jac - prt_flow_solver), &
                      prt_flow_tot
                
                if(b_solver_test_pardiso) then
                    write(iprt_flow_comp,                              &
                          "(i8,1x,3(i3, 1x),i8,1x,5(e12.4,2x))")       &
                          mtime, iter_sia, iter_seep, iterglob,        &
                          ittotglob, prt_flow_fac, prt_flow_sub,       &
                          prt_flow_symbfac_comp, prt_flow_fac_comp,    &
                          prt_flow_sub_comp
                end if            
            else
                write(iprt_flow, "(i8,1x,3(i3, 1x),i8,1x,7(e12.4,2x))")&
                      mtime, iter_sia, iter_seep, iter_vs, ittot_vs,   &
                      prt_flow_jac, prt_flow_symbfac, prt_flow_fac,    &
                      prt_flow_sub, prt_flow_solver,                   &
                      (prt_flow_tot - prt_flow_jac - prt_flow_solver), &
                      prt_flow_tot
                
                if(b_solver_test_pardiso) then
                    write(iprt_flow_comp,                              &
                          "(i8,1x,3(i3, 1x),i8,1x,5(e12.4,2x))")       &
                          mtime, iter_sia, iter_seep, iter_vs,         &
                          ittot_vs, prt_flow_fac, prt_flow_sub,        &
                          prt_flow_symbfac_comp, prt_flow_fac_comp,    &
                          prt_flow_sub_comp
                end if
            end if
        end if
        
!c  reset primary and secondary unknowns for reduced time step

          if (reduce_timestep) then
            uvsnew = uvsold
            pornew = porold
            density = densold
            densold1 = densold
            tds_new = tds_old
            if (heat_transport) then
              tempnew = tempold
              if (update_viscosity_temp) then 
                viscosity = viscoold
              end if 
              if (ispitzerdens) then
                  density_pitzer = densold_pitzer
                end if
            end if

!c  return and start over with reduced time step

            goto 20
            
          end if
           
          if (.not.iterative_solver_flow) then 
            not_converged=.false. 
            exit 
          end if
 
      end do          !newton iteration loop        
        
!   10 continue     
   
      ! If porosity is not updated according to flow
          
      if (.not.update_porosity_flow) then
           pornew=porold
      end if
   
   20 continue  

!cprov-------------------------------------------------------------------------      
!cprov Deallocate local variables
!cprov------------------------------------------------------------------------- 
      
      if (heat_transport) then
        if (b_dynamic_memory) then
            deallocate (aglob)
            call checkerr(ierr,'aglob',ilog)
            
            if (i_solver_type_flow == 0) then
                deallocate (afglob)
                call checkerr(ierr,'afglob',ilog)
            end if
        end if
      else  
        if (b_dynamic_memory) then
            deallocate (avs, stat = ierr)
            call checkerr(ierr,'avs',ilog) 
            
            if (i_solver_type_flow == 0) then
                deallocate (afvs, stat = ierr)
                call checkerr(ierr,'afvs',ilog) 
            end if
        end if
      end if

      return
      end
