!*****Revision Informations Automatically Generated by VisualSVN*****!
!---------------------------------------------------------------------
!> $ID:$
!> $Revision: 453 $
!> $Author: dsu $
!> $Date: 2017-02-21 19:54:05 +0100 (Tue, 21 Feb 2017) $
!> $URL: https://biot.eos.ubc.ca/svn/min3p_thcm/branches/fgerard_new/src/min3p/ddvsflow.F90 $
!---------------------------------------------------------------------
!********************************************************************!

!c ----------------------------------------------------------------------
!c subroutine ddvsflow
!c -----------------
!c
!c driver subroutine for density-dependent flow 
!c
!c written by:      Tom Henderson - August 15, 2002
!c
!c last modified:   Tom Henderson - September 10, 2003
!c                                  April 14, 2005 PEST early termination 
!c
!c definition of variables:
!c
!c I --> on input   * arbitrary  - initialized  + entries expected
!c O --> on output  * arbitrary  - unaltered    + altered
!c                                                                    I O
!c passed:   -
!c
!c common:   
!c gen.f:    real*8:
!c           -------
!c           avs(njavs)         = jacobian matrix                     * +
!c           afvs(njafvs)       = incomplete factorization            * +
!c           bvs(nn)            = rhs vector                          * +
!c           deltol_vs          = solver update tolerance             + -
!c           sanew(nn)          = aqueous phase saturation            + +
!c                                - new tim level
!c           uvs(nn)            = update towards solution-vector      * +
!c           uvsnew(nn)         = solution vector (new time level)    + +
!c           uvsold(nn)         = solution vector (old time level)    + -
!c           restol_vs          = solver residual tolerance           + -
!c           resvs(nn)          = residual                            * + 
!c           rmupdate           = maximum solution update (solver)    * +
!c           rnorm              = residual 2-norm                     * +
!c           rwork(8*nn)        = real*8 work array                   * *
!c           tol_vs             = convergence tolerance               + -
!c                                (variably saturated flow)
!c           zg(nn)             = spatial coordinates in z-direction  + -
!c
!c           integer*4:
!c           ----------
!c
!c           igen               = unit number, generic output file    + -
!c           ilog               = unit number, log file               + -
!c           iavs(nn+1)         = row pointer array for avs           + -
!c           iafvs(nn+1)        = row pointer array for afvs          + -
!c           iafdvs(nn)         = diagonal pointer array for afvs     + -
!c           idbg               = unit number, debugging file         + -
!c           idetail_vs         = information level                   + -
!c           invordvs(nn)       = array containing inverse ordering   + -
!c           iter_seep          = iteration counter                   * +
!c                                (seepage face iteration)
!c           iter_vs            = iteration counter                   * +
!c                                (variably saturated flow)
!c           itseep_tot         = total number of seepage face        * +
!c                                iterations
!c           ittot_vs           = total number of iterations          * +
!c                                (variably saturated flow)
!c           iwork(*)           = integer work array                  * *
!c           javs(njavs)        = connectivity list                   + -
!c           jafvs(njafvs)      = column pointer array for afvs       + -
!c           lordervs(nn)       = array containing ordering           + -
!c           maxit_vs           = max. number of newton iterations    + -
!c                                (variably saturated flow)
!c           mpropvs(nn)        = pointer array for allocation of     + -
!c                                material properties
!c           msolvit_vs         = max. number of solver iterations    + -
!c           njavs              = number of global connections        + -
!c           njafvs             = number of factored connections      + -
!c           nn                 = total number of control volumes     + -
!c           itsolv             = actual number of solver iterations  * +
!c           itsolvtot_vs       = total number of solver              + +
!c                                iterations
!c                                (variably saturated flow)
!c          
!c           logical:
!c           --------
!c           mass_balance_vs    = .true.  -> compute mass balance     + -
!c                                           (variably_saturated
!c                                            flow)
!c           not_converged      = .true.  -> continue Newton          * +
!c                                           iteration
!c           reduce_timestep    = .true.  -> restart with reduced     + +
!c                                           timestep
!c           seepage_face       = .true.  -> seepage face boundary    + -
!c                                           specified
!c           seep_iter          = .true.  -> continue seepage face    + +
!c                                           iteration
!c           steady_flow        = .true.  -> steady state flow        + -
!c           transient_flow     = .true.  -> .not.steady_flow,        + -
!c                                        -> transient flow   
!c dens.f:   real*8:
!c           -------
!c           pressure(nn)       = fluid pressure                      + +
!c           density(nn)        = fluid density                       + -
!c local:    real*8:
!c           -------
!c           gacc               = gravitational acceleration [m s^-2]
!c
!c           integer*4:
!c           ----------
!c           ierr               = 0 -> memory allocation successful
!c           ilist              = pointer (integer work array)
!c           ivol               = counter (control volumes)
!c           izn                = pointer (material property)
!c     
!c           logical:
!c           --------
!c           over_flow          = .true.  -> ||r||_2 norm -> infinity
!c
!c external: checkerr = check for error during memory allocation
!c           zero_r8   = clear real*8 array
!c           jacddvs   = construct Jacobian matrix 
!c                       (density dependent flow)
!c           jacbvs    = incorporate boundary terms in Jacobian 
!c                       (variably saturated flow)
!c           incompletefactorization = incomplete lu-decomposition of
!c                                     stiffness matrix
!c           ws209     = iterative solution of matrix equation
!c           updatedd  = update solution vector, secondary variables
!c                       and check for convergence
!c           soilparm  = compute soil hydraulic parameters
!c           mbaldd    = compute mass balance (density dependent flow) 
!c           seepfdd   = seepage face iteration control 
!c                       (density dependent flow)
!c ----------------------------------------------------------------------

      subroutine ddvsflow

      use parm
      use gen
      use phys
      use dens
      use chem 
      use dgml, only : dgm, maxwell 
      use file_unit, only : lun_get, lun_set, lun_free
      use solver_results, only : solver_results_check_output
      
#ifdef OPENMP
      use omp_lib 
#endif

#ifdef PARDISO
      use solver_pardiso, only : pardiso_symbolicfactorization,      &
                                 pardiso_numfactorization,           &
                                 pardiso_substitution, ptvs, ptglob, &
                                 iparm_vs, iparm_glob
#endif  

      
#ifdef PETSC
      use solver_dd, only : solver_dd_snes_solve_flow
      use petsc_mpi_common, only : petsc_mpi_finalize
#endif
      use matrix_utility, only : export_arrays1d, export_mmformat,     &
                                 export_mmformat_gbl                      !for test, dsu
      
      implicit none
      
      integer :: i, ierr, ierrcode, ilist, iter, ivol, izn, ipest,     &
                 istatus, maxiter, n_unknown_vs, n_unknown_glob,       &
                 ilun_pest
      real*8 :: cputime, errormax

      external checkerr, zero_r8, infcvs_cp, jacddvs, jacbvs,          &
              incompletefactorization, ws209, updatedd, soilprdd,      &
              mbaldd, seepfdd


      logical over_flow, b_redo_symbfac
      
      real*8, parameter :: r0=0.0d0, r1=1.0d0
      
#ifdef PETSC_V3_6_X
#include <petsc/finclude/petscsys.h>
#elif PETSC
#include <finclude/petscsys.h>
#endif
      
      integer, parameter :: i0=0 
      
      not_converged = .true.

      if (seepage_face) then
        iter_seep = 0
        seep_iter = .true.
      end if
      
!c  compute soil hydraulic parameters
#ifdef OPENMP
    !$omp parallel                                                    &
    !$omp if (nngl > numofloops_thred_ddvsflow_1)                     &
    !$omp num_threads(numofthreads_global)                            &
    !$omp default(shared)                                             &
    !$omp private (ivol, izn)                                              
    !$omp do schedule(static)
#endif 
      do ivol=1,nngl
        izn = mpropvs(ivol)
        call soilprdd(uvsnew(ivol),sanew(ivol),sgnew(ivol),   &  
                     relperm(ivol),relpermg(ivol),            &
                     snnew(ivol),swr(izn),aentry(izn),        &
                     spalpha(izn),                            &
                     spbeta(izn),expn(izn),spgamma(izn),      &
                     napl_permeability,                       &
                     napl_kfunction,sgr,isovendrying(izn),    &
                     beta_ovendry(izn),hm_ovendry(izn),       &
                     w0_ovendry(izn),cp0_ovendry(izn),        &
                     ref_dens,gacc)
      end do
#ifdef OPENMP
    !$omp end do
    !$omp end parallel
#endif     


      if (heat_transport) then

        if(.not. allocated(aglob)) then  
            allocate (aglob(njaglob), stat = ierr)
            aglob = 0.0d0
            call checkerr(ierr,'aglob',ilog)
        end if
        
        if (i_solver_type_flow == 0) then
            if (.not. allocated(afglob)) then
                allocate (afglob(njafglob), stat = ierr)
                afglob = 0.0d0
                call checkerr(ierr,'afglob',ilog)
            end if
        end if

        iterglob = i0
         
        !ittotglob = i0  
         
      else   
      
!c  allocate memory for solver
        if(.not. allocated(avs)) then
            allocate (avs(njavs), stat = ierr)
            avs = 0.0d0
            call checkerr(ierr,'avs',ilog)
        end if
        
        if (i_solver_type_flow == 0) then
            if (.not. allocated(afvs)) then
                allocate (afvs(njafvs), stat = ierr)
                afvs = 0.0d0
                call checkerr(ierr,'afvs',ilog)
            end if
        end if

        iter_vs = i0
         
        !ittot_vs = i0 
         
      end if

!c option look for file pest.stp, which will cause simulation to abort
      ipest = 0 !(0/1) -> 1 = activate PEST termination function

      do while (seep_iter.or.not_converged)   !seepage face iteration

        if(ipest .eq.1) then
          if (rank == 0) then       !if MPI rank 0
            ilun_pest = lun_get()  
            open (ilun_pest,file='../pest.stp',status='old',iostat=istatus)
            if(istatus .eq. 0) then
              write(ilog,'(a)')'execution halted due to pest.stp'
              close(ilun_pest)
              open (ilun_pest,file='pslave.fin',status='unknown') ! terminate slave
              write(ilun_pest,'(a)') 'F'
              close(ilun_pest)
            end if
            call lun_free(ilun_pest)
          end if                    !end if MPI rank 0

#ifdef MPI
          call MPI_BCAST(istatus, 1, MPI_INTEGER4, 0,             &
                         Petsc_Comm_World, ierrcode)
          CHKERRQ(ierrcode)
#endif
          if(istatus .eq. 0) then
#ifdef PETSC
            call petsc_mpi_finalize
#endif
            stop
          end if
          
        end if
                                              
        if (seepage_face) then
          iter_seep = iter_seep+1
          itseep_tot = itseep_tot + 1
          
          if(rank == 0 .and. b_enable_output)  then
            write(ilog,'(/,2x,a,i2,a)') 'Seepage Face Iteration ',  &
                                      iter_seep,':'
            write(ilog,'(2x,a,i4/)')                                &
                 'Number of seepage face nodes: ',nseep_first
          end if
        end if
        
        

        iter_vs = 0
        not_converged = .true.

        do while (not_converged)          !newton iteration loop
            
          prt_flow_tot = cputime()

          errormax=r0
          
!cprovi--------------------------------------------
!cprovi Energy balance 
!cprovi--------------------------------------------        
          if (heat_transport) then
        
           iterglob = iterglob + 1         !iteration counter (current)
           ittotglob = ittotglob + 1       !iteration counter (total)

           if (idetailglob.eq.2 .and. rank == 0 .and. b_enable_output) then
             write(ilog,'(/a,i3,a)') 'Newton iteration ',iterglob,':'
             write(ilog,'(a)') '---------------------'
           end if

!cprovi---------------------------------------------------------------------
!cprovi Initialice arrays
!cprovi--------------------------------------------------------------------
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp parallel
    !$omp sections
#endif
#endif
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif 
           aglob=r0
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif 
           bglob=r0
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif 
           uglob=r0    
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif 
           if (i_solver_type_flow == 0) then
               call zero_r8(afglob, size(afglob, 1), 1, 1)
           end if
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp end sections
    !$omp end parallel
#endif
#endif


           prt_flow_jac = cputime()    
           
!c  compute influence coefficients in terms of conductivities
           if (gas_advection .or. dgm .or. maxwell) then
             call infcvs_cp
           end if 
         
!cprovi--------------------------------------------------------------------
!cprovi assemble matrix and rhs-vector for flow and heat equation  
!cprovi Parallelized, OpenMP, DSU
!cprovi--------------------------------------------------------------------
           call jacddfs_energybal
!cprovi--------------------------------------------------------------------
!cprovi adjust matrix and rhs vector for boundary conditions for flow
!cprovi and heat equations 
!cprovi Parallelized, OpenMP, DSU
!cprovi--------------------------------------------------------------------
           call jacbvs_energybal
          
           !Export sparse matrix dataset and right hand side. For test only, dsu. 
           if((b_output_matrix.or.itimestep_output_matrix==mtime) .and.&
               b_enable_output) then
               if(itype_matrix_format == 0) then
                  call export_arrays1d(2*nngl, njaglob, iaglob, jaglob,&
                       aglob, bglob, uglob, .true., .true., .false.,   &
                       "ddvsflow_glob", ittotglob)
               else if(itype_matrix_format == 1) then
                  call export_mmformat(2*nngl, njaglob, iaglob, jaglob,&
                       aglob, bglob, uglob, .true., .true., .false.,   &
                       "ddvsflow_glob", ittotglob)
#ifdef PETSC
                  call export_mmformat_gbl(2*nngl, njaglob, iaglob,    &
                       jaglob, aglob, bglob, uglob, .true., .true.,    &
                       .false., "ddvsflow_glob", nngl, nngbl, .false., &
                       ittotglob)
#endif
               end if
           end if
      
           
!cprovi--------------------------------------------------------------------
!cprovi Estimate condition number for the current matrix. 
!cprovi This is used for testing when newton iteration failed.
!cprovi--------------------------------------------------------------------
#ifdef CONDITION_NUMBER
         if(b_output_condition_number) then
            call cond_num_cal(2*nngl, njaglob, iaglob, jaglob, aglob,  &
                              condition_number, condition_number_info)  
            if (rank == 0 .and. b_enable_output) then
            
            if (condition_number_info(1) .ge. 0) then
              write(*,"(2(a, e10.3, 1x))")                             & 
                    " classical cond. num. ", condition_number(1),     &
                    " skeel cond. num. ", condition_number(2)
              write(ilog,"(2(a, e10.3, 1x))")                          &
                    " classical cond. num. ", condition_number(1),     &
                    " skeel cond. num. ", condition_number(2)
            else
              write(*,*)                                               &
                    ' error in estimating condition number, info(1) ', &
                    condition_number_info(1)
              write(ilog,*)                                            &
                    ' error in estimating condition number, info(1) ', &
                    condition_number_info(1)
            endif
            
            if(i_solver_type_flow == 1) then
              if(condition_number(1) > 1.0e10 .and.                    &
                      condition_number(2) > 1.0e10) then
                  write(*,"(a)")                                       &
                        " Warning: matrix is ill-conditioned."
                  write(ilog,"(a)")                                    &
                        " Warning: matrix is ill-conditioned."
              end if
            end if
            
            end if
         end if
#endif         
         prt_flow_jac = cputime() - prt_flow_jac
           
         prt_flow_solver = 0.0d0  
        !! use ws209 solver
        if (i_solver_type_flow == 0) then
#ifdef PARDISO
           if (b_solver_test_pardiso) then
    !$omp parallel                                                    &
    !$omp if (njaglob > numofloops_thred_global)                      &
    !$omp num_threads(numofthreads_global)                            &
    !$omp default(shared)                                             &
    !$omp private (i)  
    !$omp do schedule(static)
                do i = 1, njaglob
                    aglob_std(i) = aglob(imapglob_std(i))
                end do
    !$omp end do
    !$omp end parallel
           
                b_redo_symbfac = .true.
100             prt_flow_symbfac_comp = cputime()
                if(bsymbolicfactor_glob  .or.                          &
                        i_symfactor_type_flow == 1) then
                    call pardiso_symbolicfactorization(iparm_glob,     &
                         ptglob, 2*nngl, njaglob, iaglob, jaglob_std,  &
                         aglob_std)
                    n_unknown_glob = 2*nngl
                    bsymbolicfactor_glob = .false.
                end if 
                prt_flow_symbfac_comp=cputime()-prt_flow_symbfac_comp

                prt_flow_fac_comp = cputime()
                call pardiso_numfactorization(iparm_glob,              &
                     ptglob, 2*nngl, njaglob, iaglob, jaglob_std,      &
                     aglob_std)
                prt_flow_fac_comp=cputime()-prt_flow_fac_comp

                prt_flow_sub_comp = cputime()  
                call pardiso_substitution(ilog, msolvitglob,           &
                     itsolvtotglob, idetailglob, resglob, restolglob,  &
                     deltolglob, over_flow, rnorm, rmupdate,           &
                     iparm_glob, ptglob, 2*nngl, njaglob, iaglob,      &
                     jaglob_std, aglob_std, bglob, uglob_std)
                prt_flow_sub_comp = cputime() - prt_flow_sub_comp
                
                if (b_redo_symbfac .and.                               &
                      (itsolvtotglob > n_max_iteration_flow .or.       &
                      rnorm > r_max_residual_flow .or. over_flow)) then
                    bsymbolicfactor_glob = .true.  
                    b_redo_symbfac = .false.
                    goto 100
                end if
            
           end if
#endif       

#ifdef PETSC
           if(b_solver_test_petsc) then
            !only solver the local part, update the ghost value
              call solver_dd_snes_solve_flow(ilog,idetailglob,aglob,   &
                       bglob,uglob_std,iaglob,jaglob,2*nngl,           &
                       itsolvtotglob,over_flow,rnorm,                  &
                       row_idx_l2pg_glob,col_idx_l2pg_glob,.true.)
              over_flow_vs = over_flow
#ifdef DEBUG
             if(rank == 0) then
                write(*,'(a, 2(1x, i5), 1x, l1, 1x, e12.4)')          &
                "ddvsflow-A: rank, iteration, over_flow, rnorm ",     &
                rank, itsolvtotglob, over_flow, rnorm 
             end if
#endif
           end if
#endif

!cprovi--------------------------------------------------------------------
!cprovi Scale [avs] and {bvs} to produce unit diagonal
!cprovi Generate re-ordered preconditioner [af]
!cprovi--------------------------------------------------------------------
           ilist = 1
           prt_flow_fac = cputime()
           
           call incompletefactorization(2*nngl,njaglob,njafglob,bglob, &
                                        aglob,afglob,rwork_max,iaglob, &
                                        jaglob,iafglob,iafdglob,       &
                                        jafglob,iwork_max(ilist),      &
                                        lorderglob,invordglob,         &
                                        numofthreads_ws209)
           prt_flow_fac = cputime() - prt_flow_fac
 
!c  solve [avs] * {uvs} = {bvs}
           prt_flow_sub = cputime()  

           call ws209(ilog,2*nngl,msolvitglob,itsolvtotglob,           &
                idetailglob,iaglob,jaglob,iafglob,iafdglob,jafglob,    &
                lorderglob,aglob,afglob,uglob,bglob,resglob,rwork_max, &
                restolglob,deltolglob,njaglob,njafglob,over_flow,rnorm,&
                rmupdate,numofthreads_ws209,b_enable_output) 

           prt_flow_sub = cputime() - prt_flow_sub
           
#ifdef PARDISO
           if (b_solver_test_pardiso) then      
             call solver_results_check_output(ittotglob, 2*nngl,       &
                  uglob, uglob_std, "ddvsflow_glob") 
           end if 
#endif

#ifdef PETSC
           if (b_solver_test_petsc) then        
               call solver_results_check_output(ittotglob, 2*nngl,     &
                    uglob, uglob_std, "ddvsflow_glob_petsc") 
           end if
#endif
         prt_flow_solver = prt_flow_symbfac + prt_flow_fac + prt_flow_sub
        !! use pardiso solver
        else if (i_solver_type_flow == 1) then
#ifdef PARDISO 
    !$omp parallel                                                    &
    !$omp if (njaglob > numofloops_thred_global)                      &
    !$omp num_threads(numofthreads_global)                            &
    !$omp default(shared)                                             &
    !$omp private (i)  
    !$omp do schedule(static)
            do i = 1, njaglob
                aglob_std(i) = aglob(imapglob_std(i))
            end do
    !$omp end do
    !$omp end parallel
           
            b_redo_symbfac = .true.
200         prt_flow_symbfac = cputime() 
            if(bsymbolicfactor_glob  .or.                              &
                    i_symfactor_type_flow == 1) then
                !write(idbg, *) "pardiso symbolic factorization for ddvsflow line 340"
                call pardiso_symbolicfactorization(iparm_glob, ptglob, &
                     2*nngl, njaglob, iaglob, jaglob_std, aglob_std)
                n_unknown_glob = 2*nngl
                bsymbolicfactor_glob = .false.
            end if 
            prt_flow_symbfac = cputime() - prt_flow_symbfac
            
            !write(idbg, *) "pardiso numerical factorization for ddvsflow line 345"
            prt_flow_fac = cputime()
            call pardiso_numfactorization(iparm_glob, ptglob, 2*nngl,  &
                 njaglob, iaglob, jaglob_std, aglob_std)
            prt_flow_fac = cputime() - prt_flow_fac
            
            !write(idbg, *) "pardiso substitution for ddvsflow line 347"
            prt_flow_sub = cputime() 
            call pardiso_substitution(ilog, msolvitglob,               &
                 itsolvtotglob, idetailglob, resglob, restolglob,      &
                 deltolglob, over_flow, rnorm, rmupdate, iparm_glob,   &
                 ptglob, 2*nngl, njaglob, iaglob, jaglob_std,          &
                 aglob_std, bglob, uglob) 
            prt_flow_sub = cputime() - prt_flow_sub
            
            if (b_redo_symbfac .and.                                   &
                  (itsolvtotglob > n_max_iteration_flow .or.           &
                  rnorm > r_max_residual_flow .or. over_flow)) then
                bsymbolicfactor_glob = .true.    
                b_redo_symbfac = .false.
                goto 200
            end if
#endif 
         prt_flow_solver=prt_flow_symbfac+prt_flow_fac+prt_flow_sub
        !! use PETSc solver
        else if (i_solver_type_flow == 2) then
#ifdef PETSC     
           prt_flow_solver = cputime()
           !only solver the local part, update the ghost value
           call solver_dd_snes_solve_flow(ilog,idetailglob,aglob,      &
                    bglob,uglob,iaglob,jaglob,2*nngl,                  &
                    itsolvtotglob,over_flow,rnorm,                     &
                    row_idx_l2pg_glob,col_idx_l2pg_glob,.true.)
           over_flow_vs = over_flow
           prt_flow_solver = cputime() - prt_flow_solver
#ifdef DEBUG
             if(rank == 0 .and. b_enable_output) then
                write(*,'(a, 2(1x, i5), 1x, l1, 1x, e12.4)')          &
                "ddvsflow-B: rank, iteration, over_flow, rnorm ",     &
                rank, itsolvtotglob, over_flow, rnorm  
             end if
#endif
#endif        
        end if
        
         !Export sparse matrix dataset and right hand side. For test only, dsu.
         if((b_output_matrix.or.itimestep_output_matrix == mtime) .and.&
             b_enable_output) then
             if(itype_matrix_format == 0) then
                call export_arrays1d(2*nngl, njaglob, iaglob, jaglob,  &
                aglob, bglob, uglob, .false., .false., .true.,         &
                "ddvsflow_glob", ittotglob)
             else if(itype_matrix_format == 1) then
                call export_mmformat(2*nngl, njaglob, iaglob, jaglob,  &
                aglob, bglob, uglob, .false., .false., .true.,         &
                "ddvsflow_glob", ittotglob)
#ifdef PETSC
                call export_mmformat_gbl(2*nngl, njaglob, iaglob,      &
                     jaglob, aglob, bglob, uglob, .false., .false.,    &
                     .true., "ddvsflow_glob", nngl, nngbl, .false.,    &
                     ittotglob)
#endif
             end if
         end if
         
           if (.not.transient_flow.and.itsolvtotglob.eq.msolvitglob) then
              if(rank == 0) then        !if MPI rank 0 
                  write(*,'(a/a)')                                &
                 'maximum number of inner iterations exceeded',   &
                 'steady state flow solution non-convergent'
                  write(ilog,'(a/a)')                             &
                 'maximum number of inner iterations exceeded',   &
                 'steady state flow solution non-convergent'
              end if                     !end if MPI rank 0

#ifdef PETSC
              call petsc_mpi_finalize
#endif
              stop
           end if
        
         else 
!cprovi--------------------------------------------
!cprovi Only flow  
!cprovi--------------------------------------------         
           iter_vs = iter_vs+1             !iteration counter (current)
           ittot_vs = ittot_vs+1           !iteration counter (total)

           if (idetail_vs.eq.2 .and. rank == 0 .and. b_enable_output) then
             write(ilog,'(/a,i3,a)') 'Newton iteration ',iter_vs,':'
             write(ilog,'(a)') '---------------------'
           end if

!c  clear arrays
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp parallel
    !$omp sections
#endif
#endif

#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif  
           avs=r0
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif
           bvs=r0
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif
           uvs=r0
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp section
#endif
#endif
           if (i_solver_type_flow == 0) then
               call zero_r8(afvs, size(afvs, 1), 1, 1)
           end if
#ifdef OPENMP
#ifdef PARALLEL_SECTION
    !$omp end sections
    !$omp end parallel
#endif
#endif


           prt_flow_jac = cputime()
           
!c  compute influence coefficients in terms of conductivities
           if (gas_advection .or. dgm .or. maxwell) then
             call infcvs_cp
           end if 

!c Compute the jacobian and residual
           call jacddvs
 
!c  adjust matrix and rhs vector for boundary conditions 
           call jacbvs
          
        !Export sparse matrix dataset and right hand side. For test only, dsu.    
        if((b_output_matrix.or.itimestep_output_matrix == mtime) .and. &
            b_enable_output) then
            if(itype_matrix_format == 0) then
                call export_arrays1d(nngl, njavs, iavs, javs, avs, bvs,&
                uvs, .true., .true., .false., "ddvsflow_vs", ittot_vs)
            else if(itype_matrix_format == 1) then
                call export_mmformat(nngl, njavs, iavs, javs, avs, bvs,&
                uvs, .true., .true., .false., "ddvsflow_vs", ittot_vs)
#ifdef PETSC
                call export_mmformat_gbl(nngl, njavs, iavs, javs, avs, &
                     bvs, uvs, .true., .true., .false., "ddvsflow_vs", &
                     nngl, nngbl, .false.,ittot_vs)
#endif
            end if
        end if   


!cprovi--------------------------------------------------------------------
!cprovi Estimate condition number for the current matrix. 
!cprovi This is used for testing when newton iteration failed.
!cprovi--------------------------------------------------------------------
#ifdef CONDITION_NUMBER
         if(b_output_condition_number) then
            call cond_num_cal(nngl, njavs, iavs, javs, avs,            &
                 condition_number, condition_number_info)
            
            if (rank == 0 .and. b_enable_output) then
            
            if (condition_number_info(1) .ge. 0) then
              write(*,"(2(a, e10.3, 1x))")                             &
                    " classical cond. num. ", condition_number(1),     &
                    " skeel cond. num. ", condition_number(2)
              write(ilog,"(2(a, e10.3, 1x))")                          &
                    " classical cond. num. ", condition_number(1),     &
                    " skeel cond. num. ", condition_number(2)
            else
              write(*,*)                                               &
                    ' error in estimating condition number, info(1) ', &
                    condition_number_info(1)
              write(ilog,*)                                            &
                    ' error in estimating condition number, info(1) ', &
                    condition_number_info(1)
            endif 
            
            if(i_solver_type_flow == 1) then
              if(condition_number(1) > 1.0e10 .and.                    &
                      condition_number(2) > 1.0e10) then
                  write(*,"(a)")                                       &
                        " Warning: matrix is ill-conditioned."
                  write(ilog,"(a)")                                    &
                        " Warning: matrix is ill-conditioned."
              end if
            end if
            
            end if
            
         end if
#endif           
        prt_flow_jac = cputime() - prt_flow_jac
           
        !! use ws209 solver
        if (i_solver_type_flow == 0) then 
#ifdef PARDISO
        if (b_solver_test_pardiso) then
            !!reset value of a
    !$omp parallel                                                    &
    !$omp if (njavs > numofloops_thred_global)                        &
    !$omp num_threads(numofthreads_global)                            &
    !$omp default(shared)                                             &
    !$omp private (i)  
    !$omp do schedule(static)
            do i = 1, njavs
                avs_std(i) = avs(imapvs_std(i))
            end do
    !$omp end do
    !$omp end parallel
           
            b_redo_symbfac = .true.
300         prt_flow_symbfac_comp = cputime()
            if(bsymbolicfactor_vs  .or.                                &
                    i_symfactor_type_flow == 1) then
                call pardiso_symbolicfactorization(iparm_vs, ptvs,     &
                     nngl, njavs, iavs, javs_std, avs_std)
                n_unknown_vs = nngl
                bsymbolicfactor_vs = .false.
            end if  
            prt_flow_symbfac_comp = cputime() - prt_flow_symbfac_comp
            
            prt_flow_fac_comp = cputime()
            call pardiso_numfactorization(iparm_vs, ptvs, nngl, njavs, &
                 iavs, javs_std, avs_std)
            prt_flow_fac_comp = cputime() - prt_flow_fac_comp

            prt_flow_sub_comp = cputime()
            call pardiso_substitution(ilog, msolvit_vs, itsolv,        &
                 idetail_vs, resvs, restol_vs, deltol_vs, over_flow,   &
                 rnorm, rmupdate, iparm_vs, ptvs, nngl, njavs, iavs,   &
                 javs_std, avs_std, bvs, uvs_std) 
            prt_flow_sub_comp = cputime() - prt_flow_sub_comp
            
            if (b_redo_symbfac .and.                                   &
                  (itsolv > n_max_iteration_flow .or.                  &
                  rnorm > r_max_residual_flow .or. over_flow)) then
                bsymbolicfactor_vs = .true. 
                b_redo_symbfac = .false.
                goto 300
            end if
            
        end if       
#endif

#ifdef PETSC
        if(b_solver_test_petsc) then
            !only solver the local part, update the ghost value
            call solver_dd_snes_solve_flow(ilog,idetail_vs,avs,bvs,    &
                    uvs_std,iavs,javs,nngl,itsolv,over_flow,rnorm,     &
                    row_idx_l2pg_vs,col_idx_l2pg_vs,.false.)
            over_flow_vs = over_flow
#ifdef DEBUG
             if(rank == 0) then
                write(*,'(a, 2(1x, i5), 1x, l1, 1x, e12.4)')          &
                "ddvsflow-C: rank, iteration, over_flow, rnorm ",     &
                rank, itsolv, over_flow, rnorm    
             end if
#endif
        end if
#endif

!c  Scale [avs] and {bvs} to produce unit diagonal
!c  Generate re-ordered preconditioner [af]
        ilist = 1
        prt_flow_fac = cputime()

        call incompletefactorization(nngl,njavs,njafvs,bvs,avs,afvs,   &
                                     rwork_max,iavs,javs,iafvs,iafdvs, &
                                     jafvs,iwork_max(ilist),lordervs,  &
                                     invordvs,numofthreads_ws209)
        prt_flow_fac = cputime() - prt_flow_fac
        
!c  solve [avs] * {uvs} = {bvs}
        prt_flow_sub = cputime()
 
        call ws209(ilog,nngl,msolvit_vs,itsolv,idetail_vs,iavs,javs,   &
                   iafvs,iafdvs,jafvs,lordervs,avs,afvs,uvs,bvs,resvs, &
                   rwork_max,restol_vs,deltol_vs,njavs,njafvs,         &
                   over_flow,rnorm,rmupdate,numofthreads_ws209,        &
                   b_enable_output)

        prt_flow_sub = cputime() - prt_flow_sub
#ifdef PARDISO
        if (b_solver_test_pardiso) then     
          call solver_results_check_output(ittot_vs, nngl, uvs,        &
               uvs_std, "ddvsflow_vs") 
        end if 
#endif     

#ifdef PETSC  
        if (b_solver_test_petsc) then        
            call solver_results_check_output(ittot_vs, nngl, uvs,      &
                 uvs_std, "ddvsflow_vs_petsc") 
        end if
#endif 
        prt_flow_solver = prt_flow_symbfac+prt_flow_fac+prt_flow_sub
        !! use pardiso solver
        else if (i_solver_type_flow == 1) then
#ifdef PARDISO
    !$omp parallel                                                    &
    !$omp if (njavs > numofloops_thred_global)                        &
    !$omp num_threads(numofthreads_global)                            &
    !$omp default(shared)                                             &
    !$omp private (i)  
    !$omp do schedule(static)
            do i = 1, njavs
                avs_std(i) = avs(imapvs_std(i))
            end do
    !$omp end do
    !$omp end parallel
           
            b_redo_symbfac = .true.
400         prt_flow_symbfac = cputime()
            if(bsymbolicfactor_vs  .or.                                &
                    i_symfactor_type_flow == 1) then
                !write(idbg, *) "pardiso symbolic factorization for ddvsflow line 435"
                call pardiso_symbolicfactorization(iparm_vs, ptvs,     &
                     nngl, njavs, iavs, javs_std, avs_std)
                n_unknown_vs = nngl
                bsymbolicfactor_vs = .false.
            end if  
            prt_flow_symbfac = cputime() - prt_flow_symbfac
            
            !write(idbg, *) "pardiso numerical factorization for ddvsflow line 439"
            prt_flow_fac = cputime()
            call pardiso_numfactorization(iparm_vs, ptvs, nngl, njavs, &
                 iavs, javs_std, avs_std)
            prt_flow_fac = cputime() - prt_flow_fac
            
            !write(idbg, *) "pardiso substitution for ddvsflow line 441"
            prt_flow_sub = cputime()
            call pardiso_substitution(ilog, msolvit_vs, itsolv,        &
                 idetail_vs, resvs, restol_vs, deltol_vs, over_flow,   &
                 rnorm, rmupdate, iparm_vs, ptvs, nngl, njavs, iavs,   &
                 javs_std, avs_std, bvs, uvs) 
            prt_flow_sub = cputime() - prt_flow_sub
            
            if (b_redo_symbfac .and.                                   &
                  (itsolv > n_max_iteration_flow .or.                  &
                  rnorm > r_max_residual_flow .or. over_flow)) then
                bsymbolicfactor_vs = .true.   
                b_redo_symbfac = .false.
                goto 400
            end if
#endif
            prt_flow_solver=prt_flow_symbfac+prt_flow_fac+prt_flow_sub
        !! use PETSc solver
        else if (i_solver_type_flow == 2) then
#ifdef PETSC      
            prt_flow_solver = cputime()
            !only solver the local part, update the ghost value
            call solver_dd_snes_solve_flow(ilog,idetail_vs,avs,bvs,    &
                     uvs,iavs,javs,nngl,itsolv,over_flow,rnorm,        &
                     row_idx_l2pg_vs,col_idx_l2pg_vs,.false.) 
            over_flow_vs = over_flow
            prt_flow_solver = cputime() - prt_flow_solver
#ifdef DEBUG
             if(rank == 0 .and. b_enable_output) then
                write(*,'(a, 2(1x, i5), 1x, l1, 1x, e12.4)')          &
                "ddvsflow-D: rank, iteration, over_flow, rnorm ",     &
                rank, itsolv, over_flow, rnorm
             end if
#endif
#endif        
        end if
        
        !Export sparse matrix dataset and right hand side. For test only, dsu.  
        if((b_output_matrix.or.itimestep_output_matrix == mtime) .and. &
            b_enable_output) then
            if(itype_matrix_format == 0) then
                call export_arrays1d(nngl,njavs,iavs,javs,avs,bvs,     &
                     uvs,.false.,.false.,.true.,"ddvsflow_vs",ittot_vs)
            else if(itype_matrix_format == 1) then
                call export_mmformat(nngl,njavs,iavs,javs,avs,bvs,     &
                     uvs,.false.,.false.,.true.,"ddvsflow_vs",ittot_vs)
#ifdef PETSC
                call export_mmformat_gbl(nngl,njavs,iavs,javs,avs,bvs, &
                     uvs,.false.,.false.,.true.,"ddvsflow_vs",nngl,    &
                     nngbl, .false., ittot_vs)
#endif
            end if
        end if   

        if (.not.transient_flow.and.itsolv.eq.msolvit_vs) then
          if(rank == 0) then        !if MPI rank 0
          write(*,'(a/a)')                                &
          'maximum number of inner iterations exceeded',    &
          'steady state flow solution non-convergent'
          write(ilog,'(a/a)')                             &
          'maximum number of inner iterations exceeded',    &
          'steady state flow solution non-convergent'
          end if                    !end if MPI rank 0

#ifdef PETSC
          call petsc_mpi_finalize
#endif
          stop
        end if

       end if ! energy balance 

!cprovi---------------------------------------------------------------------------------------------------
!cprovi End build jacobian and residual 
!cprovi---------------------------------------------------------------------------------------------------      
!c  total number of solver iterations

      itsolvtot_vs = itsolvtot_vs + itsolv   

      
      if (.not.over_flow) then
!cprovi---------------------------------------------------------------------------------------------------
!cprovi Update the solution 
!cprovi Parallelized, OpenMP, DSU
!cprovi---------------------------------------------------------------------------------------------------           
            if (heat_transport) then

               call updatedd_energybalance 

               iter=iterglob
               maxiter=maxiterglob
            else 

               call updatedd
             
               iter=iter_vs
               maxiter=maxit_vs
            end if

!cprovi---------------------------------------------------------------------------------------------------           
!cprovi---------------------------------------------------------------------------------------------------                 
!cprovi---------------------------------------------------------------------------------------------------            
                        
!c  max. number of iterations is exceeded and convergence tolerance
!c  not satisfied
!c  steady state problem -> terminate execution

            if ((iter==maxiter).and.(not_converged)) then
              if (steady_flow) then
                if (rank == 0 .and. b_enable_output) then
                  write(ilog,*)                                     &
                  '-------------------------------------------'
                  write(ilog,*)                                     &
                  '   terminated in routine vsflow            '
                  write(ilog,*)                                     &
                  '   maximum number of iterations exceeded   '
                  write(ilog,*)                                     &
                  '   bye now ...                             '
                  write(ilog,*)                                     &
                  '-------------------------------------------'
                  
                  if (b_enable_output_gen) then
                    write(igen,*)                                   &
                    '-------------------------------------------'
                    write(igen,*)                                   &
                    '   terminated in routine vsflow            '
                    write(igen,*)                                   &
                    '   maximum number of iterations exceeded   '
                    write(igen,*)                                   &
                    '   bye now ...                             '
                    write(igen,*)                                   &
                    '-------------------------------------------'
                  end if
                end if
#ifdef PETSC
                call petsc_mpi_finalize
#endif
                stop

!c  transient problem -> reduce time step

              elseif (transient_flow) then 
                  
                if(rank == 0 .and. b_enable_output)  then 

                  write(ilog,*)                                   & 
                  '-------------------------------------------'
                  write(ilog,*)                                   & 
                  '   maximum number of iterations exceeded   '
                  write(ilog,*)                                   &
                  '             reducing time step            '
                  write(ilog,*)                                   & 
                  '-------------------------------------------'
                
                end if

                reduce_timestep = .true.
              end if
              
              
            end if

!c  overflow occurred
!c  steady state problem -> terminate execution

          elseif (over_flow) then
            if (steady_flow) then
              if (rank == 0 .and. b_enable_output) then
                write(ilog,*)'-------------------------------------------'
                write(ilog,*)'   failure in solver - overflow occurred in ddvsflow   '
                write(ilog,*)'   bye now ...                             '
                write(ilog,*)'-------------------------------------------'
                
                if (b_enable_output_gen) then
                  write(igen,*)'-------------------------------------------'
                  write(igen,*)'   failure in solver - overflow occurred in ddvsflow   '
                  write(igen,*)'   bye now ...                             '
                  write(igen,*)'-------------------------------------------'
                end if
                
              end if

              reduce_timestep = .true.

!c  transient problem -> reduce time step

            elseif (transient_flow) then
                
              if(rank == 0 .and. b_enable_output)  then  

              write(ilog,*)'-------------------------------------------'
              write(ilog,*)'   failure in solver - overflow occurred in ddvsflow   '
              write(ilog,*)'             reducing time step            '
              write(ilog,*)'-------------------------------------------'
              
              end if

              reduce_timestep = .true.
            end if
          end if                      !(over_flow)
          
          prt_flow_tot = cputime() - prt_flow_tot
          
!c  write runtime to file
        if(rank == 0 .and. b_prtfile) then
            if (heat_transport) then
                write(iprt_flow, "(i8,1x,3(i3, 1x),i8,1x,7(e12.4,2x))")&
                      mtime, iter_sia, iter_seep, iterglob, ittotglob, &
                      prt_flow_jac, prt_flow_symbfac, prt_flow_fac,    &
                      prt_flow_sub, prt_flow_solver,                   &
                      (prt_flow_tot - prt_flow_jac - prt_flow_solver), &
                      prt_flow_tot
                
                if(b_solver_test_pardiso) then
                    write(iprt_flow_comp,                              &
                          "(i8,1x,3(i3, 1x),i8,1x,5(e12.4,2x))")       &
                          mtime, iter_sia, iter_seep, iterglob,        &
                          ittotglob, prt_flow_fac, prt_flow_sub,       &
                          prt_flow_symbfac_comp, prt_flow_fac_comp,    &
                          prt_flow_sub_comp
                end if 
            else
                write(iprt_flow, "(i8,1x,3(i3, 1x),i8,1x,7(e12.4,2x))")&
                      mtime, iter_sia, iter_seep, iter_vs, ittot_vs,   &
                      prt_flow_jac, prt_flow_symbfac, prt_flow_fac,    &
                      prt_flow_sub, prt_flow_solver,                   &
                      (prt_flow_tot - prt_flow_jac - prt_flow_solver), &
                      prt_flow_tot
                
                if(b_solver_test_pardiso) then
                    write(iprt_flow_comp,                              &
                          "(i8,1x,3(i3, 1x),i8,1x,5(e12.4,2x))")       &
                          mtime, iter_sia, iter_seep, iter_vs,         &
                          ittot_vs, prt_flow_fac, prt_flow_sub,        &
                          prt_flow_symbfac_comp, prt_flow_fac_comp,    &
                          prt_flow_sub_comp
                end if
            end if
        end if

!c  reset primary and secondary unknowns for reduced time step

          if (reduce_timestep) then   
   
            uvsnew = uvsold
            pornew = porold
            density = densold
            densold1 = densold
            tds_new = tds_old
            sanew = saold 
            if (heat_transport) then
              tempnew = tempold
              if (update_viscosity_temp) then 
                viscosity = viscoold
              end if 
              if (ispitzerdens) then
                  density_pitzer = densold_pitzer
                end if
                if (variably_saturated) then
                  sgnew = sgold
                  if (evaporation) then
                    densvnew = densvold
                    latvapnew = latvapold
                  end if  
                end if                
            end if

!c  return and start over with reduced time step

            goto 20
            
          end if          
 
        end do          !newton iteration loop
        
   
        ! If porosity is not updated according to flow
        if (.not.update_porosity_flow) then
             pornew=porold
        end if
 

!c  seepage face iteration update
!c  Parallelized, OpenMP, DSU. No benchmark to test this subroutine.
        if (seepage_face) then
          call seepfdd
        end if
      
      end do            !seepage face iteration loop


!c  estimate time step size for next time level
!c  Parallelized, OpenMP, DSU
      if (transient_flow) then
        call tstepvs
      end if  
      
   20 continue  

!cprov-------------------------------------------------------------------------      
!cprov Deallocate local variables
!cprov-------------------------------------------------------------------------
      
      if (heat_transport) then
        if (b_dynamic_memory) then
            deallocate (aglob)
            call checkerr(ierr,'aglob',ilog)
            
            if (i_solver_type_flow == 0) then
                deallocate (afglob)
                call checkerr(ierr,'afglob',ilog)     
            end if
        end if
      else  
        if (b_dynamic_memory) then
            deallocate (avs, stat = ierr)
            call checkerr(ierr,'avs',ilog)
            
            if (i_solver_type_flow == 0) then
                deallocate (afvs, stat = ierr)
                call checkerr(ierr,'afvs',ilog) 
            end if 
        end if
      end if

      return
      end
